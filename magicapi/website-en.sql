-- MySQL dump 10.13  Distrib 5.7.32, for Linux (x86_64)
--
-- Host: localhost    Database: website
-- ------------------------------------------------------
-- Server version	5.7.32

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Current Database: `website`
--

CREATE DATABASE /*!32312 IF NOT EXISTS*/ `website` /*!40100 DEFAULT CHARACTER SET utf8 */;

USE `website_en`;

--
-- Table structure for table `e_dict`
--

DROP TABLE IF EXISTS `e_dict`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `e_dict` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_by` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `create_time` datetime DEFAULT NULL,
  `update_by` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `code` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `name` longtext COLLATE utf8mb4_unicode_ci,
  `remark` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `UKf5wwh5osfukkeebw7h2yb4kmp` (`code`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `e_dict`
--

LOCK TABLES `e_dict` WRITE;
/*!40000 ALTER TABLE `e_dict` DISABLE KEYS */;
INSERT INTO `e_dict` VALUES (1,'admin','2022-07-13 11:42:48','admin','2022-07-13 11:42:48','java','java','测试字典能力');
/*!40000 ALTER TABLE `e_dict` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `e_dict_item`
--

DROP TABLE IF EXISTS `e_dict_item`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `e_dict_item` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_by` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `create_time` datetime DEFAULT NULL,
  `update_by` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `code` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `name` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `remark` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `sort` int(11) DEFAULT NULL,
  `erupt_dict_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `UKl0kiq8otpn3fvtlvarebt8xkh` (`code`,`erupt_dict_id`),
  KEY `FKrrbi2dt94rjd8sjt830m3w0a` (`erupt_dict_id`),
  CONSTRAINT `FKrrbi2dt94rjd8sjt830m3w0a` FOREIGN KEY (`erupt_dict_id`) REFERENCES `e_dict` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `e_dict_item`
--

LOCK TABLES `e_dict_item` WRITE;
/*!40000 ALTER TABLE `e_dict_item` DISABLE KEYS */;
/*!40000 ALTER TABLE `e_dict_item` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `e_upms_login_log`
--

DROP TABLE IF EXISTS `e_upms_login_log`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `e_upms_login_log` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `browser` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `device_type` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `ip` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `login_time` datetime DEFAULT NULL,
  `name` varchar(255) CHARACTER SET utf8 DEFAULT NULL,
  `system_name` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `token` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `user_name` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `region` varchar(255) CHARACTER SET utf8 DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=66 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `e_upms_login_log`
--

LOCK TABLES `e_upms_login_log` WRITE;
/*!40000 ALTER TABLE `e_upms_login_log` DISABLE KEYS */;
INSERT INTO `e_upms_login_log` VALUES (1,'Chrome 10 103','Computer','192.168.10.233','2022-07-12 18:54:44',NULL,'Mac OS X','ROIZXzsM7Cnnkf75','erupt','0|0|0|内网IP|内网IP'),(2,'Chrome 10 103','Computer','192.168.10.233','2022-07-12 19:28:58',NULL,'Mac OS X','eliuTlvaIfbvsFd9','erupt','0|0|0|内网IP|内网IP'),(3,'Chrome 10 103','Computer','192.168.10.233','2022-07-12 19:32:12',NULL,'Mac OS X','ZZeFtdfpNuqH4MiI','erupt','0|0|0|内网IP|内网IP'),(4,'Chrome 10 103','Computer','192.168.10.233','2022-07-12 19:35:36',NULL,'Mac OS X','5bGN6GhilUbUUHTZ','erupt','0|0|0|内网IP|内网IP'),(5,'Chrome 10 103','Computer','192.168.10.233','2022-07-12 21:31:37',NULL,'Mac OS X','EO5WEyHQwwTn5Swa','erupt','0|0|0|内网IP|内网IP'),(6,'Chrome 10 103','Computer','192.168.10.233','2022-07-12 21:37:15',NULL,'Mac OS X','4j9L3lTj4HY5CQIR','test1','0|0|0|内网IP|内网IP'),(7,'Chrome 10 103','Computer','192.168.10.233','2022-07-12 21:38:46',NULL,'Mac OS X','KWdTIDoyPt60UYNr','admin','0|0|0|内网IP|内网IP'),(8,'Chrome 10 103','Computer','192.168.10.233','2022-07-13 11:37:58',NULL,'Mac OS X','ka8W8vBzE3T0fEYc','admin','0|0|0|内网IP|内网IP'),(9,'Chrome 10 103','Computer','192.168.10.233','2022-07-13 13:45:40',NULL,'Mac OS X','cONFl3uyODe6Lwf0','admin','0|0|0|内网IP|内网IP'),(10,'Chrome 10 103','Computer','192.168.10.233','2022-07-13 13:55:18',NULL,'Mac OS X','5f53tsXMOJ3FDkmt','admin','0|0|0|内网IP|内网IP'),(11,'Chrome 10 103','Computer','192.168.10.233','2022-07-13 14:15:08',NULL,'Mac OS X','b0WrmveryA8qKt30','admin','0|0|0|内网IP|内网IP'),(12,'Chrome 10 103','Computer','192.168.10.233','2022-07-13 14:31:35',NULL,'Mac OS X','0V7Ot32Ke8DDrQ6l','admin','0|0|0|内网IP|内网IP'),(13,'Chrome 10 103','Computer','192.168.10.233','2022-07-13 14:37:50',NULL,'Mac OS X','SA06loOmYFEHOSXq','admin','0|0|0|内网IP|内网IP'),(14,'Chrome 10 103','Computer','192.168.10.233','2022-07-13 16:07:11',NULL,'Mac OS X','rshqcHVBjhgMahA9','admin','0|0|0|内网IP|内网IP'),(15,'Chrome 10 103','Computer','192.168.10.233','2022-07-13 16:49:21',NULL,'Mac OS X','KY8pG9E0dNLBB2PV','admin','0|0|0|内网IP|内网IP'),(16,'Chrome 10 103','Computer','192.168.10.233','2022-07-13 17:43:09',NULL,'Mac OS X','rUNyH4HTL6PX5pEO','admin','0|0|0|内网IP|内网IP'),(17,'Chrome 10 103','Computer','192.168.10.233','2022-07-13 17:52:44',NULL,'Mac OS X','Nam76heedbDb5Wo1','admin','0|0|0|内网IP|内网IP'),(18,'Chrome 10 103','Computer','192.168.10.233','2022-07-13 19:03:47',NULL,'Mac OS X','4B9AfQruzj5Dsvuv','admin','0|0|0|内网IP|内网IP'),(19,'Chrome 10 103','Computer','192.168.10.233','2022-07-13 19:27:34',NULL,'Mac OS X','A7JaNDgAyxMWk0I7','admin','0|0|0|内网IP|内网IP'),(20,'Chrome 10 103','Computer','192.168.10.233','2022-07-14 11:03:19',NULL,'Mac OS X','KgKlHrwB3IS7ys0h','admin','0|0|0|内网IP|内网IP'),(21,'Chrome 10 103','Computer','192.168.10.233','2022-07-14 11:39:55',NULL,'Mac OS X','Fy1lZf5Soqf02oJX','admin','0|0|0|内网IP|内网IP'),(22,'Chrome 10 103','Computer','192.168.10.233','2022-07-14 13:27:18',NULL,'Mac OS X','UlnsDJgmRATYuI8b','admin','0|0|0|内网IP|内网IP'),(23,'Chrome 10 103','Computer','192.168.10.233','2022-07-14 13:49:32',NULL,'Mac OS X','9K4VT5aMaYnhPs1E','admin','0|0|0|内网IP|内网IP'),(24,'Chrome 10 103','Computer','192.168.10.233','2022-07-14 13:49:54',NULL,'Mac OS X','qjomZfkNiswHIaeZ','admin','0|0|0|内网IP|内网IP'),(25,'Chrome 10 103','Computer','192.168.10.233','2022-07-14 14:35:45',NULL,'Mac OS X','v7u39lR3v3Nyi4RO','admin','0|0|0|内网IP|内网IP'),(26,'Chrome 10 103','Computer','192.168.10.233','2022-07-14 14:46:22',NULL,'Mac OS X','zvOzqbb6mPMZbjUi','admin','0|0|0|内网IP|内网IP'),(27,'Chrome 10 103','Computer','192.168.10.233','2022-07-14 14:48:56',NULL,'Mac OS X','C4AWwgfvQ9780o3H','admin','0|0|0|内网IP|内网IP'),(28,'Chrome 10 103','Computer','192.168.10.233','2022-07-14 15:40:30',NULL,'Mac OS X','WrwEzQ6JT7pPCAMm','admin','0|0|0|内网IP|内网IP'),(29,'Chrome 10 103','Computer','192.168.10.233','2022-07-14 18:26:26',NULL,'Mac OS X','MFER7tNBOLbkt44P','admin','0|0|0|内网IP|内网IP'),(30,'Chrome 10 103','Computer','192.168.10.233','2022-07-14 19:08:54',NULL,'Mac OS X','2IjnXBKE4cWFT08E','admin','0|0|0|内网IP|内网IP'),(31,'Chrome 10 103','Computer','192.168.10.233','2022-07-14 19:09:54',NULL,'Mac OS X','56eRH9YGrUeLtGIe','admin','0|0|0|内网IP|内网IP'),(32,'Chrome 10 103','Computer','192.168.10.233','2022-07-15 10:41:41',NULL,'Mac OS X','r55ogEoef3K57VUg','admin','0|0|0|内网IP|内网IP'),(33,'Chrome 10 103','Computer','192.168.10.233','2022-07-15 11:10:24',NULL,'Mac OS X','LifjKbHPUn0tbrc6','admin','0|0|0|内网IP|内网IP'),(34,'Chrome 10 103','Computer','192.168.10.233','2022-07-15 14:19:26',NULL,'Mac OS X','ruXBKw18wJttEVGL','admin','0|0|0|内网IP|内网IP'),(35,'Chrome 10 103','Computer','192.168.10.233','2022-07-15 16:52:32',NULL,'Mac OS X','i1AhkyxoSi9WPqAm','admin','0|0|0|内网IP|内网IP'),(36,'Chrome 10 103','Computer','192.168.10.233','2022-07-19 11:06:22',NULL,'Mac OS X','5HwfgLr3OCvEFHBL','admin','0|0|0|内网IP|内网IP'),(37,'Chrome 10 103','Computer','192.168.10.233','2022-07-19 11:21:38',NULL,'Mac OS X','MriN7mbqLRd4sWfX','admin','0|0|0|内网IP|内网IP'),(38,'Chrome 10 103','Computer','192.168.10.233','2022-07-19 11:30:00',NULL,'Mac OS X','uYWChA563mvUb7Dj','admin','0|0|0|内网IP|内网IP'),(39,'Chrome 10 103','Computer','192.168.10.233','2022-07-19 13:31:42',NULL,'Mac OS X','zhWDLoemgb9bp31k','admin','0|0|0|内网IP|内网IP'),(40,'Chrome 10 103','Computer','192.168.10.233','2022-07-19 13:32:44',NULL,'Mac OS X','z1ZKIJEePJrB947h','admin','0|0|0|内网IP|内网IP'),(41,'Chrome 10 103','Computer','192.168.10.233','2022-07-19 14:11:00',NULL,'Mac OS X','Yc0wQOius422uoLL','admin','0|0|0|内网IP|内网IP'),(42,'Chrome 10 103','Computer','192.168.10.233','2022-07-19 14:11:04',NULL,'Mac OS X','oAYoTJ94GPVZWLwt','admin','0|0|0|内网IP|内网IP'),(43,'Chrome 10 103','Computer','192.168.10.233','2022-07-19 17:32:14',NULL,'Mac OS X','YmNMrIDg8xIUpY7s','admin','0|0|0|内网IP|内网IP'),(44,'Chrome 10 103','Computer','192.168.10.233','2022-07-19 17:55:26',NULL,'Mac OS X','QNHpHk0FvcK2YixC','admin','0|0|0|内网IP|内网IP'),(45,'Chrome 10 103','Computer','192.168.10.233','2022-07-19 18:35:13',NULL,'Mac OS X','8SPbBFK0uZVux2Kb','admin','0|0|0|内网IP|内网IP'),(46,'Chrome 10 103','Computer','192.168.10.233','2022-07-19 20:04:37',NULL,'Mac OS X','TBccVVddx7ukkC6Q','admin','0|0|0|内网IP|内网IP'),(47,'Chrome 10 103','Computer','192.168.10.233','2022-07-19 20:08:31',NULL,'Mac OS X','gUvl6FYBx5gATPu8','admin','0|0|0|内网IP|内网IP'),(48,'Chrome 10 103','Computer','192.168.10.233','2022-07-20 15:36:16',NULL,'Mac OS X','LQdPtWEbwcqBzqLz','admin','0|0|0|内网IP|内网IP'),(49,'Chrome 10 103','Computer','192.168.10.233','2022-07-20 16:22:51',NULL,'Mac OS X','mn2EkXUYMugbkB4I','admin','0|0|0|内网IP|内网IP'),(50,'Chrome 10 103','Computer','192.168.10.233','2022-07-20 16:34:20',NULL,'Mac OS X','4WjN89X7LPWnFGK5','admin','0|0|0|内网IP|内网IP'),(51,'Chrome 10 103','Computer','192.168.10.233','2022-07-20 16:37:37',NULL,'Mac OS X','iay2fsrfh5LQNA03','admin','0|0|0|内网IP|内网IP'),(52,'Chrome 10 103','Computer','192.168.10.233','2022-07-20 16:48:43',NULL,'Mac OS X','32HrzlwgWr0XQkCB','admin','0|0|0|内网IP|内网IP'),(53,'Chrome 10 103','Computer','192.168.10.233','2022-07-20 17:03:27',NULL,'Mac OS X','CZKsK96rycSjkisH','admin','0|0|0|内网IP|内网IP'),(54,'Chrome 10 103','Computer','192.168.10.233','2022-07-20 17:04:50',NULL,'Mac OS X','s2CiwXM0lDM6RSjb','admin','0|0|0|内网IP|内网IP'),(55,'Chrome 10 103','Computer','192.168.10.233','2022-07-20 19:12:16',NULL,'Mac OS X','zQje6DMrc1LJ0uOn','admin','0|0|0|内网IP|内网IP'),(56,'Chrome 10 103','Computer','192.168.10.233','2022-07-20 19:17:31',NULL,'Mac OS X','oX0JJzDY4lwjIugS','admin','0|0|0|内网IP|内网IP'),(57,'Chrome 10 103','Computer','192.168.10.233','2022-07-20 19:33:49',NULL,'Mac OS X','vUIBCRelZbtmFejb','admin','0|0|0|内网IP|内网IP'),(58,'Chrome 10 103','Computer','172.30.0.2','2022-07-20 19:37:43',NULL,'Mac OS X','bHG1TuQ78BU5Icgz','admin','0|0|0|内网IP|内网IP'),(59,'Chrome 10 103','Computer','192.168.10.233','2022-07-22 17:00:28',NULL,'Mac OS X','09eZY7dJFTOHlMar','admin','0|0|0|内网IP|内网IP'),(60,'Chrome 10 103','Computer','192.168.10.233','2022-07-22 17:42:16',NULL,'Mac OS X','SQwlzxdDh5lvVruc','admin','0|0|0|内网IP|内网IP'),(61,'Chrome 10 103','Computer','192.168.10.233','2022-07-22 17:48:34',NULL,'Mac OS X','2YovBMHUNLVwC4Fq','admin','0|0|0|内网IP|内网IP'),(62,'Chrome 10 103','Computer','192.168.10.233','2022-07-22 17:54:38',NULL,'Mac OS X','I1RXkpKRAl9byuZM','admin','0|0|0|内网IP|内网IP'),(63,'Chrome 10 103','Computer','192.168.10.233','2022-07-22 18:04:05',NULL,'Mac OS X','Ez7Vvhr9r2xoS9ju','admin','0|0|0|内网IP|内网IP'),(64,'Chrome 10 103','Computer','192.168.10.233','2022-07-22 19:31:57',NULL,'Mac OS X','wzBepCYjuHUFJT1v','admin','0|0|0|内网IP|内网IP'),(65,'Chrome 10 103','Computer','192.168.10.233','2022-07-22 19:37:23',NULL,'Mac OS X','wyD1PEMQYKojz2Rh','admin','0|0|0|内网IP|内网IP');
/*!40000 ALTER TABLE `e_upms_login_log` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `e_upms_menu`
--

DROP TABLE IF EXISTS `e_upms_menu`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `e_upms_menu` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_by` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `create_time` datetime DEFAULT NULL,
  `update_by` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `code` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `icon` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `name` varchar(255) CHARACTER SET utf8 DEFAULT NULL,
  `param` varchar(2000) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `sort` int(11) DEFAULT NULL,
  `status` int(11) DEFAULT NULL,
  `type` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `value` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `parent_menu_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `UK95xpkppt33d2bka0g2d7rgwqt` (`code`),
  KEY `FK5mkgea183mm02v7ic1pdwxy5s` (`parent_menu_id`),
  CONSTRAINT `FK5mkgea183mm02v7ic1pdwxy5s` FOREIGN KEY (`parent_menu_id`) REFERENCES `e_upms_menu` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=99 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `e_upms_menu`
--

LOCK TABLES `e_upms_menu` WRITE;
/*!40000 ALTER TABLE `e_upms_menu` DISABLE KEYS */;
INSERT INTO `e_upms_menu` VALUES (1,NULL,'2022-07-11 20:41:07',NULL,NULL,'magic-api',NULL,'接口配置',NULL,50,1,'tpl','magic-api.ftl',NULL),(2,NULL,'2022-07-11 20:41:07',NULL,NULL,'magic-api-function',NULL,'函数',NULL,10,1,'button','ERUPT_MAGIC_FUNCTION',1),(3,NULL,'2022-07-11 20:41:07',NULL,NULL,'magic-api-datasource',NULL,'数据源',NULL,20,1,'button','ERUPT_MAGIC_DATASOURCE',1),(4,NULL,'2022-07-11 20:41:07',NULL,NULL,'magic-api-save',NULL,'保存',NULL,30,1,'button','ERUPT_MAGIC_SAVE',1),(5,NULL,'2022-07-11 20:41:07',NULL,NULL,'magic-api-view',NULL,'查看',NULL,40,1,'button','ERUPT_MAGIC_VIEW',1),(6,NULL,'2022-07-11 20:41:08',NULL,NULL,'magic-api-delete',NULL,'删除',NULL,50,1,'button','ERUPT_MAGIC_DELETE',1),(7,NULL,'2022-07-11 20:41:08',NULL,NULL,'magic-api-download',NULL,'导出',NULL,60,1,'button','ERUPT_MAGIC_DOWNLOAD',1),(8,NULL,'2022-07-11 20:41:08',NULL,NULL,'magic-api-upload',NULL,'上传',NULL,70,1,'button','ERUPT_MAGIC_UPLOAD',1),(9,NULL,'2022-07-11 20:41:08',NULL,NULL,'magic-api-push',NULL,'远程推送',NULL,80,1,'button','ERUPT_MAGIC_PUSH',1),(10,NULL,'2022-07-11 20:41:08',NULL,NULL,'magic-api-lock',NULL,'锁定',NULL,90,1,'button','ERUPT_MAGIC_LOCK',1),(11,NULL,'2022-07-11 20:41:08',NULL,NULL,'magic-api-unlock',NULL,'解锁',NULL,100,1,'button','ERUPT_MAGIC_UNLOCK',1),(12,NULL,'2022-07-11 20:41:08',NULL,NULL,'$manager','fa fa-cogs','系统管理',NULL,1,1,NULL,NULL,NULL),(13,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptMenu','','菜单管理',NULL,0,1,'tree','EruptMenu',12),(14,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptMenu@ADD',NULL,'新增',NULL,10,1,'button','EruptMenu@ADD',13),(15,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptMenu@EDIT',NULL,'修改',NULL,20,1,'button','EruptMenu@EDIT',13),(16,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptMenu@DELETE',NULL,'删除',NULL,30,1,'button','EruptMenu@DELETE',13),(17,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptMenu@VIEW_DETAIL',NULL,'详情',NULL,40,1,'button','EruptMenu@VIEW_DETAIL',13),(18,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptRole','','角色管理',NULL,10,1,'table','EruptRole',12),(19,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptRole@ADD',NULL,'新增',NULL,10,1,'button','EruptRole@ADD',18),(20,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptRole@EDIT',NULL,'修改',NULL,20,1,'button','EruptRole@EDIT',18),(21,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptRole@DELETE',NULL,'删除',NULL,30,1,'button','EruptRole@DELETE',18),(22,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptRole@VIEW_DETAIL',NULL,'详情',NULL,40,1,'button','EruptRole@VIEW_DETAIL',18),(23,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptOrg','','组织维护',NULL,20,1,'tree','EruptOrg',12),(24,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptOrg@ADD',NULL,'新增',NULL,10,1,'button','EruptOrg@ADD',23),(25,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptOrg@EDIT',NULL,'修改',NULL,20,1,'button','EruptOrg@EDIT',23),(26,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptOrg@DELETE',NULL,'删除',NULL,30,1,'button','EruptOrg@DELETE',23),(27,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptOrg@VIEW_DETAIL',NULL,'详情',NULL,40,1,'button','EruptOrg@VIEW_DETAIL',23),(28,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptPost','','岗位维护',NULL,30,1,'tree','EruptPost',12),(29,NULL,'2022-07-11 20:41:08',NULL,NULL,'EruptPost@ADD',NULL,'新增',NULL,10,1,'button','EruptPost@ADD',28),(30,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptPost@EDIT',NULL,'修改',NULL,20,1,'button','EruptPost@EDIT',28),(31,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptPost@DELETE',NULL,'删除',NULL,30,1,'button','EruptPost@DELETE',28),(32,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptPost@VIEW_DETAIL',NULL,'详情',NULL,40,1,'button','EruptPost@VIEW_DETAIL',28),(33,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptUser','','用户配置',NULL,40,1,'table','EruptUser',12),(34,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptUser@ADD',NULL,'新增',NULL,10,1,'button','EruptUser@ADD',33),(35,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptUser@EDIT',NULL,'修改',NULL,20,1,'button','EruptUser@EDIT',33),(36,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptUser@DELETE',NULL,'删除',NULL,30,1,'button','EruptUser@DELETE',33),(37,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptUser@VIEW_DETAIL',NULL,'详情',NULL,40,1,'button','EruptUser@VIEW_DETAIL',33),(38,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptDict','','数据字典',NULL,50,1,'table','EruptDict',12),(39,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptDict@ADD',NULL,'新增',NULL,10,1,'button','EruptDict@ADD',38),(40,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptDict@EDIT',NULL,'修改',NULL,20,1,'button','EruptDict@EDIT',38),(41,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptDict@DELETE',NULL,'删除',NULL,30,1,'button','EruptDict@DELETE',38),(42,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptDict@EXPORT',NULL,'导出',NULL,40,1,'button','EruptDict@EXPORT',38),(43,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptDict@VIEW_DETAIL',NULL,'详情',NULL,50,1,'button','EruptDict@VIEW_DETAIL',38),(44,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptDictItem','','字典项',NULL,60,2,'table','EruptDictItem',12),(45,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptDictItem@ADD',NULL,'新增',NULL,10,1,'button','EruptDictItem@ADD',44),(46,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptDictItem@EDIT',NULL,'修改',NULL,20,1,'button','EruptDictItem@EDIT',44),(47,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptDictItem@DELETE',NULL,'删除',NULL,30,1,'button','EruptDictItem@DELETE',44),(48,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptDictItem@EXPORT',NULL,'导出',NULL,40,1,'button','EruptDictItem@EXPORT',44),(49,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptDictItem@VIEW_DETAIL',NULL,'详情',NULL,50,1,'button','EruptDictItem@VIEW_DETAIL',44),(52,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptLoginLog','','登录日志',NULL,70,1,'table','EruptLoginLog',12),(53,NULL,'2022-07-11 20:41:09',NULL,NULL,'EruptLoginLog@EXPORT',NULL,'导出',NULL,10,1,'button','EruptLoginLog@EXPORT',52),(54,NULL,'2022-07-11 20:41:10',NULL,NULL,'EruptOperateLog','','操作日志',NULL,80,1,'table','EruptOperateLog',12),(55,'admin','2022-07-13 13:47:48','admin','2022-07-13 17:45:29','i2F2YcUN',NULL,'官网管理',NULL,110,1,'tree','website_manage',NULL),(63,NULL,'2022-07-13 17:45:29',NULL,NULL,'40kckugb',NULL,'新增',NULL,10,1,'button','website_manage@ADD',55),(64,NULL,'2022-07-13 17:45:29',NULL,NULL,'qmgq6pEj',NULL,'修改',NULL,20,1,'button','website_manage@EDIT',55),(65,NULL,'2022-07-13 17:45:29',NULL,NULL,'T8pnQkGV',NULL,'删除',NULL,30,1,'button','website_manage@DELETE',55),(66,NULL,'2022-07-13 17:45:29',NULL,NULL,'o7nqTSIJ',NULL,'导出',NULL,40,1,'button','website_manage@EXPORT',55),(67,NULL,'2022-07-13 17:45:29',NULL,NULL,'MrWnipjs',NULL,'导入',NULL,50,1,'button','website_manage@IMPORTABLE',55),(68,NULL,'2022-07-13 17:45:29',NULL,NULL,'1IlKDum1',NULL,'详情',NULL,60,1,'button','website_manage@VIEW_DETAIL',55),(69,'admin','2022-07-13 17:46:22','admin','2022-07-14 11:47:19','Kk5A1ruF',NULL,'博客管理',NULL,130,1,'tpl','websiteBlog',55),(83,'admin','2022-07-19 15:28:43','admin','2022-07-19 15:28:43','NbJm3E7k',NULL,'官网博客',NULL,140,2,'table','Blog',55),(84,NULL,'2022-07-19 15:28:43',NULL,NULL,'BWzFYZl9',NULL,'新增',NULL,10,1,'button','Blog@ADD',83),(85,NULL,'2022-07-19 15:28:43',NULL,NULL,'HWO3It4N',NULL,'修改',NULL,20,1,'button','Blog@EDIT',83),(86,NULL,'2022-07-19 15:28:43',NULL,NULL,'4DfVGqH5',NULL,'删除',NULL,30,1,'button','Blog@DELETE',83),(87,NULL,'2022-07-19 15:28:43',NULL,NULL,'Y3blVazx',NULL,'导出',NULL,40,1,'button','Blog@EXPORT',83),(88,NULL,'2022-07-19 15:28:43',NULL,NULL,'sYCz9FTP',NULL,'导入',NULL,50,1,'button','Blog@IMPORTABLE',83),(89,NULL,'2022-07-19 15:28:43',NULL,NULL,'YkgzjCDk',NULL,'详情',NULL,60,1,'button','Blog@VIEW_DETAIL',83),(90,NULL,'2022-07-19 19:49:13',NULL,NULL,'EruptOnline','','在线用户',NULL,65,1,'table','EruptOnline',12),(91,NULL,'2022-07-19 19:49:13',NULL,NULL,'EruptOnline@EXPORT',NULL,'导出',NULL,10,1,'button','EruptOnline@EXPORT',90),(92,'admin','2022-07-22 17:01:11','admin','2022-07-22 17:01:11','xJh1aHoA',NULL,'产品信息',NULL,150,1,'table','Product',55),(93,NULL,'2022-07-22 17:01:11',NULL,NULL,'OhgISRHM',NULL,'新增',NULL,10,1,'button','Product@ADD',92),(94,NULL,'2022-07-22 17:01:11',NULL,NULL,'RNpjqpOl',NULL,'修改',NULL,20,1,'button','Product@EDIT',92),(95,NULL,'2022-07-22 17:01:11',NULL,NULL,'Pmo90N65',NULL,'删除',NULL,30,1,'button','Product@DELETE',92),(96,NULL,'2022-07-22 17:01:12',NULL,NULL,'9ZTwBClg',NULL,'导出',NULL,40,1,'button','Product@EXPORT',92),(97,NULL,'2022-07-22 17:01:12',NULL,NULL,'P1LzprPv',NULL,'导入',NULL,50,1,'button','Product@IMPORTABLE',92),(98,NULL,'2022-07-22 17:01:12',NULL,NULL,'AcXdJOuC',NULL,'详情',NULL,60,1,'button','Product@VIEW_DETAIL',92);
/*!40000 ALTER TABLE `e_upms_menu` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `e_upms_operate_log`
--

DROP TABLE IF EXISTS `e_upms_operate_log`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `e_upms_operate_log` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `api_name` varchar(255) CHARACTER SET utf8 DEFAULT NULL,
  `create_time` datetime DEFAULT NULL,
  `error_info` longtext COLLATE utf8mb4_unicode_ci,
  `ip` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `operate_user` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `region` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `req_addr` varchar(4000) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `req_method` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `req_param` longtext COLLATE utf8mb4_unicode_ci,
  `status` bit(1) DEFAULT NULL,
  `total_time` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=69 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `e_upms_operate_log`
--

LOCK TABLES `e_upms_operate_log` WRITE;
/*!40000 ALTER TABLE `e_upms_operate_log` DISABLE KEYS */;
INSERT INTO `e_upms_operate_log` VALUES (1,'修改 | 用户配置','2022-07-12 19:29:44',NULL,'192.168.10.233','erupt','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptUser','PUT','{\"account\":\"admin\",\"name\":\"admin\",\"status\":true,\"isAdmin\":true,\"isMd5\":true,\"createTime\":\"2022-07-11 20:41:10\",\"id\":1}',_binary '',5193),(2,'修改 | 用户配置','2022-07-12 19:32:26',NULL,'192.168.10.233','erupt','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptUser','PUT','{\"account\":\"admin\",\"name\":\"admin\",\"status\":true,\"isAdmin\":true,\"isMd5\":true,\"createTime\":\"2022-07-11 20:41:10\",\"id\":1}',_binary '',6078),(3,'修改 | 用户配置','2022-07-12 19:35:49',NULL,'192.168.10.233','erupt','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptUser','PUT','{\"account\":\"admin\",\"name\":\"admin\",\"status\":true,\"isAdmin\":true,\"isMd5\":true,\"createTime\":\"2022-07-11 20:41:10\",\"id\":1}',_binary '',5229),(4,'新增 | 用户配置','2022-07-12 19:36:12',NULL,'192.168.10.233','erupt','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptUser','POST','{\"account\":\"test\",\"name\":\"test\",\"status\":true,\"isAdmin\":false,\"passwordA\":\"123456\",\"passwordB\":\"123456\",\"isMd5\":true}',_binary '',5143),(5,'修改 | 用户配置','2022-07-12 21:32:06',NULL,'192.168.10.233','erupt','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptUser','PUT','{\"account\":\"admin\",\"name\":\"admin\",\"status\":true,\"isAdmin\":true,\"isMd5\":true,\"createTime\":\"2022-07-11 20:41:10\",\"id\":1}',_binary '',5387),(6,'新增 | 角色管理','2022-07-12 21:35:15',NULL,'192.168.10.233','erupt','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptRole','POST','{\"code\":\"1\",\"name\":\"官网维护\",\"sort\":1,\"status\":true,\"menus\":[],\"users\":[]}',_binary '',5199),(7,'新增 | 用户配置','2022-07-12 21:36:12',NULL,'192.168.10.233','erupt','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptUser','POST','{\"account\":\"test1\",\"name\":\"test1\",\"status\":true,\"isAdmin\":false,\"isMd5\":true,\"roles\":[{\"id\":1}]}',_binary '',5136),(8,'新增 | 用户配置','2022-07-12 21:36:28',NULL,'192.168.10.233','erupt','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptUser','POST','{\"account\":\"test1\",\"name\":\"test1\",\"status\":true,\"isAdmin\":false,\"passwordA\":\"123456\",\"passwordB\":\"123456\",\"isMd5\":true,\"roles\":[{\"id\":1}]}',_binary '',5230),(9,'新增 | 数据字典','2022-07-13 11:42:53',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptDict','POST','{\"code\":\"java\",\"name\":\"java\",\"remark\":\"测试字典能力\"}',_binary '',5348),(10,'导出Excel | 数据字典','2022-07-13 11:43:24',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/excel/export/EruptDict','POST','[]',_binary '',10131),(11,'删除 | 菜单管理','2022-07-13 11:45:13',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu/51','DELETE',NULL,_binary '',5517),(12,'删除 | 菜单管理','2022-07-13 11:45:24',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu/50','DELETE',NULL,_binary '',5408),(13,'新增 | 菜单管理','2022-07-13 13:47:53',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu','POST','{\"name\":\"官网\",\"status\":\"1\",\"type\":\"tpl\",\"value\":\"webiste.html\",\"sort\":110}',_binary '',5247),(14,'修改 | 菜单管理','2022-07-13 14:32:08',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu','PUT','{\"name\":\"官网\",\"status\":\"1\",\"type\":\"tpl\",\"value\":\"websiteBlog\",\"sort\":110,\"code\":\"i2F2YcUN\",\"id\":55}',_binary '',5402),(15,'修改 | 角色管理','2022-07-13 14:33:42',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptRole','PUT','{\"code\":\"1\",\"name\":\"官网维护\",\"sort\":1,\"status\":true,\"menus\":[],\"users\":[{\"id\":2},{\"id\":\"1\"}],\"updateUser\":{\"id\":1,\"name\":\"admin\"},\"updateTime\":\"2022-07-12 21:35:10\",\"id\":1}',_binary '',5372),(16,'修改 | 角色管理','2022-07-13 14:38:40',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptRole','PUT','{\"code\":\"1\",\"name\":\"官网维护\",\"sort\":1,\"status\":true,\"menus\":[{\"id\":\"55\"}],\"users\":[{\"id\":1},{\"id\":2}],\"updateUser\":{\"id\":1,\"name\":\"admin\"},\"updateTime\":\"2022-07-13 14:33:37\",\"id\":1}',_binary '',5613),(17,'新增 | 菜单管理','2022-07-13 17:44:33',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu','POST','{\"name\":\"官网博客（中文）\",\"status\":\"1\",\"parentMenu\":{\"id\":\"55\",\"name\":\"官网\"},\"type\":\"table\",\"value\":\"website_blog\",\"sort\":120}',_binary '',5667),(18,'修改 | 菜单管理','2022-07-13 17:45:18',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu','PUT','{\"name\":\"官网管理\",\"status\":\"1\",\"type\":\"tree\",\"sort\":110,\"code\":\"i2F2YcUN\",\"id\":55}',_binary '',5311),(19,'修改 | 菜单管理','2022-07-13 17:45:34',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu','PUT','{\"name\":\"官网管理\",\"status\":\"1\",\"type\":\"tree\",\"value\":\"website_manage\",\"sort\":110,\"code\":\"i2F2YcUN\",\"id\":55}',_binary '',5605),(20,'新增 | 菜单管理','2022-07-13 17:46:27',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu','POST','{\"name\":\"自定义管理页面\",\"status\":\"1\",\"parentMenu\":{\"id\":\"55\",\"name\":\"官网管理\"},\"type\":\"tpl\",\"value\":\"websiteBlog\",\"sort\":130}',_binary '',5302),(21,'修改 | 菜单管理','2022-07-13 17:49:36',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu','PUT','{\"name\":\"官网博客（中文）\",\"status\":\"1\",\"parentMenu\":{\"id\":55,\"name\":\"官网管理\"},\"type\":\"table\",\"value\":\"Blog\",\"sort\":120,\"code\":\"bBGl3oxp\",\"id\":56}',_binary '',5537),(22,'新增 | 官网博客（中文）','2022-07-13 19:36:30',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','POST','{\"pic\":\"/2022-07-13/NCLwtCHrbOmA.png\",\"title\":\"测试标题\",\"top\":false,\"publish\":false,\"remark\":\"备注备注1111\"}',_binary '',5182),(23,'修改 | 菜单管理','2022-07-14 11:47:24',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu','PUT','{\"name\":\"博客管理\",\"status\":\"1\",\"parentMenu\":{\"id\":55,\"name\":\"官网管理\"},\"type\":\"tpl\",\"value\":\"websiteBlog\",\"sort\":130,\"code\":\"Kk5A1ruF\",\"id\":69}',_binary '',5508),(24,'删除 | 菜单管理','2022-07-14 14:38:25',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu/75','DELETE',NULL,_binary '',5489),(25,'删除 | 菜单管理','2022-07-14 14:38:34',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu/74','DELETE',NULL,_binary '',5463),(26,'删除 | 菜单管理','2022-07-14 14:38:44',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu/73','DELETE',NULL,_binary '',5580),(27,'删除 | 菜单管理','2022-07-14 14:39:01',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu/70','DELETE',NULL,_binary '',5314),(28,'删除 | 菜单管理','2022-07-14 14:39:11',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu/71','DELETE',NULL,_binary '',5323),(29,'删除 | 菜单管理','2022-07-14 14:39:28',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu/72','DELETE',NULL,_binary '',5399),(30,'删除 | 菜单管理','2022-07-14 14:39:38',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu/56','DELETE',NULL,_binary '',5363),(31,'新增 | 菜单管理','2022-07-14 14:41:39',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu','POST','{\"name\":\"官网博客\",\"status\":\"1\",\"parentMenu\":{\"id\":55,\"name\":\"官网管理\"},\"type\":\"table\",\"value\":\"Blog\",\"sort\":140,\"icon\":\"fa fa-file-text-o\"}',_binary '',5596),(32,'新增 | 官网博客','2022-07-14 15:14:57',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','POST','{\"pic\":\"/2022-07-14/tQFrxnoKGuRO.png\",\"title\":\"a a\",\"description\":\"123\",\"publish\":true,\"content\":\"123\"}',_binary '',5224),(33,'删除 | 官网博客','2022-07-14 15:18:37',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog/2','DELETE',NULL,_binary '',5384),(34,'删除 | 官网博客','2022-07-14 15:18:42',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog/2','DELETE',NULL,_binary '',5644),(35,'新增 | 官网博客','2022-07-14 15:19:03',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','POST','{\"pic\":\"/2022-07-14/YQgGJLfsIvCB.png\",\"title\":\"2\",\"description\":\"qwe\",\"publish\":true,\"content\":\"qwe\"}',_binary '',5174),(36,'新增 | 官网博客','2022-07-14 15:50:11',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','POST','{\"pic\":\"/2022-07-14/bgTBSNvhycWS.png\",\"title\":\"123\",\"description\":\"123aaa\",\"publish\":true,\"content\":\"asdfa\"}',_binary '',5225),(37,'新增 | 官网博客','2022-07-14 18:56:56',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','POST','{\"pic\":\"1\",\"title\":\"1\",\"author\":\"1\",\"description\":\"1\",\"publish\":true,\"content\":\"1\"}',_binary '',5312),(38,'新增 | 官网博客','2022-07-19 11:16:19',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','POST','{\"pic\":\"https://www-cdn.nebula-graph.com.cn/nebula-blog/DockerImage01.png\",\"title\":\"前端 Docker 镜像体积优化\",\"author\":\"Jerry\",\"description\":\"本文主要来讲述下开源的分布式图数据库 Nebula Graph 是如何将 Docker 应用到可视化界面中，并将镜像体积从 1.3G 减到 0.3G 。\",\"publish\":false,\"content\":\"如果 2019 年技术圈有十大流行词，**容器化**肯定占有一席之地，随着 Docker 的风靡，前端领域应用到 Docker 的场景也越来越多，本文主要来讲述下开源的分布式图数据库 Nebula Graph 是如何将 Docker 应用到可视化界面中。\\n\\n## 为什么要用 Docker\\n\\n对于前端日常开发而言，有时也会用到 Docker，结合到 Nebula Graph Studio（分布式图数据库 Nebula Graph 的图形界面工具）使用 Docker 主要基于以下考虑:\\n\\n- **统一运行环境**：我们的工具背后有好几个服务组合在一起，诸如不同技术栈的现有服务，纯前端的静态资源。\\n- **用户使用成本低**：目前云服务还在开发中，想让用户对服务组合无感，能直接在本地一键启动应用并使用。\\n- **快速部署**：团队本就提供有 [Nebula镜像版本](https://github.com/vesoft-inc/nebula-docker-compose) 实践，给了我们前端一些参考和借鉴。\\n\\n## Docker 镜像的构建\\n\\n既然要使用 Docker 来承载我们的应用，就得将项目进行镜像构建。与所有 build 镜像类似，需要配置一份命名为[Dockerfile ](https://docs.docker.com/engine/reference/builder/)的文件，文件是一些步骤的描述，简单来说就是把项目复制到镜像里，并设置好启动方式：\\n\\n```shell\\n# 选择基础镜像\\nFROM node:10\\n# 设置工作目录\\nWORKDIR /nebula-web-console\\n# 把当前项目内容拷贝到镜像中的 /nebula-web-console 目录下\\nADD . /nebula-web-console\\n# 在镜像中下载前端依赖\\nRUN npm install\\n# 执行构建\\nRUN npm run build\\nEXPOSE 7001\\n# 镜像启动时执行的部署命令\\nCMD [\\\"npm\\\", \\\"run\\\", \\\"docker-start\\\"]\\n```\\n\\n## Docker 镜像体积优化\\n\\n如果按照上述的配置文件来构建 Docker 镜像，以我们的项目为例，将会生成一个体积约为 1.3GB 的镜像，这个看起来有点吓人，因为即使在网速快的用户电脑光下载镜像也需要等待不少时间，这是不能接受的。\\n\\n在调研了相应的资料后，了解到可以从以下几个方面缩小 Docker 镜像体积进行优化：\\n\\n### 基础镜像源的选择\\n\\n所谓基础镜像源，就是我们在进行构建步骤时，选择的一个基础环境（如上 `node:10` )，通过查看 [Dockerhub](https://hub.docker.com/_/node) 上有关 Node.js 的基础环境镜像时，我们会发现有**多个版本**，虽然都是 Node.js 相关基础镜像，但不同版本，他们除了 Node.js 版本不同外，在**内部集成的环境也不一样**，例如带有 [alpine](https://yeasy.gitbooks.io/docker_practice/cases/os/alpine.html) 的版本，相当于是一个比较精巧的 Linux 系统镜像，在此版本运行的容器中会发现不存在我们常规系统中所附带的工具，比如 bash、curl 等，由此来缩小体积。\\n\\n根据项目实际需要，当我把基础镜像换为 [alpine](https://yeasy.gitbooks.io/docker_practice/cases/os/alpine.html) 版本后，再次进行构建，此时镜像体积已大幅度减小，从 1.3GB 直降为 500+MB，体积优化效果明显，所以当你发现自己构建的镜像体积过大时，可以**考虑从更换基础镜像源的方式**来着手，看看是否使用了过于臃肿的镜像源。\\n\\n### Multi-stage 构建镜像\\n\\n所谓 [multi-stage](https://docs.docker.com/develop/develop-images/multistage-build/) 即是 Docker 镜像构建的时候采取的策略，详细可点击链接提供的资料。\\n\\n#### Docker 构建规则\\n\\n简言之就是利用 Docker 构建提供的规则：Dockerfile 的操作都会增加一个所谓镜像的“层”，每一层都会增加镜像体积，通过采用多步骤策略，每一步骤包含具有相同意义的一系列操作（例如构建，部署），步骤与步骤之间通过产物镜像引用的方式，由此来缩减最终构建镜像所需要的层数，具体操作比如：\\n\\n```shell\\n# 设置第一步骤产生的镜像，并命名为builder\\nFROM node:10-alpine as builder\\nWORKDIR /nebula-web-console\\n# 复制当前项目内容至镜像中\\nADD . /nebula-web-console\\n# 进行相应的构建\\nRUN npm install\\nRUN npm run build\\n....\\n\\n# 进行第二步骤构建\\nFROM node:10-alpine\\nWORKDIR /nebula-web-console\\n# 复制第一步构建镜像的产物内容至当前镜像，只用到了一层镜像层从而节约了之前构建步骤的镜像层数\\nCOPY --from=builder . /nebula-web-console\\nCMD [\\\"npm\\\", \\\"run\\\", \\\"docker-start\\\"]\\n\\n```\\n\\n### .dockerignore\\n\\n类似我们熟悉的 `.gitignore` ，就是当我们在进行 `COPY` 或 `ADD` 文件复制操作时，将不必要的文件忽略掉（诸如文档文件、git文件、node_modules以及一些非生成必要文件等），从而减小镜像体积，更详细内容可参考文档连接：[.dockerignore](https://docs.docker.com/engine/reference/builder/#dockerignore-file)。\\n\\n### 操作合并\\n\\n基于上述提到在 Dockerfile 构建镜像的过程做，每一个操作都会在前一步镜像基础上增加一“层”，可以利用 `&` 来合并多个操作，减少层数，比如：\\n```shell\\n# 以下两个操作分别代表两层\\nRUN npm install\\nRUN npm run build\\n```\\n改为：\\n```shell\\n# 使用 & 后变了为一层\\nRUN npm install && npm run build\\n```\\n由此我们减少了层数的增加，即减少了镜像的体积。同时，在构建镜像的过程中，我们也可以通过在达到相同目的的前提下，尽量减少不必要的操作来减少“层数”的添加。\\n\\n### 前端常规性体积优化\\n\\n- 压缩丑化代码，移除源码\\n     此操作可以放在构建步骤阶段，这样会进一步缩小镜像的文件体积。\\n- node_modules 只下载生产环境需要的代码\\n     此操作可以放在部署阶段，只下载生产环境所需要的第三方依赖代码: `npm install --production` 。\\n- 公共资源放在CDN\\n     如果镜像被期待运行在联网环境，可以考虑将一些体积相比较大的公共文件（图片、第三方库等）放在CDN服务 器上，将部分资源剥离出去，也会进一步缩小体积。\\n- ...\\n\\n以上只作为一个线索参考，更多前端常规的优化步骤，都可以迁移至镜像中进行，毕竟和我们本地开发一样，镜像构建也是一个运行代码的环境嘛。\\n\\n## 小结\\n\\n以上便是我在此次使用 Docker 镜像来运行我们 [Nebula Studio](Nebula/blob/master/README.md) 所用到的一些优化镜像体积的方法，希望能给需要的人一些帮助和参考，可能还有一些认识不准确的地方，欢迎指出，同样欢迎你来试用 Nebula Graph Studio：[Nebula](Nebula) \\n\"}',_binary '',5276),(39,'删除 | 官网博客','2022-07-19 11:41:56',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog/2','DELETE',NULL,_binary '',5366),(40,'删除 | 官网博客','2022-07-19 11:48:44',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog/8','DELETE',NULL,_binary '',5204),(41,'删除 | 官网博客','2022-07-19 11:49:37',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog/7','DELETE',NULL,_binary '',5238),(42,'新增 | 官网博客','2022-07-19 12:06:55',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','POST','{\"pic\":\"https://www-cdn.nebula-graph.com.cn/nebula-blog/auto01.jpeg\",\"title\":\"Nebula Graph 使用 GitHub Action 的自动化实践\",\"author\":\"Yee\",\"description\":\"在讲 Action 实践之前还需先讲下 Nebula Graph 的需求：首要目标比较明确就是自动化测试，分为单元测试和集成测试，顺带再解决一下 PM 小姐姐的发布需求，构建起来了第一版的 CI/CD 流程。\",\"publish\":true,\"content\":\"\\n## 缘起\\n\\nNebula Graph 最早的自动化测试是使用搭建在 Azure 上的 [Jenkins](https://jenkins.io/zh/)，配合着 GitHub 的 Webhook 实现的，在用户提交 Pull Request 时，加个 `ready-for-testing` 的 label 再评论一句 `Jenkins go` 就可以自动的运行相应的 UT 测试，效果如下：\\n\\n![Jenkins](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto02.png)\\n\\n因为是租用的 Azure 的云主机，加上 nebula 的编译要求的机器配置较高，而且任务的触发主要集中在白天。所以上述的方案性价比较低，从去年团队就在考虑寻找替代的方案，准备下线 Azure 上的测试机，并且还要能提供多环境的测试方案。\\n\\n调研了一圈现有的产品主要有：\\n1. TravisCI\\n1. CircleCI\\n1. Azure Pipeline\\n1. Jenkins on k8s（自建）\\n\\n虽然上面的产品对开源项目有些限制，但整体都还算比较友好。\\n\\n鉴于之前 GitLab CI 的使用经验，体会到如果能跟 GitHub 深度集成那当然是首选。所谓“深度”表示可以共享 GitHub 的整个开源的生态以及完美的 API 调用（后话）。恰巧 2019，GitHub Action 2.0 横空出世，Nebula Graph 便勇敢的入了坑。\\n\\n这里简单概述一下我们在使用 GitHub Action 时体会到的优点：\\n1. 免费。开源项目可以免费使用 Action 的所有功能，而且机器[配置较高](https://help.github.com/en/actions/reference/virtual-environments-for-github-hosted-runners#supported-runners-and-hardware-resources)。\\n1. 开源生态好。在整个 CI 的流程里，可以直接使用 GitHub 上的所有开源的 Action，哪怕就是没有满足需求的 Action，自己上手写也不是很麻烦，而且还支持 docker 定制，用 bash 就可以完成一个专属的 Action。\\n1. 支持多种系统。Windows、macOS 和 Linux 都可以一键使用，跨平台简单方便。\\n1. 可跟 GitHub 的 API 互动。通过 `GITHUB_TOKEN` 可以直接访问 [GitHub API V3](https://developer.github.com/v3/)，想上传文件，检查 PR 状态，使用 curl 命令即可完成。\\n1. 自托管。只要提供 workflow 的描述文件，将其放置到 `.github/workflows/` 目录下，每次提交便会自动触发执行新的 action run。\\n1. Workflow 描述文件改为 YAML 格式。目前的描述方式要比 Action 1.0 中的 workflow 文件更加简洁易读。\\n\\n下面在讲实践之前还是要先讲讲 Nebula Graph 的需求：首要目标比较明确就是自动化测试。\\n\\n作为数据库产品，测试怎么强调也不为过。Nebula Graph 的测试主要分单元测试和集成测试。用 GitHub Action 其实主要瞄准的是单元测试，然后再给集成测试做些准备，比如 docker 镜像构建和安装程序打包。顺带再解决一下 PM 小姐姐的发布需求，就整个构建起来了第一版的 CI/CD 流程。\\n\\n## PR 测试\\n\\nNebula Graph 作为托管在 GitHub 上的开源项目，首先要解决的测试问题就是当贡献者提交了 PR 请求后，如何才能快速地进行变更验证？主要有以下几个方面。\\n\\n1. 符不符合编码规范；\\n1. 能不能在不同系统上都编译通过；\\n1. 单测有没有失败；\\n1. 代码覆盖率有没有下降等。\\n\\n只有上述的要求全部满足并且有至少两位 reviewer 的同意，变更才能进入主干分支。\\n\\n借助于 cpplint 或者 clang-format 等开源工具可以比较简单地实现要求 1，如果此要求未通过验证，后面的步骤就自动跳过，不再继续执行。\\n\\n对于要求 2，我们希望能同时在目前支持的几个系统上运行 Nebula 源码的编译验证。那么像之前在物理机上直接构建的方式就不再可取，毕竟一台物理机的价格已经高昂，何况一台还不足够。为了保证编译环境的一致性，还要尽可能的减少机器的性能损失，最终采用了 docker 的容器化构建方式。再借助 Action 的 [matrix 运行策略](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idstrategymatrix)和对 [docker 的支持](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idcontainer)，还算顺利地将整个流程走通。\\n\\n![action-workflow](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto03.svg)\\n\\n运行的大概流程如上图所示，在 [vesoft-inc/nebula-dev-docker](https://github.com/vesoft-inc/nebula-dev-docker) 项目中维护 nebula 编译环境的 docker 镜像，当编译器或者 thirdparty 依赖升级变更时，自动触发 docker hub 的 Build 任务（见下图）。当新的 Pull Request 提交以后，Action 便会被触发开始拉取最新的编译环境镜像，执行编译。\\n\\n![build-activity](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto04.png)\\n\\n针对 PR 的 workflow 完整描述见文件 [pull_request.yaml](https://github.com/vesoft-inc/nebula/blob/master/.github/workflows/pull_request.yaml)。同时，考虑到并不是每个人提交的 PR 都需要立即运行 CI 测试，且自建的机器资源有限，对 CI 的触发做了如下限制：\\n\\n1. 只有 lint 校验通过的 PR 才会将后续的 job 下发到自建的 runner，lint 的任务比较轻量，可以使用 GitHub Action 托管的机器来执行，无需占用线下的资源。\\n1. 只有添加了 `ready-for-testing`  label 的 PR 才会触发 action 的执行，而 label 的添加有权限的控制。进一步优化 runner 被随意触发的情况。对 label 的限制如下所示：\\n\\n```yaml\\njobs:\\n  lint:\\n    name: cpplint\\n    if: contains(join(toJson(github.event.pull_request.labels.*.name)), \'ready-for-testing\')\\n```\\n\\n在 PR 中执行完成后的效果如下所示：\\n\\n![pr-workflow-result](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto05.png)\\n\\nCode Coverage 的说明见博文：[图数据库 Nebula Graph 的代码变更测试覆盖率实践](https://nebula-graph.io/cn/posts/integrate-codecov-test-coverage-with-nebula-graph/)。\\n\\n## Nightly 构建\\n\\n在 Nebula Graph 的集成测试框架中，希望能够在每天晚上对 codebase 中的代码全量跑一遍所有的测试用例。同时有些新的特性，有时也希望能快速地打包交给用户体验使用。这就需要 CI 系统能在每天给出当日代码的 docker 镜像和 rpm/deb 安装包。\\n\\nGitHub Action 被触发的事件类型除了 pull_request，还可以执行 [schedule](https://help.github.com/en/actions/reference/events-that-trigger-workflows#scheduled-events-schedule) 类型。schedule 类型的事件可以像 crontab 一样，让用户指定任何重复任务的触发时间，比如每天凌晨两点执行任务如下所示：\\n\\n```yaml\\non:\\n  schedule:\\n    - cron: \'0 18 * * *\'\\n```\\n\\n因为 GitHub 采用的是 UTC 时间，所以东八区的凌晨 2 点，就对应到 UTC 的前日 18 时。\\n\\n### docker\\n\\n每日构建的 docker 镜像需要 push 到 docker hub 上，并打上 nightly 的标签，集成测试的 k8s 集群，将 image 的拉取策略设置为 Always，每日触发便能滚动升级到当日最新进行测试。因为当日的问题目前都会尽量当日解决，便没有再给 nightly 的镜像再额外打一个日期的 tag。对应的 action 部分如下所示：\\n\\n```yaml\\n      - name: Build image\\n        env:\\n          IMAGE_NAME: ${{ secrets.DOCKER_USERNAME }}/nebula-${{ matrix.service }}:nightly\\n        run: |\\n          docker build -t ${IMAGE_NAME} -f docker/Dockerfile.${{ matrix.service }} .\\n          docker push ${IMAGE_NAME}\\n        shell: bash\\n```\\n\\n### package\\n\\nGitHub Action 提供了 [artifacts](https://help.github.com/en/actions/configuring-and-managing-workflows/persisting-workflow-data-using-artifacts) 的功能，可以让用户持久化 workflow 运行过程中的数据，这些数据可以保留 90 天。对于 nightly 版本安装包的存储而言，已经绰绰有余。利用官方提供的 `actions/upload-artifact@v1`  action，可以方便的将指定目录下的文件上传到 artifacts。最后 nightly 版本的 nebula 的安装包如下图所示。\\n\\n![package](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto06.png)\\n\\n上述完整的 workflow 文件见 [package.yaml](https://github.com/vesoft-inc/nebula/blob/master/.github/workflows/package.yaml)\\n\\n## 分支发布\\n\\n为了更好地维护每个发布的版本和进行 bugfix，Nebula Graph 采用分支发布的方式。即每次发布之前进行 code freeze，并创建新的 release 分支，在 release 分支上只接受 bugfix，而不进行 feature 的开发。bugfix 还是会在开发分支上提交，最后 cherrypick 到 release 分支。\\n\\n在每次 release 时，除了 source 外，我们希望能把安装包也追加到 assets 中方便用户直接下载。如果每次都手工上传，既容易出错，也非常耗时。这就比较适合 Action 来自动化这块的工作，而且，打包和上传都走 GitHub 内部网络，速度更快。\\n\\n在安装包编译好后，通过 curl 命令直接调用 GitHub 的 API，就能上传到 assets 中，[具体脚本](https://github.com/vesoft-inc/nebula/blob/master/ci/scripts/upload-github-release-asset.sh)内容如下所示：\\n\\n```bash\\ncurl --silent \\\\\\n     --request POST \\\\\\n     --url \\\"$upload_url?name=$filename\\\" \\\\\\n     --header \\\"authorization: Bearer $github_token\\\" \\\\\\n     --header \\\"content-type: $content_type\\\" \\\\\\n     --data-binary @\\\"$filepath\\\"\\n```\\n\\n同时，为了安全起见，在每次的安装包发布时，希望可以计算安装包的 checksum 值，并将其一同上传到 assets 中，以便用户下载后进行完整性校验。具体步骤如下所示：\\n\\n```yaml\\njobs:\\n  package:\\n    name: package and upload release assets\\n    runs-on: ubuntu-latest\\n    strategy:\\n      matrix:\\n        os:\\n          - ubuntu1604\\n          - ubuntu1804\\n          - centos6\\n          - centos7\\n    container:\\n      image: vesoft/nebula-dev:${{ matrix.os }}\\n    steps:\\n      - uses: actions/checkout@v1\\n      - name: package\\n        run: ./package/package.sh\\n      - name: vars\\n        id: vars\\n        env:\\n          CPACK_OUTPUT_DIR: build/cpack_output\\n          SHA_EXT: sha256sum.txt\\n        run: |\\n          tag=$(echo ${{ github.ref }} | rev | cut -d/ -f1 | rev)\\n          cd $CPACK_OUTPUT_DIR\\n          filename=$(find . -type f \\\\( -iname \\\\*.deb -o -iname \\\\*.rpm \\\\) -exec basename {} \\\\;)\\n          sha256sum $filename > $filename.$SHA_EXT\\n          echo \\\"::set-output name=tag::$tag\\\"\\n          echo \\\"::set-output name=filepath::$CPACK_OUTPUT_DIR/$filename\\\"\\n          echo \\\"::set-output name=shafilepath::$CPACK_OUTPUT_DIR/$filename.$SHA_EXT\\\"\\n        shell: bash\\n      - name: upload release asset\\n        run: |\\n          ./ci/scripts/upload-github-release-asset.sh github_token=${{ secrets.GITHUB_TOKEN }} repo=${{ github.repository }} tag=${{ steps.vars.outputs.tag }} filepath=${{ steps.vars.outputs.filepath }}\\n          ./ci/scripts/upload-github-release-asset.sh github_token=${{ secrets.GITHUB_TOKEN }} repo=${{ github.repository }} tag=${{ steps.vars.outputs.tag }} filepath=${{ steps.vars.outputs.shafilepath }}\\n```\\n\\n上述完整的 workflow 文件见 [release.yaml](https://github.com/vesoft-inc/nebula/blob/master/.github/workflows/release.yaml)。\\n\\n## 命令\\n\\nGitHub Action 为 workflow 提供了一些[命令](https://help.github.com/en/actions/reference/workflow-commands-for-github-actions)方便在 shell 中进行调用，来更精细地控制和调试每个步骤的执行。常用的命令如下：\\n\\n### set-output\\n\\n有时在 job 的 steps 之间需要传递一些结果，这时就可以通过 `echo \\\"::set-output name=output_name::output_value\\\"` 的命令形式将想要输出的 `output_value` 值设置到 `output_name` 变量中。\\n\\n在接下来的 step 中，可以通过 `${{ steps.step_id.outputs.output_name }}` 的方式引用上述的输出值。\\n\\n上节中上传 asset 的 job 中就使用了上述的方式来传递文件名称。一个步骤可以通过多次执行上述命令来设置多个输出。\\n\\n### set-env\\n\\n同 `set-output` 一样，可以为后续的步骤设置环境变量。语法： `echo \\\"::set-env name={name}::{value}\\\"` 。\\n\\n### add-path\\n\\n将某路径加入到 `PATH` 变量中，为后续步骤使用。语法： `echo \\\"::add-path::{path}\\\"` 。\\n\\n## Self-Hosted Runner\\n\\n除了 GitHub 官方托管的 runner 之外，Action 还允许使用线下自己的机器作为 Runner 来跑 Action 的 job。在机器上安装好 Action Runner 之后，按照[教程](https://help.github.com/en/actions/hosting-your-own-runners/adding-self-hosted-runners)，将其注册到项目后，在 workflow 文件中通过配置 `runs-on: self-hosted` 即可使用。\\n\\nself-hosted 的机器可以打上不同的 label，这样便可以通过[不同的标签](https://help.github.com/en/actions/hosting-your-own-runners/using-labels-with-self-hosted-runners)来将任务分发到特定的机器上。比如线下的机器安装有不同的操作系统，那么 job 就可以根据 `runs-on` 的 label [在特定的机器](https://help.github.com/en/actions/hosting-your-own-runners/using-self-hosted-runners-in-a-workflow)上运行。 `self-hosted` 也是一个特定的标签。\\n\\n![self-hosted-runner-label](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto07.png)\\n\\n### 安全\\n\\nGitHub 官方是不推荐开源项目使用 Self-Hosted 的 runner 的，原因是任何人都可以通过提交 PR 的方式，让 runner 的机器运行危险的代码对其所在的环境进行攻击。\\n\\n但是 Nebula Graph 的编译需要的存储空间较大，且 GitHub 只能提供 2 核的环境来编译，不得已还是选择了自建 Runner。考虑到安全的因素，进行了如下方面的安全加固：\\n\\n#### 虚拟机部署\\n\\n所有注册到 GitHub Action 的 runner 都是采用虚拟机部署，跟宿主机做好第一层的隔离，也更方便对每个虚拟机做资源分配。一台高配置的宿主机可以分配多个虚拟机让 runner 来并行地跑所有收到的任务。\\n\\n如果虚拟机出了问题，可以方便地进行环境复原的操作。\\n\\n#### 网络隔离\\n\\n将所有 runner 所在的虚拟机隔离在办公网络之外，使其无法直接访问公司内部资源。即便有人通过 PR 提交了恶意代码，也让其无法访问公司内部网络，造成进一步的攻击。\\n\\n#### Action 选择\\n\\n尽量选择大厂和官方发布的 action，如果是使用个人开发者的作品，最好能检视一下其具体实现代码，免得出现网上爆出来的[泄漏隐私密钥](https://julienrenaux.fr/2019/12/20/github-actions-security-risk/)等事情发生。\\n\\n比如 GitHub 官方维护的 action 列表：[https://github.com/actions](https://github.com/actions)。\\n\\n#### 私钥校验\\n\\nGitHub Action 会自动校验 PR 中是否使用了一些私钥，除却 `GITHUB_TOKEN` 之外的其他私钥（通过 `${{ secrets.MY_TOKENS }}` 形式引用）均是不可以在 PR 事件触发的相关任务中使用，以防用户通过 PR 的方式私自打印输出窃取密钥。\\n\\n### 环境搭建与清理\\n\\n对于自建的 runner，在不同任务（job）之间做文件共享是方便的，但是最后不要忘记每次在整个 action 执行结束后，清理产生的中间文件，不然这些文件有可能会影响接下来的任务执行和不断地占用磁盘空间。\\n\\n```yaml\\n      - name: Cleanup\\n        if: always()\\n        run: rm -rf build\\n```\\n\\n将 step 的运行条件设置为 `always()` 确保每次任务都要执行该步骤，即便中途出错。\\n\\n### 基于 Docker 的 Matrix 并行构建\\n\\n因为 Nebula Graph 需要在不同的系统上做编译验证，在构建方式上采用了容器的方案，原因是构建时不同环境的隔离简单方便，GitHub Action 可以原生支持基于 docker 的任务。\\n\\nAction 支持 matrix 策略运行任务的方式，类似于 TravisCI 的 [build matrix](https://docs.travis-ci.com/user/build-matrix/)。通过配置不同系统和编译器的组合，我们可以方便地设置在每个系统下使用 `gcc` 和 `clang` 来同时编译 nebula 的源码，如下所示：\\n\\n```yaml\\njobs:\\n  build:\\n    name: build\\n    runs-on: ubuntu-latest\\n    strategy:\\n      fail-fast: false\\n      matrix:\\n        os:\\n          - centos6\\n          - centos7\\n          - ubuntu1604\\n          - ubuntu1804\\n        compiler:\\n          - gcc-9.2\\n          - clang-9\\n        exclude:\\n          - os: centos7\\n            compiler: clang-9\\n```\\n\\n上述的 strategy 会生成 8 个并行的任务（4 os x 2 compiler），每个任务都是（os, compiler）的一个组合。这种类似矩阵的表达方式，可以极大的减少不同纬度上的任务组合的定义。\\n\\n如果想排除 matrix 中的某个组合，只要将组合的值配置到 `exclude` 选项下面即可。如果想在任务中访问 matrix 中的值，也只要通过类似 `${{ matrix.os }}` 获取上下文变量值的方式拿到。这些方式让你定制自己的任务时都变得十分方便。\\n\\n#### 运行时容器\\n\\n我们可以为每个任务指定运行时的一个容器环境，这样该任务下的所有步骤（steps）都会在容器的内部环境中执行。相较于在每个步骤中都套用 docker 命令要简洁明了。\\n\\n```yaml\\n    container:\\n      image: vesoft/nebula-dev:${{ matrix.os }}\\n      env:\\n        CCACHE_DIR: /tmp/ccache/${{ matrix.os }}-${{ matrix.compiler }}\\n```\\n\\n对容器的配置，像在 docker compose 中配置 service 一样，可以指定 image/env/ports/volumes/options 等等[参数](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idcontainer)。在 self-hosted 的 runner 中，可以方便地将宿主机上的目录挂载到容器中做文件的共享。\\n\\n正是基于 Action 上面的容器特性，才方便的在 docker 内做后续编译的缓存加速。\\n\\n## 编译加速\\n\\nNebula Graph 的源码采用 C++ 编写，整个构建过程时间较长，如果每次 CI 都完全地重新开始，会浪费许多计算资源。因为每台 runner 跑的（容器）任务不定，需要对每个源文件及对应的编译过程进行精准判别才能确认该源文件是否真的被修改。目前使用最新版本的 [ccache](https://ccache.dev/) 来完成缓存的任务。\\n\\n虽然 GitHub Action 本身提供 [cache 的功能](https://help.github.com/en/actions/configuring-and-managing-workflows/caching-dependencies-to-speed-up-workflows)，由于 Nebula Graph 目前单元测试的用例采用静态链接，编译后体积较大，超出其可用的配额，遂使用本地缓存的策略。\\n\\n### ccache\\n\\n[ccache](https://ccache.dev/) 是个编译器的缓存工具，可以有效地加速编译的过程，同时支持 gcc/clang 等编译器。Nebula Graph 使用 C++ 14 标准，低版本的 ccache 在兼容性上有问题，所以在所有的 `vesoft/nebula-dev` [镜像](https://github.com/vesoft-inc/nebula-dev-docker)中都采用手动编译的方式安装。\\n\\nNebula Graph 在 cmake 的配置中自动识别是否安装了 ccache，并决定是否对其打开启用。所以只要在容器环境中对 ccache 做些配置即可，比如在[ ccache.conf ](https://github.com/vesoft-inc/nebula/blob/master/ci/ccache.conf)中配置其最大缓存容量为 1 G，超出后自动替换较旧缓存。\\n\\n```yaml\\nmax_size = 1.0G\\n```\\n\\nccache.conf 配置文件最好放置在缓存目录下，这样 ccache 可方便读取其中内容。\\n\\n### tmpfs\\n\\ntmpfs 是位于内存或者 swap 分区的临时文件系统，可以有效地缓解磁盘 IO 带来的延迟，因为 self-hosted 的主机内存足够，所以将 ccache 的目录挂载类型改为 tmpfs，来减少 ccache 读写时间。在 docker 中使用 tmpfs 的挂载类型可以参考[相应文档](https://docs.docker.com/storage/tmpfs/)。相应的配置参数如下：\\n\\n```yaml\\n    env:\\n      CCACHE_DIR: /tmp/ccache/${{ matrix.os }}-${{ matrix.compiler }}\\n    options: --mount type=tmpfs,destination=/tmp/ccache,tmpfs-size=1073741824 -v /tmp/ccache/${{ matrix.os }}-${{ matrix.compiler }}:/tmp/ccache/${{ matrix.os }}-${{ matrix.compiler }} \\n```\\n\\n将所有 ccache 产生的缓存文件，放置到挂载为 tmpfs 类型的目录下。\\n\\n### 并行编译\\n\\nmake 本身即支持多个源文件的并行编译，在编译时配置 `-j $(nproc)` 便可同时启动与核数相同的任务数。在 action 的 steps 中配置如下：\\n\\n```yaml\\n      - name: Make\\n        run: cmake --build build/ -j $(nproc)\\n```\\n\\n## 坑\\n\\n说了那么多的优点，那有没有不足呢？使用下来主要体会到如下几点：\\n\\n1. 只支持较新版本的系统。很多 Action 是基于较新的 Nodejs 版本开发，没法方便地在类似 CentOS 6 等老版本 docker 容器中直接使用。否则会报 Nodejs 依赖的库文件找不到，从而无法正常启动 action 的执行。因为 Nebula Graph 希望可以支持 CentOS 6，所以在该系统下的任务不得不需要特殊处理。\\n\\n2. 不能方便地进行本地验证。虽然社区有个开源项目 [act](https://github.com/nektos/act)，但使用下来还是有诸多限制，有时不得不通过在自己仓库中反复提交验证才能确保 action 的修改正确。\\n\\n3. 目前还缺少比较好的指导规范，当定制的任务较多时，总有种在 YAML 配置中写程序的感受。目前的做法主要有以下三种：\\n\\n    1. 根据任务拆分配置文件。\\n    1. 定制专属 action，通过 GitHub 的 SDK 来实现想要的功能。\\n    1. 编写大的 shell 脚本来完成任务内容，在任务中调用该脚本。\\n\\n\\n目前针对尽量多使用小任务的组合还是使用大任务的方式，社区也没有定论。不过小任务组合的方式可以方便地定位任务失败位置以及确定每步的执行时间。\\n\\n![action](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto08.png)\\n\\n4. Action 的一些历史记录目前无法清理，如果中途更改了 workflows 的名字，那么老的 check runs 记录还是会一直保留在 Action 页面，影响使用体验。\\n\\n5. 目前还缺少像 GitLab CI 中手动触发 job/task 运行的功能。无法运行中间进行人工干预。\\n\\n6. action 的开发也在不停的迭代中，有时需要维护一下新版的升级，比如：[checkout@v2](https://github.com/actions/checkout/issues/23)\\n\\n不过总体来说，GitHub Action 是一个相对优秀的 CI/CD 系统，毕竟站在 GitLab CI/Travis CI 等前人肩膀上的产品，还是有很多经验可以借鉴使用。\\n\\n## 后续\\n\\n### 定制 Action\\n\\n前段时间 [docker 发布了自己的第一款 Action](https://www.docker.com/blog/first-docker-github-action-is-here/)，简化用户与 docker 相关的任务。后续，针对 Nebula Graph 的一些 CI/CD 的复杂需求，我们亦会定制一些专属的 action 来给 nebula 的所有 repo 使用。通用的就会创建独立的 repo，发布到 action 市场里，比如追加 assets 到 release 功能。专属的就可以放置 repo 的 `.github/actions` 目录下。\\n\\n这样就可以简化 workflows 中的 YAML 配置，只要 use 某个定制 action 即可。灵活性和拓展性都更优。\\n\\n### 跟钉钉/slack 等 IM 集成\\n\\n通过 GitHub 的 SDK 可以开发复杂的 action 应用，再结合[钉钉](https://ding-doc.dingtalk.com/doc#/serverapi2/qf2nxq)/slack 等 bot 的定制，可以实现许多自动化的有意思的小应用。比如，当一个 PR 被 2 个以上的 reviewer approve 并且所有的 check runs 都通过，那么就可以向钉钉群里发消息并 @ 一些人让其去 merge 该 PR。免去了每次都去 PR list 里面 check 每个 PR 状态的辛苦。\\n\\n当然围绕 GitHub 的周边通过一些 bot 还可以迸发许多有意思的玩法。\\n\\n## One More Thing...\\n\\n~~图数据库 Nebula Graph 1.0 GA 快要发布啦。欢迎大家来围观。~~\\n\\n本文中如有任何错误或疏漏欢迎去 GitHub：[https://github.com/vesoft-inc/nebula](https://github.com/vesoft-inc/nebula) issue 区向我们提 issue 或者前往官方论坛：[https://discuss.nebula-graph.com.cn/](https://discuss.nebula-graph.com.cn/) 的 `建议反馈` 分类下提建议 ?；交流图数据库技术？加入 Nebula 交流群请先[填写下你的 Nebula 名片](https://wj.qq.com/s2/8321168/8e2f/)，Nebula 小助手会拉你进群~~\\n\\n> 作者有话说：Hi，我是 Yee，是[图数据 Nebula Graph](https://github.com/vesoft-inc/nebula) 研发工程师，对数据库查询引擎有浓厚的兴趣，希望本次的经验分享能给大家带来帮助，如有不当之处也希望能帮忙纠正，谢谢~\\n\\n\"}',_binary '',5317),(43,'新增 | 官网博客','2022-07-19 12:09:17',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','POST','{\"pic\":\"https://www-cdn.nebula-graph.com.cn/nebula-blog/auto01.jpeg\",\"title\":\"123\",\"author\":\"123\",\"description\":\"123\",\"publish\":true,\"content\":\"https://www-cdn.nebula-graph.com.cn/nebula-blog/auto01.jpeg\"}',_binary '',5159),(44,'新增 | 官网博客','2022-07-19 13:34:31',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','POST','{\"pic\":\"https://www-cdn.nebula-graph.com.cn/nebula-blog/auto01.jpeg\",\"title\":\"Nebula Graph 使用 GitHub Action 的自动化实践\",\"author\":\"Yee\",\"description\":\"在讲 Action 实践之前还需先讲下 Nebula Graph 的需求：首要目标比较明确就是自动化测试，分为单元测试和集成测试，顺带再解决一下 PM 小姐姐的发布需求，构建起来了第一版的 CI/CD 流程。\",\"publish\":true,\"content\":\"\\n## 缘起\\n\\nNebula Graph 最早的自动化测试是使用搭建在 Azure 上的 [Jenkins](https://jenkins.io/zh/)，配合着 GitHub 的 Webhook 实现的，在用户提交 Pull Request 时，加个 `ready-for-testing` 的 label 再评论一句 `Jenkins go` 就可以自动的运行相应的 UT 测试，效果如下：\\n\\n![Jenkins](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto02.png)\\n\\n因为是租用的 Azure 的云主机，加上 nebula 的编译要求的机器配置较高，而且任务的触发主要集中在白天。所以上述的方案性价比较低，从去年团队就在考虑寻找替代的方案，准备下线 Azure 上的测试机，并且还要能提供多环境的测试方案。\\n\\n调研了一圈现有的产品主要有：\\n1. TravisCI\\n1. CircleCI\\n1. Azure Pipeline\\n1. Jenkins on k8s（自建）\\n\\n虽然上面的产品对开源项目有些限制，但整体都还算比较友好。\\n\\n鉴于之前 GitLab CI 的使用经验，体会到如果能跟 GitHub 深度集成那当然是首选。所谓“深度”表示可以共享 GitHub 的整个开源的生态以及完美的 API 调用（后话）。恰巧 2019，GitHub Action 2.0 横空出世，Nebula Graph 便勇敢的入了坑。\\n\\n这里简单概述一下我们在使用 GitHub Action 时体会到的优点：\\n1. 免费。开源项目可以免费使用 Action 的所有功能，而且机器[配置较高](https://help.github.com/en/actions/reference/virtual-environments-for-github-hosted-runners#supported-runners-and-hardware-resources)。\\n1. 开源生态好。在整个 CI 的流程里，可以直接使用 GitHub 上的所有开源的 Action，哪怕就是没有满足需求的 Action，自己上手写也不是很麻烦，而且还支持 docker 定制，用 bash 就可以完成一个专属的 Action。\\n1. 支持多种系统。Windows、macOS 和 Linux 都可以一键使用，跨平台简单方便。\\n1. 可跟 GitHub 的 API 互动。通过 `GITHUB_TOKEN` 可以直接访问 [GitHub API V3](https://developer.github.com/v3/)，想上传文件，检查 PR 状态，使用 curl 命令即可完成。\\n1. 自托管。只要提供 workflow 的描述文件，将其放置到 `.github/workflows/` 目录下，每次提交便会自动触发执行新的 action run。\\n1. Workflow 描述文件改为 YAML 格式。目前的描述方式要比 Action 1.0 中的 workflow 文件更加简洁易读。\\n\\n下面在讲实践之前还是要先讲讲 Nebula Graph 的需求：首要目标比较明确就是自动化测试。\\n\\n作为数据库产品，测试怎么强调也不为过。Nebula Graph 的测试主要分单元测试和集成测试。用 GitHub Action 其实主要瞄准的是单元测试，然后再给集成测试做些准备，比如 docker 镜像构建和安装程序打包。顺带再解决一下 PM 小姐姐的发布需求，就整个构建起来了第一版的 CI/CD 流程。\\n\\n## PR 测试\\n\\nNebula Graph 作为托管在 GitHub 上的开源项目，首先要解决的测试问题就是当贡献者提交了 PR 请求后，如何才能快速地进行变更验证？主要有以下几个方面。\\n\\n1. 符不符合编码规范；\\n1. 能不能在不同系统上都编译通过；\\n1. 单测有没有失败；\\n1. 代码覆盖率有没有下降等。\\n\\n只有上述的要求全部满足并且有至少两位 reviewer 的同意，变更才能进入主干分支。\\n\\n借助于 cpplint 或者 clang-format 等开源工具可以比较简单地实现要求 1，如果此要求未通过验证，后面的步骤就自动跳过，不再继续执行。\\n\\n对于要求 2，我们希望能同时在目前支持的几个系统上运行 Nebula 源码的编译验证。那么像之前在物理机上直接构建的方式就不再可取，毕竟一台物理机的价格已经高昂，何况一台还不足够。为了保证编译环境的一致性，还要尽可能的减少机器的性能损失，最终采用了 docker 的容器化构建方式。再借助 Action 的 [matrix 运行策略](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idstrategymatrix)和对 [docker 的支持](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idcontainer)，还算顺利地将整个流程走通。\\n\\n![action-workflow](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto03.svg)\\n\\n运行的大概流程如上图所示，在 [vesoft-inc/nebula-dev-docker](https://github.com/vesoft-inc/nebula-dev-docker) 项目中维护 nebula 编译环境的 docker 镜像，当编译器或者 thirdparty 依赖升级变更时，自动触发 docker hub 的 Build 任务（见下图）。当新的 Pull Request 提交以后，Action 便会被触发开始拉取最新的编译环境镜像，执行编译。\\n\\n![build-activity](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto04.png)\\n\\n针对 PR 的 workflow 完整描述见文件 [pull_request.yaml](https://github.com/vesoft-inc/nebula/blob/master/.github/workflows/pull_request.yaml)。同时，考虑到并不是每个人提交的 PR 都需要立即运行 CI 测试，且自建的机器资源有限，对 CI 的触发做了如下限制：\\n\\n1. 只有 lint 校验通过的 PR 才会将后续的 job 下发到自建的 runner，lint 的任务比较轻量，可以使用 GitHub Action 托管的机器来执行，无需占用线下的资源。\\n1. 只有添加了 `ready-for-testing`  label 的 PR 才会触发 action 的执行，而 label 的添加有权限的控制。进一步优化 runner 被随意触发的情况。对 label 的限制如下所示：\\n\\n```yaml\\njobs:\\n  lint:\\n    name: cpplint\\n    if: contains(join(toJson(github.event.pull_request.labels.*.name)), \'ready-for-testing\')\\n```\\n\\n在 PR 中执行完成后的效果如下所示：\\n\\n![pr-workflow-result](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto05.png)\\n\\nCode Coverage 的说明见博文：[图数据库 Nebula Graph 的代码变更测试覆盖率实践](https://nebula-graph.io/cn/posts/integrate-codecov-test-coverage-with-nebula-graph/)。\\n\\n## Nightly 构建\\n\\n在 Nebula Graph 的集成测试框架中，希望能够在每天晚上对 codebase 中的代码全量跑一遍所有的测试用例。同时有些新的特性，有时也希望能快速地打包交给用户体验使用。这就需要 CI 系统能在每天给出当日代码的 docker 镜像和 rpm/deb 安装包。\\n\\nGitHub Action 被触发的事件类型除了 pull_request，还可以执行 [schedule](https://help.github.com/en/actions/reference/events-that-trigger-workflows#scheduled-events-schedule) 类型。schedule 类型的事件可以像 crontab 一样，让用户指定任何重复任务的触发时间，比如每天凌晨两点执行任务如下所示：\\n\\n```yaml\\non:\\n  schedule:\\n    - cron: \'0 18 * * *\'\\n```\\n\\n因为 GitHub 采用的是 UTC 时间，所以东八区的凌晨 2 点，就对应到 UTC 的前日 18 时。\\n\\n### docker\\n\\n每日构建的 docker 镜像需要 push 到 docker hub 上，并打上 nightly 的标签，集成测试的 k8s 集群，将 image 的拉取策略设置为 Always，每日触发便能滚动升级到当日最新进行测试。因为当日的问题目前都会尽量当日解决，便没有再给 nightly 的镜像再额外打一个日期的 tag。对应的 action 部分如下所示：\\n\\n```yaml\\n      - name: Build image\\n        env:\\n          IMAGE_NAME: ${{ secrets.DOCKER_USERNAME }}/nebula-${{ matrix.service }}:nightly\\n        run: |\\n          docker build -t ${IMAGE_NAME} -f docker/Dockerfile.${{ matrix.service }} .\\n          docker push ${IMAGE_NAME}\\n        shell: bash\\n```\\n\\n### package\\n\\nGitHub Action 提供了 [artifacts](https://help.github.com/en/actions/configuring-and-managing-workflows/persisting-workflow-data-using-artifacts) 的功能，可以让用户持久化 workflow 运行过程中的数据，这些数据可以保留 90 天。对于 nightly 版本安装包的存储而言，已经绰绰有余。利用官方提供的 `actions/upload-artifact@v1`  action，可以方便的将指定目录下的文件上传到 artifacts。最后 nightly 版本的 nebula 的安装包如下图所示。\\n\\n![package](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto06.png)\\n\\n上述完整的 workflow 文件见 [package.yaml](https://github.com/vesoft-inc/nebula/blob/master/.github/workflows/package.yaml)\\n\\n## 分支发布\\n\\n为了更好地维护每个发布的版本和进行 bugfix，Nebula Graph 采用分支发布的方式。即每次发布之前进行 code freeze，并创建新的 release 分支，在 release 分支上只接受 bugfix，而不进行 feature 的开发。bugfix 还是会在开发分支上提交，最后 cherrypick 到 release 分支。\\n\\n在每次 release 时，除了 source 外，我们希望能把安装包也追加到 assets 中方便用户直接下载。如果每次都手工上传，既容易出错，也非常耗时。这就比较适合 Action 来自动化这块的工作，而且，打包和上传都走 GitHub 内部网络，速度更快。\\n\\n在安装包编译好后，通过 curl 命令直接调用 GitHub 的 API，就能上传到 assets 中，[具体脚本](https://github.com/vesoft-inc/nebula/blob/master/ci/scripts/upload-github-release-asset.sh)内容如下所示：\\n\\n```bash\\ncurl --silent \\\\\\n     --request POST \\\\\\n     --url \\\"$upload_url?name=$filename\\\" \\\\\\n     --header \\\"authorization: Bearer $github_token\\\" \\\\\\n     --header \\\"content-type: $content_type\\\" \\\\\\n     --data-binary @\\\"$filepath\\\"\\n```\\n\\n同时，为了安全起见，在每次的安装包发布时，希望可以计算安装包的 checksum 值，并将其一同上传到 assets 中，以便用户下载后进行完整性校验。具体步骤如下所示：\\n\\n```yaml\\njobs:\\n  package:\\n    name: package and upload release assets\\n    runs-on: ubuntu-latest\\n    strategy:\\n      matrix:\\n        os:\\n          - ubuntu1604\\n          - ubuntu1804\\n          - centos6\\n          - centos7\\n    container:\\n      image: vesoft/nebula-dev:${{ matrix.os }}\\n    steps:\\n      - uses: actions/checkout@v1\\n      - name: package\\n        run: ./package/package.sh\\n      - name: vars\\n        id: vars\\n        env:\\n          CPACK_OUTPUT_DIR: build/cpack_output\\n          SHA_EXT: sha256sum.txt\\n        run: |\\n          tag=$(echo ${{ github.ref }} | rev | cut -d/ -f1 | rev)\\n          cd $CPACK_OUTPUT_DIR\\n          filename=$(find . -type f \\\\( -iname \\\\*.deb -o -iname \\\\*.rpm \\\\) -exec basename {} \\\\;)\\n          sha256sum $filename > $filename.$SHA_EXT\\n          echo \\\"::set-output name=tag::$tag\\\"\\n          echo \\\"::set-output name=filepath::$CPACK_OUTPUT_DIR/$filename\\\"\\n          echo \\\"::set-output name=shafilepath::$CPACK_OUTPUT_DIR/$filename.$SHA_EXT\\\"\\n        shell: bash\\n      - name: upload release asset\\n        run: |\\n          ./ci/scripts/upload-github-release-asset.sh github_token=${{ secrets.GITHUB_TOKEN }} repo=${{ github.repository }} tag=${{ steps.vars.outputs.tag }} filepath=${{ steps.vars.outputs.filepath }}\\n          ./ci/scripts/upload-github-release-asset.sh github_token=${{ secrets.GITHUB_TOKEN }} repo=${{ github.repository }} tag=${{ steps.vars.outputs.tag }} filepath=${{ steps.vars.outputs.shafilepath }}\\n```\\n\\n上述完整的 workflow 文件见 [release.yaml](https://github.com/vesoft-inc/nebula/blob/master/.github/workflows/release.yaml)。\\n\\n## 命令\\n\\nGitHub Action 为 workflow 提供了一些[命令](https://help.github.com/en/actions/reference/workflow-commands-for-github-actions)方便在 shell 中进行调用，来更精细地控制和调试每个步骤的执行。常用的命令如下：\\n\\n### set-output\\n\\n有时在 job 的 steps 之间需要传递一些结果，这时就可以通过 `echo \\\"::set-output name=output_name::output_value\\\"` 的命令形式将想要输出的 `output_value` 值设置到 `output_name` 变量中。\\n\\n在接下来的 step 中，可以通过 `${{ steps.step_id.outputs.output_name }}` 的方式引用上述的输出值。\\n\\n上节中上传 asset 的 job 中就使用了上述的方式来传递文件名称。一个步骤可以通过多次执行上述命令来设置多个输出。\\n\\n### set-env\\n\\n同 `set-output` 一样，可以为后续的步骤设置环境变量。语法： `echo \\\"::set-env name={name}::{value}\\\"` 。\\n\\n### add-path\\n\\n将某路径加入到 `PATH` 变量中，为后续步骤使用。语法： `echo \\\"::add-path::{path}\\\"` 。\\n\\n## Self-Hosted Runner\\n\\n除了 GitHub 官方托管的 runner 之外，Action 还允许使用线下自己的机器作为 Runner 来跑 Action 的 job。在机器上安装好 Action Runner 之后，按照[教程](https://help.github.com/en/actions/hosting-your-own-runners/adding-self-hosted-runners)，将其注册到项目后，在 workflow 文件中通过配置 `runs-on: self-hosted` 即可使用。\\n\\nself-hosted 的机器可以打上不同的 label，这样便可以通过[不同的标签](https://help.github.com/en/actions/hosting-your-own-runners/using-labels-with-self-hosted-runners)来将任务分发到特定的机器上。比如线下的机器安装有不同的操作系统，那么 job 就可以根据 `runs-on` 的 label [在特定的机器](https://help.github.com/en/actions/hosting-your-own-runners/using-self-hosted-runners-in-a-workflow)上运行。 `self-hosted` 也是一个特定的标签。\\n\\n![self-hosted-runner-label](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto07.png)\\n\\n### 安全\\n\\nGitHub 官方是不推荐开源项目使用 Self-Hosted 的 runner 的，原因是任何人都可以通过提交 PR 的方式，让 runner 的机器运行危险的代码对其所在的环境进行攻击。\\n\\n但是 Nebula Graph 的编译需要的存储空间较大，且 GitHub 只能提供 2 核的环境来编译，不得已还是选择了自建 Runner。考虑到安全的因素，进行了如下方面的安全加固：\\n\\n#### 虚拟机部署\\n\\n所有注册到 GitHub Action 的 runner 都是采用虚拟机部署，跟宿主机做好第一层的隔离，也更方便对每个虚拟机做资源分配。一台高配置的宿主机可以分配多个虚拟机让 runner 来并行地跑所有收到的任务。\\n\\n如果虚拟机出了问题，可以方便地进行环境复原的操作。\\n\\n#### 网络隔离\\n\\n将所有 runner 所在的虚拟机隔离在办公网络之外，使其无法直接访问公司内部资源。即便有人通过 PR 提交了恶意代码，也让其无法访问公司内部网络，造成进一步的攻击。\\n\\n#### Action 选择\\n\\n尽量选择大厂和官方发布的 action，如果是使用个人开发者的作品，最好能检视一下其具体实现代码，免得出现网上爆出来的[泄漏隐私密钥](https://julienrenaux.fr/2019/12/20/github-actions-security-risk/)等事情发生。\\n\\n比如 GitHub 官方维护的 action 列表：[https://github.com/actions](https://github.com/actions)。\\n\\n#### 私钥校验\\n\\nGitHub Action 会自动校验 PR 中是否使用了一些私钥，除却 `GITHUB_TOKEN` 之外的其他私钥（通过 `${{ secrets.MY_TOKENS }}` 形式引用）均是不可以在 PR 事件触发的相关任务中使用，以防用户通过 PR 的方式私自打印输出窃取密钥。\\n\\n### 环境搭建与清理\\n\\n对于自建的 runner，在不同任务（job）之间做文件共享是方便的，但是最后不要忘记每次在整个 action 执行结束后，清理产生的中间文件，不然这些文件有可能会影响接下来的任务执行和不断地占用磁盘空间。\\n\\n```yaml\\n      - name: Cleanup\\n        if: always()\\n        run: rm -rf build\\n```\\n\\n将 step 的运行条件设置为 `always()` 确保每次任务都要执行该步骤，即便中途出错。\\n\\n### 基于 Docker 的 Matrix 并行构建\\n\\n因为 Nebula Graph 需要在不同的系统上做编译验证，在构建方式上采用了容器的方案，原因是构建时不同环境的隔离简单方便，GitHub Action 可以原生支持基于 docker 的任务。\\n\\nAction 支持 matrix 策略运行任务的方式，类似于 TravisCI 的 [build matrix](https://docs.travis-ci.com/user/build-matrix/)。通过配置不同系统和编译器的组合，我们可以方便地设置在每个系统下使用 `gcc` 和 `clang` 来同时编译 nebula 的源码，如下所示：\\n\\n```yaml\\njobs:\\n  build:\\n    name: build\\n    runs-on: ubuntu-latest\\n    strategy:\\n      fail-fast: false\\n      matrix:\\n        os:\\n          - centos6\\n          - centos7\\n          - ubuntu1604\\n          - ubuntu1804\\n        compiler:\\n          - gcc-9.2\\n          - clang-9\\n        exclude:\\n          - os: centos7\\n            compiler: clang-9\\n```\\n\\n上述的 strategy 会生成 8 个并行的任务（4 os x 2 compiler），每个任务都是（os, compiler）的一个组合。这种类似矩阵的表达方式，可以极大的减少不同纬度上的任务组合的定义。\\n\\n如果想排除 matrix 中的某个组合，只要将组合的值配置到 `exclude` 选项下面即可。如果想在任务中访问 matrix 中的值，也只要通过类似 `${{ matrix.os }}` 获取上下文变量值的方式拿到。这些方式让你定制自己的任务时都变得十分方便。\\n\\n#### 运行时容器\\n\\n我们可以为每个任务指定运行时的一个容器环境，这样该任务下的所有步骤（steps）都会在容器的内部环境中执行。相较于在每个步骤中都套用 docker 命令要简洁明了。\\n\\n```yaml\\n    container:\\n      image: vesoft/nebula-dev:${{ matrix.os }}\\n      env:\\n        CCACHE_DIR: /tmp/ccache/${{ matrix.os }}-${{ matrix.compiler }}\\n```\\n\\n对容器的配置，像在 docker compose 中配置 service 一样，可以指定 image/env/ports/volumes/options 等等[参数](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idcontainer)。在 self-hosted 的 runner 中，可以方便地将宿主机上的目录挂载到容器中做文件的共享。\\n\\n正是基于 Action 上面的容器特性，才方便的在 docker 内做后续编译的缓存加速。\\n\\n## 编译加速\\n\\nNebula Graph 的源码采用 C++ 编写，整个构建过程时间较长，如果每次 CI 都完全地重新开始，会浪费许多计算资源。因为每台 runner 跑的（容器）任务不定，需要对每个源文件及对应的编译过程进行精准判别才能确认该源文件是否真的被修改。目前使用最新版本的 [ccache](https://ccache.dev/) 来完成缓存的任务。\\n\\n虽然 GitHub Action 本身提供 [cache 的功能](https://help.github.com/en/actions/configuring-and-managing-workflows/caching-dependencies-to-speed-up-workflows)，由于 Nebula Graph 目前单元测试的用例采用静态链接，编译后体积较大，超出其可用的配额，遂使用本地缓存的策略。\\n\\n### ccache\\n\\n[ccache](https://ccache.dev/) 是个编译器的缓存工具，可以有效地加速编译的过程，同时支持 gcc/clang 等编译器。Nebula Graph 使用 C++ 14 标准，低版本的 ccache 在兼容性上有问题，所以在所有的 `vesoft/nebula-dev` [镜像](https://github.com/vesoft-inc/nebula-dev-docker)中都采用手动编译的方式安装。\\n\\nNebula Graph 在 cmake 的配置中自动识别是否安装了 ccache，并决定是否对其打开启用。所以只要在容器环境中对 ccache 做些配置即可，比如在[ ccache.conf ](https://github.com/vesoft-inc/nebula/blob/master/ci/ccache.conf)中配置其最大缓存容量为 1 G，超出后自动替换较旧缓存。\\n\\n```yaml\\nmax_size = 1.0G\\n```\\n\\nccache.conf 配置文件最好放置在缓存目录下，这样 ccache 可方便读取其中内容。\\n\\n### tmpfs\\n\\ntmpfs 是位于内存或者 swap 分区的临时文件系统，可以有效地缓解磁盘 IO 带来的延迟，因为 self-hosted 的主机内存足够，所以将 ccache 的目录挂载类型改为 tmpfs，来减少 ccache 读写时间。在 docker 中使用 tmpfs 的挂载类型可以参考[相应文档](https://docs.docker.com/storage/tmpfs/)。相应的配置参数如下：\\n\\n```yaml\\n    env:\\n      CCACHE_DIR: /tmp/ccache/${{ matrix.os }}-${{ matrix.compiler }}\\n    options: --mount type=tmpfs,destination=/tmp/ccache,tmpfs-size=1073741824 -v /tmp/ccache/${{ matrix.os }}-${{ matrix.compiler }}:/tmp/ccache/${{ matrix.os }}-${{ matrix.compiler }} \\n```\\n\\n将所有 ccache 产生的缓存文件，放置到挂载为 tmpfs 类型的目录下。\\n\\n### 并行编译\\n\\nmake 本身即支持多个源文件的并行编译，在编译时配置 `-j $(nproc)` 便可同时启动与核数相同的任务数。在 action 的 steps 中配置如下：\\n\\n```yaml\\n      - name: Make\\n        run: cmake --build build/ -j $(nproc)\\n```\\n\\n## 坑\\n\\n说了那么多的优点，那有没有不足呢？使用下来主要体会到如下几点：\\n\\n1. 只支持较新版本的系统。很多 Action 是基于较新的 Nodejs 版本开发，没法方便地在类似 CentOS 6 等老版本 docker 容器中直接使用。否则会报 Nodejs 依赖的库文件找不到，从而无法正常启动 action 的执行。因为 Nebula Graph 希望可以支持 CentOS 6，所以在该系统下的任务不得不需要特殊处理。\\n\\n2. 不能方便地进行本地验证。虽然社区有个开源项目 [act](https://github.com/nektos/act)，但使用下来还是有诸多限制，有时不得不通过在自己仓库中反复提交验证才能确保 action 的修改正确。\\n\\n3. 目前还缺少比较好的指导规范，当定制的任务较多时，总有种在 YAML 配置中写程序的感受。目前的做法主要有以下三种：\\n\\n    1. 根据任务拆分配置文件。\\n    1. 定制专属 action，通过 GitHub 的 SDK 来实现想要的功能。\\n    1. 编写大的 shell 脚本来完成任务内容，在任务中调用该脚本。\\n\\n\\n目前针对尽量多使用小任务的组合还是使用大任务的方式，社区也没有定论。不过小任务组合的方式可以方便地定位任务失败位置以及确定每步的执行时间。\\n\\n![action](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto08.png)\\n\\n4. Action 的一些历史记录目前无法清理，如果中途更改了 workflows 的名字，那么老的 check runs 记录还是会一直保留在 Action 页面，影响使用体验。\\n\\n5. 目前还缺少像 GitLab CI 中手动触发 job/task 运行的功能。无法运行中间进行人工干预。\\n\\n6. action 的开发也在不停的迭代中，有时需要维护一下新版的升级，比如：[checkout@v2](https://github.com/actions/checkout/issues/23)\\n\\n不过总体来说，GitHub Action 是一个相对优秀的 CI/CD 系统，毕竟站在 GitLab CI/Travis CI 等前人肩膀上的产品，还是有很多经验可以借鉴使用。\\n\\n## 后续\\n\\n### 定制 Action\\n\\n前段时间 [docker 发布了自己的第一款 Action](https://www.docker.com/blog/first-docker-github-action-is-here/)，简化用户与 docker 相关的任务。后续，针对 Nebula Graph 的一些 CI/CD 的复杂需求，我们亦会定制一些专属的 action 来给 nebula 的所有 repo 使用。通用的就会创建独立的 repo，发布到 action 市场里，比如追加 assets 到 release 功能。专属的就可以放置 repo 的 `.github/actions` 目录下。\\n\\n这样就可以简化 workflows 中的 YAML 配置，只要 use 某个定制 action 即可。灵活性和拓展性都更优。\\n\\n### 跟钉钉/slack 等 IM 集成\\n\\n通过 GitHub 的 SDK 可以开发复杂的 action 应用，再结合[钉钉](https://ding-doc.dingtalk.com/doc#/serverapi2/qf2nxq)/slack 等 bot 的定制，可以实现许多自动化的有意思的小应用。比如，当一个 PR 被 2 个以上的 reviewer approve 并且所有的 check runs 都通过，那么就可以向钉钉群里发消息并 @ 一些人让其去 merge 该 PR。免去了每次都去 PR list 里面 check 每个 PR 状态的辛苦。\\n\\n当然围绕 GitHub 的周边通过一些 bot 还可以迸发许多有意思的玩法。\\n\\n## One More Thing...\\n\\n~~图数据库 Nebula Graph 1.0 GA 快要发布啦。欢迎大家来围观。~~\\n\\n本文中如有任何错误或疏漏欢迎去 GitHub：[https://github.com/vesoft-inc/nebula](https://github.com/vesoft-inc/nebula) issue 区向我们提 issue 或者前往官方论坛：[https://discuss.nebula-graph.com.cn/](https://discuss.nebula-graph.com.cn/) 的 `建议反馈` 分类下提建议 ?；交流图数据库技术？加入 Nebula 交流群请先[填写下你的 Nebula 名片](https://wj.qq.com/s2/8321168/8e2f/)，Nebula 小助手会拉你进群~~\\n\\n> 作者有话说：Hi，我是 Yee，是[图数据 Nebula Graph](https://github.com/vesoft-inc/nebula) 研发工程师，对数据库查询引擎有浓厚的兴趣，希望本次的经验分享能给大家带来帮助，如有不当之处也希望能帮忙纠正，谢谢~\\n\\n\"}',_binary '',5377),(45,'新增 | 官网博客','2022-07-19 13:38:33',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','POST','{\"pic\":\"https://www-cdn.nebula-graph.com.cn/nebula-blog/auto01.jpeg\",\"title\":\"Nebula Graph 使用 GitHub Action 的自动化实践\",\"author\":\"Yee\",\"description\":\"在讲 Action 实践之前还需先讲下 Nebula Graph 的需求：首要目标比较明确就是自动化测试，分为单元测试和集成测试，顺带再解决一下 PM 小姐姐的发布需求，构建起来了第一版的 CI/CD 流程。\",\"publish\":true,\"content\":\"\\n## 缘起\\n\\nNebula Graph 最早的自动化测试是使用搭建在 Azure 上的 [Jenkins](https://jenkins.io/zh/)，配合着 GitHub 的 Webhook 实现的，在用户提交 Pull Request 时，加个 `ready-for-testing` 的 label 再评论一句 `Jenkins go` 就可以自动的运行相应的 UT 测试，效果如下：\\n\\n![Jenkins](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto02.png)\\n\\n因为是租用的 Azure 的云主机，加上 nebula 的编译要求的机器配置较高，而且任务的触发主要集中在白天。所以上述的方案性价比较低，从去年团队就在考虑寻找替代的方案，准备下线 Azure 上的测试机，并且还要能提供多环境的测试方案。\\n\\n调研了一圈现有的产品主要有：\\n1. TravisCI\\n1. CircleCI\\n1. Azure Pipeline\\n1. Jenkins on k8s（自建）\\n\\n虽然上面的产品对开源项目有些限制，但整体都还算比较友好。\\n\\n鉴于之前 GitLab CI 的使用经验，体会到如果能跟 GitHub 深度集成那当然是首选。所谓“深度”表示可以共享 GitHub 的整个开源的生态以及完美的 API 调用（后话）。恰巧 2019，GitHub Action 2.0 横空出世，Nebula Graph 便勇敢的入了坑。\\n\\n这里简单概述一下我们在使用 GitHub Action 时体会到的优点：\\n1. 免费。开源项目可以免费使用 Action 的所有功能，而且机器[配置较高](https://help.github.com/en/actions/reference/virtual-environments-for-github-hosted-runners#supported-runners-and-hardware-resources)。\\n1. 开源生态好。在整个 CI 的流程里，可以直接使用 GitHub 上的所有开源的 Action，哪怕就是没有满足需求的 Action，自己上手写也不是很麻烦，而且还支持 docker 定制，用 bash 就可以完成一个专属的 Action。\\n1. 支持多种系统。Windows、macOS 和 Linux 都可以一键使用，跨平台简单方便。\\n1. 可跟 GitHub 的 API 互动。通过 `GITHUB_TOKEN` 可以直接访问 [GitHub API V3](https://developer.github.com/v3/)，想上传文件，检查 PR 状态，使用 curl 命令即可完成。\\n1. 自托管。只要提供 workflow 的描述文件，将其放置到 `.github/workflows/` 目录下，每次提交便会自动触发执行新的 action run。\\n1. Workflow 描述文件改为 YAML 格式。目前的描述方式要比 Action 1.0 中的 workflow 文件更加简洁易读。\\n\\n下面在讲实践之前还是要先讲讲 Nebula Graph 的需求：首要目标比较明确就是自动化测试。\\n\\n作为数据库产品，测试怎么强调也不为过。Nebula Graph 的测试主要分单元测试和集成测试。用 GitHub Action 其实主要瞄准的是单元测试，然后再给集成测试做些准备，比如 docker 镜像构建和安装程序打包。顺带再解决一下 PM 小姐姐的发布需求，就整个构建起来了第一版的 CI/CD 流程。\\n\\n## PR 测试\\n\\nNebula Graph 作为托管在 GitHub 上的开源项目，首先要解决的测试问题就是当贡献者提交了 PR 请求后，如何才能快速地进行变更验证？主要有以下几个方面。\\n\\n1. 符不符合编码规范；\\n1. 能不能在不同系统上都编译通过；\\n1. 单测有没有失败；\\n1. 代码覆盖率有没有下降等。\\n\\n只有上述的要求全部满足并且有至少两位 reviewer 的同意，变更才能进入主干分支。\\n\\n借助于 cpplint 或者 clang-format 等开源工具可以比较简单地实现要求 1，如果此要求未通过验证，后面的步骤就自动跳过，不再继续执行。\\n\\n对于要求 2，我们希望能同时在目前支持的几个系统上运行 Nebula 源码的编译验证。那么像之前在物理机上直接构建的方式就不再可取，毕竟一台物理机的价格已经高昂，何况一台还不足够。为了保证编译环境的一致性，还要尽可能的减少机器的性能损失，最终采用了 docker 的容器化构建方式。再借助 Action 的 [matrix 运行策略](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idstrategymatrix)和对 [docker 的支持](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idcontainer)，还算顺利地将整个流程走通。\\n\\n![action-workflow](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto03.svg)\\n\\n运行的大概流程如上图所示，在 [vesoft-inc/nebula-dev-docker](https://github.com/vesoft-inc/nebula-dev-docker) 项目中维护 nebula 编译环境的 docker 镜像，当编译器或者 thirdparty 依赖升级变更时，自动触发 docker hub 的 Build 任务（见下图）。当新的 Pull Request 提交以后，Action 便会被触发开始拉取最新的编译环境镜像，执行编译。\\n\\n![build-activity](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto04.png)\\n\\n针对 PR 的 workflow 完整描述见文件 [pull_request.yaml](https://github.com/vesoft-inc/nebula/blob/master/.github/workflows/pull_request.yaml)。同时，考虑到并不是每个人提交的 PR 都需要立即运行 CI 测试，且自建的机器资源有限，对 CI 的触发做了如下限制：\\n\\n1. 只有 lint 校验通过的 PR 才会将后续的 job 下发到自建的 runner，lint 的任务比较轻量，可以使用 GitHub Action 托管的机器来执行，无需占用线下的资源。\\n1. 只有添加了 `ready-for-testing`  label 的 PR 才会触发 action 的执行，而 label 的添加有权限的控制。进一步优化 runner 被随意触发的情况。对 label 的限制如下所示：\\n\\n```yaml\\njobs:\\n  lint:\\n    name: cpplint\\n    if: contains(join(toJson(github.event.pull_request.labels.*.name)), \'ready-for-testing\')\\n```\\n\\n在 PR 中执行完成后的效果如下所示：\\n\\n![pr-workflow-result](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto05.png)\\n\\nCode Coverage 的说明见博文：[图数据库 Nebula Graph 的代码变更测试覆盖率实践](https://nebula-graph.io/cn/posts/integrate-codecov-test-coverage-with-nebula-graph/)。\\n\\n## Nightly 构建\\n\\n在 Nebula Graph 的集成测试框架中，希望能够在每天晚上对 codebase 中的代码全量跑一遍所有的测试用例。同时有些新的特性，有时也希望能快速地打包交给用户体验使用。这就需要 CI 系统能在每天给出当日代码的 docker 镜像和 rpm/deb 安装包。\\n\\nGitHub Action 被触发的事件类型除了 pull_request，还可以执行 [schedule](https://help.github.com/en/actions/reference/events-that-trigger-workflows#scheduled-events-schedule) 类型。schedule 类型的事件可以像 crontab 一样，让用户指定任何重复任务的触发时间，比如每天凌晨两点执行任务如下所示：\\n\\n```yaml\\non:\\n  schedule:\\n    - cron: \'0 18 * * *\'\\n```\\n\\n因为 GitHub 采用的是 UTC 时间，所以东八区的凌晨 2 点，就对应到 UTC 的前日 18 时。\\n\\n### docker\\n\\n每日构建的 docker 镜像需要 push 到 docker hub 上，并打上 nightly 的标签，集成测试的 k8s 集群，将 image 的拉取策略设置为 Always，每日触发便能滚动升级到当日最新进行测试。因为当日的问题目前都会尽量当日解决，便没有再给 nightly 的镜像再额外打一个日期的 tag。对应的 action 部分如下所示：\\n\\n```yaml\\n      - name: Build image\\n        env:\\n          IMAGE_NAME: ${{ secrets.DOCKER_USERNAME }}/nebula-${{ matrix.service }}:nightly\\n        run: |\\n          docker build -t ${IMAGE_NAME} -f docker/Dockerfile.${{ matrix.service }} .\\n          docker push ${IMAGE_NAME}\\n        shell: bash\\n```\\n\\n### package\\n\\nGitHub Action 提供了 [artifacts](https://help.github.com/en/actions/configuring-and-managing-workflows/persisting-workflow-data-using-artifacts) 的功能，可以让用户持久化 workflow 运行过程中的数据，这些数据可以保留 90 天。对于 nightly 版本安装包的存储而言，已经绰绰有余。利用官方提供的 `actions/upload-artifact@v1`  action，可以方便的将指定目录下的文件上传到 artifacts。最后 nightly 版本的 nebula 的安装包如下图所示。\\n\\n![package](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto06.png)\\n\\n上述完整的 workflow 文件见 [package.yaml](https://github.com/vesoft-inc/nebula/blob/master/.github/workflows/package.yaml)\\n\\n## 分支发布\\n\\n为了更好地维护每个发布的版本和进行 bugfix，Nebula Graph 采用分支发布的方式。即每次发布之前进行 code freeze，并创建新的 release 分支，在 release 分支上只接受 bugfix，而不进行 feature 的开发。bugfix 还是会在开发分支上提交，最后 cherrypick 到 release 分支。\\n\\n在每次 release 时，除了 source 外，我们希望能把安装包也追加到 assets 中方便用户直接下载。如果每次都手工上传，既容易出错，也非常耗时。这就比较适合 Action 来自动化这块的工作，而且，打包和上传都走 GitHub 内部网络，速度更快。\\n\\n在安装包编译好后，通过 curl 命令直接调用 GitHub 的 API，就能上传到 assets 中，[具体脚本](https://github.com/vesoft-inc/nebula/blob/master/ci/scripts/upload-github-release-asset.sh)内容如下所示：\\n\\n```bash\\ncurl --silent \\\\\\n     --request POST \\\\\\n     --url \\\"$upload_url?name=$filename\\\" \\\\\\n     --header \\\"authorization: Bearer $github_token\\\" \\\\\\n     --header \\\"content-type: $content_type\\\" \\\\\\n     --data-binary @\\\"$filepath\\\"\\n```\\n\\n同时，为了安全起见，在每次的安装包发布时，希望可以计算安装包的 checksum 值，并将其一同上传到 assets 中，以便用户下载后进行完整性校验。具体步骤如下所示：\\n\\n```yaml\\njobs:\\n  package:\\n    name: package and upload release assets\\n    runs-on: ubuntu-latest\\n    strategy:\\n      matrix:\\n        os:\\n          - ubuntu1604\\n          - ubuntu1804\\n          - centos6\\n          - centos7\\n    container:\\n      image: vesoft/nebula-dev:${{ matrix.os }}\\n    steps:\\n      - uses: actions/checkout@v1\\n      - name: package\\n        run: ./package/package.sh\\n      - name: vars\\n        id: vars\\n        env:\\n          CPACK_OUTPUT_DIR: build/cpack_output\\n          SHA_EXT: sha256sum.txt\\n        run: |\\n          tag=$(echo ${{ github.ref }} | rev | cut -d/ -f1 | rev)\\n          cd $CPACK_OUTPUT_DIR\\n          filename=$(find . -type f \\\\( -iname \\\\*.deb -o -iname \\\\*.rpm \\\\) -exec basename {} \\\\;)\\n          sha256sum $filename > $filename.$SHA_EXT\\n          echo \\\"::set-output name=tag::$tag\\\"\\n          echo \\\"::set-output name=filepath::$CPACK_OUTPUT_DIR/$filename\\\"\\n          echo \\\"::set-output name=shafilepath::$CPACK_OUTPUT_DIR/$filename.$SHA_EXT\\\"\\n        shell: bash\\n      - name: upload release asset\\n        run: |\\n          ./ci/scripts/upload-github-release-asset.sh github_token=${{ secrets.GITHUB_TOKEN }} repo=${{ github.repository }} tag=${{ steps.vars.outputs.tag }} filepath=${{ steps.vars.outputs.filepath }}\\n          ./ci/scripts/upload-github-release-asset.sh github_token=${{ secrets.GITHUB_TOKEN }} repo=${{ github.repository }} tag=${{ steps.vars.outputs.tag }} filepath=${{ steps.vars.outputs.shafilepath }}\\n```\\n\\n上述完整的 workflow 文件见 [release.yaml](https://github.com/vesoft-inc/nebula/blob/master/.github/workflows/release.yaml)。\\n\\n## 命令\\n\\nGitHub Action 为 workflow 提供了一些[命令](https://help.github.com/en/actions/reference/workflow-commands-for-github-actions)方便在 shell 中进行调用，来更精细地控制和调试每个步骤的执行。常用的命令如下：\\n\\n### set-output\\n\\n有时在 job 的 steps 之间需要传递一些结果，这时就可以通过 `echo \\\"::set-output name=output_name::output_value\\\"` 的命令形式将想要输出的 `output_value` 值设置到 `output_name` 变量中。\\n\\n在接下来的 step 中，可以通过 `${{ steps.step_id.outputs.output_name }}` 的方式引用上述的输出值。\\n\\n上节中上传 asset 的 job 中就使用了上述的方式来传递文件名称。一个步骤可以通过多次执行上述命令来设置多个输出。\\n\\n### set-env\\n\\n同 `set-output` 一样，可以为后续的步骤设置环境变量。语法： `echo \\\"::set-env name={name}::{value}\\\"` 。\\n\\n### add-path\\n\\n将某路径加入到 `PATH` 变量中，为后续步骤使用。语法： `echo \\\"::add-path::{path}\\\"` 。\\n\\n## Self-Hosted Runner\\n\\n除了 GitHub 官方托管的 runner 之外，Action 还允许使用线下自己的机器作为 Runner 来跑 Action 的 job。在机器上安装好 Action Runner 之后，按照[教程](https://help.github.com/en/actions/hosting-your-own-runners/adding-self-hosted-runners)，将其注册到项目后，在 workflow 文件中通过配置 `runs-on: self-hosted` 即可使用。\\n\\nself-hosted 的机器可以打上不同的 label，这样便可以通过[不同的标签](https://help.github.com/en/actions/hosting-your-own-runners/using-labels-with-self-hosted-runners)来将任务分发到特定的机器上。比如线下的机器安装有不同的操作系统，那么 job 就可以根据 `runs-on` 的 label [在特定的机器](https://help.github.com/en/actions/hosting-your-own-runners/using-self-hosted-runners-in-a-workflow)上运行。 `self-hosted` 也是一个特定的标签。\\n\\n![self-hosted-runner-label](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto07.png)\\n\\n### 安全\\n\\nGitHub 官方是不推荐开源项目使用 Self-Hosted 的 runner 的，原因是任何人都可以通过提交 PR 的方式，让 runner 的机器运行危险的代码对其所在的环境进行攻击。\\n\\n但是 Nebula Graph 的编译需要的存储空间较大，且 GitHub 只能提供 2 核的环境来编译，不得已还是选择了自建 Runner。考虑到安全的因素，进行了如下方面的安全加固：\\n\\n#### 虚拟机部署\\n\\n所有注册到 GitHub Action 的 runner 都是采用虚拟机部署，跟宿主机做好第一层的隔离，也更方便对每个虚拟机做资源分配。一台高配置的宿主机可以分配多个虚拟机让 runner 来并行地跑所有收到的任务。\\n\\n如果虚拟机出了问题，可以方便地进行环境复原的操作。\\n\\n#### 网络隔离\\n\\n将所有 runner 所在的虚拟机隔离在办公网络之外，使其无法直接访问公司内部资源。即便有人通过 PR 提交了恶意代码，也让其无法访问公司内部网络，造成进一步的攻击。\\n\\n#### Action 选择\\n\\n尽量选择大厂和官方发布的 action，如果是使用个人开发者的作品，最好能检视一下其具体实现代码，免得出现网上爆出来的[泄漏隐私密钥](https://julienrenaux.fr/2019/12/20/github-actions-security-risk/)等事情发生。\\n\\n比如 GitHub 官方维护的 action 列表：[https://github.com/actions](https://github.com/actions)。\\n\\n#### 私钥校验\\n\\nGitHub Action 会自动校验 PR 中是否使用了一些私钥，除却 `GITHUB_TOKEN` 之外的其他私钥（通过 `${{ secrets.MY_TOKENS }}` 形式引用）均是不可以在 PR 事件触发的相关任务中使用，以防用户通过 PR 的方式私自打印输出窃取密钥。\\n\\n### 环境搭建与清理\\n\\n对于自建的 runner，在不同任务（job）之间做文件共享是方便的，但是最后不要忘记每次在整个 action 执行结束后，清理产生的中间文件，不然这些文件有可能会影响接下来的任务执行和不断地占用磁盘空间。\\n\\n```yaml\\n      - name: Cleanup\\n        if: always()\\n        run: rm -rf build\\n```\\n\\n将 step 的运行条件设置为 `always()` 确保每次任务都要执行该步骤，即便中途出错。\\n\\n### 基于 Docker 的 Matrix 并行构建\\n\\n因为 Nebula Graph 需要在不同的系统上做编译验证，在构建方式上采用了容器的方案，原因是构建时不同环境的隔离简单方便，GitHub Action 可以原生支持基于 docker 的任务。\\n\\nAction 支持 matrix 策略运行任务的方式，类似于 TravisCI 的 [build matrix](https://docs.travis-ci.com/user/build-matrix/)。通过配置不同系统和编译器的组合，我们可以方便地设置在每个系统下使用 `gcc` 和 `clang` 来同时编译 nebula 的源码，如下所示：\\n\\n```yaml\\njobs:\\n  build:\\n    name: build\\n    runs-on: ubuntu-latest\\n    strategy:\\n      fail-fast: false\\n      matrix:\\n        os:\\n          - centos6\\n          - centos7\\n          - ubuntu1604\\n          - ubuntu1804\\n        compiler:\\n          - gcc-9.2\\n          - clang-9\\n        exclude:\\n          - os: centos7\\n            compiler: clang-9\\n```\\n\\n上述的 strategy 会生成 8 个并行的任务（4 os x 2 compiler），每个任务都是（os, compiler）的一个组合。这种类似矩阵的表达方式，可以极大的减少不同纬度上的任务组合的定义。\\n\\n如果想排除 matrix 中的某个组合，只要将组合的值配置到 `exclude` 选项下面即可。如果想在任务中访问 matrix 中的值，也只要通过类似 `${{ matrix.os }}` 获取上下文变量值的方式拿到。这些方式让你定制自己的任务时都变得十分方便。\\n\\n#### 运行时容器\\n\\n我们可以为每个任务指定运行时的一个容器环境，这样该任务下的所有步骤（steps）都会在容器的内部环境中执行。相较于在每个步骤中都套用 docker 命令要简洁明了。\\n\\n```yaml\\n    container:\\n      image: vesoft/nebula-dev:${{ matrix.os }}\\n      env:\\n        CCACHE_DIR: /tmp/ccache/${{ matrix.os }}-${{ matrix.compiler }}\\n```\\n\\n对容器的配置，像在 docker compose 中配置 service 一样，可以指定 image/env/ports/volumes/options 等等[参数](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idcontainer)。在 self-hosted 的 runner 中，可以方便地将宿主机上的目录挂载到容器中做文件的共享。\\n\\n正是基于 Action 上面的容器特性，才方便的在 docker 内做后续编译的缓存加速。\\n\\n## 编译加速\\n\\nNebula Graph 的源码采用 C++ 编写，整个构建过程时间较长，如果每次 CI 都完全地重新开始，会浪费许多计算资源。因为每台 runner 跑的（容器）任务不定，需要对每个源文件及对应的编译过程进行精准判别才能确认该源文件是否真的被修改。目前使用最新版本的 [ccache](https://ccache.dev/) 来完成缓存的任务。\\n\\n虽然 GitHub Action 本身提供 [cache 的功能](https://help.github.com/en/actions/configuring-and-managing-workflows/caching-dependencies-to-speed-up-workflows)，由于 Nebula Graph 目前单元测试的用例采用静态链接，编译后体积较大，超出其可用的配额，遂使用本地缓存的策略。\\n\\n### ccache\\n\\n[ccache](https://ccache.dev/) 是个编译器的缓存工具，可以有效地加速编译的过程，同时支持 gcc/clang 等编译器。Nebula Graph 使用 C++ 14 标准，低版本的 ccache 在兼容性上有问题，所以在所有的 `vesoft/nebula-dev` [镜像](https://github.com/vesoft-inc/nebula-dev-docker)中都采用手动编译的方式安装。\\n\\nNebula Graph 在 cmake 的配置中自动识别是否安装了 ccache，并决定是否对其打开启用。所以只要在容器环境中对 ccache 做些配置即可，比如在[ ccache.conf ](https://github.com/vesoft-inc/nebula/blob/master/ci/ccache.conf)中配置其最大缓存容量为 1 G，超出后自动替换较旧缓存。\\n\\n```yaml\\nmax_size = 1.0G\\n```\\n\\nccache.conf 配置文件最好放置在缓存目录下，这样 ccache 可方便读取其中内容。\\n\\n### tmpfs\\n\\ntmpfs 是位于内存或者 swap 分区的临时文件系统，可以有效地缓解磁盘 IO 带来的延迟，因为 self-hosted 的主机内存足够，所以将 ccache 的目录挂载类型改为 tmpfs，来减少 ccache 读写时间。在 docker 中使用 tmpfs 的挂载类型可以参考[相应文档](https://docs.docker.com/storage/tmpfs/)。相应的配置参数如下：\\n\\n```yaml\\n    env:\\n      CCACHE_DIR: /tmp/ccache/${{ matrix.os }}-${{ matrix.compiler }}\\n    options: --mount type=tmpfs,destination=/tmp/ccache,tmpfs-size=1073741824 -v /tmp/ccache/${{ matrix.os }}-${{ matrix.compiler }}:/tmp/ccache/${{ matrix.os }}-${{ matrix.compiler }} \\n```\\n\\n将所有 ccache 产生的缓存文件，放置到挂载为 tmpfs 类型的目录下。\\n\\n### 并行编译\\n\\nmake 本身即支持多个源文件的并行编译，在编译时配置 `-j $(nproc)` 便可同时启动与核数相同的任务数。在 action 的 steps 中配置如下：\\n\\n```yaml\\n      - name: Make\\n        run: cmake --build build/ -j $(nproc)\\n```\\n\\n## 坑\\n\\n说了那么多的优点，那有没有不足呢？使用下来主要体会到如下几点：\\n\\n1. 只支持较新版本的系统。很多 Action 是基于较新的 Nodejs 版本开发，没法方便地在类似 CentOS 6 等老版本 docker 容器中直接使用。否则会报 Nodejs 依赖的库文件找不到，从而无法正常启动 action 的执行。因为 Nebula Graph 希望可以支持 CentOS 6，所以在该系统下的任务不得不需要特殊处理。\\n\\n2. 不能方便地进行本地验证。虽然社区有个开源项目 [act](https://github.com/nektos/act)，但使用下来还是有诸多限制，有时不得不通过在自己仓库中反复提交验证才能确保 action 的修改正确。\\n\\n3. 目前还缺少比较好的指导规范，当定制的任务较多时，总有种在 YAML 配置中写程序的感受。目前的做法主要有以下三种：\\n\\n    1. 根据任务拆分配置文件。\\n    1. 定制专属 action，通过 GitHub 的 SDK 来实现想要的功能。\\n    1. 编写大的 shell 脚本来完成任务内容，在任务中调用该脚本。\\n\\n\\n目前针对尽量多使用小任务的组合还是使用大任务的方式，社区也没有定论。不过小任务组合的方式可以方便地定位任务失败位置以及确定每步的执行时间。\\n\\n![action](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto08.png)\\n\\n4. Action 的一些历史记录目前无法清理，如果中途更改了 workflows 的名字，那么老的 check runs 记录还是会一直保留在 Action 页面，影响使用体验。\\n\\n5. 目前还缺少像 GitLab CI 中手动触发 job/task 运行的功能。无法运行中间进行人工干预。\\n\\n6. action 的开发也在不停的迭代中，有时需要维护一下新版的升级，比如：[checkout@v2](https://github.com/actions/checkout/issues/23)\\n\\n不过总体来说，GitHub Action 是一个相对优秀的 CI/CD 系统，毕竟站在 GitLab CI/Travis CI 等前人肩膀上的产品，还是有很多经验可以借鉴使用。\\n\\n## 后续\\n\\n### 定制 Action\\n\\n前段时间 [docker 发布了自己的第一款 Action](https://www.docker.com/blog/first-docker-github-action-is-here/)，简化用户与 docker 相关的任务。后续，针对 Nebula Graph 的一些 CI/CD 的复杂需求，我们亦会定制一些专属的 action 来给 nebula 的所有 repo 使用。通用的就会创建独立的 repo，发布到 action 市场里，比如追加 assets 到 release 功能。专属的就可以放置 repo 的 `.github/actions` 目录下。\\n\\n这样就可以简化 workflows 中的 YAML 配置，只要 use 某个定制 action 即可。灵活性和拓展性都更优。\\n\\n### 跟钉钉/slack 等 IM 集成\\n\\n通过 GitHub 的 SDK 可以开发复杂的 action 应用，再结合[钉钉](https://ding-doc.dingtalk.com/doc#/serverapi2/qf2nxq)/slack 等 bot 的定制，可以实现许多自动化的有意思的小应用。比如，当一个 PR 被 2 个以上的 reviewer approve 并且所有的 check runs 都通过，那么就可以向钉钉群里发消息并 @ 一些人让其去 merge 该 PR。免去了每次都去 PR list 里面 check 每个 PR 状态的辛苦。\\n\\n当然围绕 GitHub 的周边通过一些 bot 还可以迸发许多有意思的玩法。\\n\\n## One More Thing...\\n\\n~~图数据库 Nebula Graph 1.0 GA 快要发布啦。欢迎大家来围观。~~\\n\\n本文中如有任何错误或疏漏欢迎去 GitHub：[https://github.com/vesoft-inc/nebula](https://github.com/vesoft-inc/nebula) issue 区向我们提 issue 或者前往官方论坛：[https://discuss.nebula-graph.com.cn/](https://discuss.nebula-graph.com.cn/) 的 `建议反馈` 分类下提建议 ?；交流图数据库技术？加入 Nebula 交流群请先[填写下你的 Nebula 名片](https://wj.qq.com/s2/8321168/8e2f/)，Nebula 小助手会拉你进群~~\\n\\n> 作者有话说：Hi，我是 Yee，是[图数据 Nebula Graph](https://github.com/vesoft-inc/nebula) 研发工程师，对数据库查询引擎有浓厚的兴趣，希望本次的经验分享能给大家带来帮助，如有不当之处也希望能帮忙纠正，谢谢~\\n\\n\"}',_binary '',5308),(46,'删除 | 官网博客','2022-07-19 13:38:52',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog/10','DELETE',NULL,_binary '',5311),(47,'修改 | 官网博客','2022-07-19 15:02:48',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','PUT','{\"pic\":\"https://www-cdn.nebula-graph.com.cn/nebula-blog/bdd.png\",\"title\":\"基于 BDD 理论的 Nebula 集111成测试框架重构（下篇）\",\"description\":\"这回，我们来给 Nebula Graph 添加一个测试用例，步骤很简单，首先：打开文章，然后准备好环境，开发 case，提交上线…\",\"publish\":true,\"content\":\"## 引子\\n\\n由于 Nebula Graph 在持续研发过程中会频繁地更改返回数据的格式，这样就会造成了上层应用程序无法正确解析数据。\\n\\n比如在 v2.0.0 发布的时候，改变了 SHOW JOBS 的格式，造成了 Studio 解析的时候页面崩溃。\\n\\n为了避免再次发生这样的悲剧问题，可以使用 Nebula Graph 提供的测试框架，方便地增加测试用例。\\n\\n## 环境准备   \\n\\n按照文档[《源码编译安装》](https://docs.nebula-graph.com.cn/2.0.1/4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/) 中所示，我们可以参考以下步骤进行操作：\\n\\na. 准备一台开发机，这里给出了开发环境的配置要求。\\n\\n- Python3 要求的最低版本为 Python 3.7.\\n\\n```\\npython3 --version\\n``` \\n\\nb. 按照文档中步骤编译源代码。选择 master 版本,并拉一个分支\\n\\n```\\ngit checkout -b  dev tck\\n```\\n\\n具体步骤可以见 Nebula 文档站中如何贡献中的 GitHub [使用步骤部分](https://docs.nebula-graph.com.cn/2.0.1/15.contribution/how-to-contribute/) 。\\n\\nc. 安装 case 运行环境\\n\\n```\\n$ cd nebula-graph/tests/\\n$ make init-all\\n```\\n\\n如果遇到模块版本过低，可以根据提示升级版本，比如：命令 `pip3 install --upgrade keyrings.alt` 。\\n\\nd. 运行已有case \\n\\n```\\nmake test\\n```\\n\\n## 开发 case\\n\\n### 研究一下已有 case\\n\\n大多数已有 case 都在 https://github.com/vesoft-inc/nebula-graph/tree/master/tests/tck/features 目录下，根据主要功能放在不同目录下。\\n\\n例如，以最常用的 MATCH 功能举例。打开 GitHub 目录下的 [match/MatchById.feature](https://github.com/vesoft-inc/nebula-graph/blob/master/tests/tck/features/match/MatchById.feature) 文件\\n\\n```\\nFeature: Match By Id\\n\\n  Background:\\n    Given a graph with space named \\\"basketballplayer\\\"     # 选择一个已有的单元测试数据集 basketballplayer\\n\\n  Scenario: single node                                   # 给这个 case 取个名字\\n    When executing query:                              # 以下三引号之间的部分，为发送给 Nebula Graph 的文本。\\n      \\\"\\\"\\\"                                                            # 这句话的目的，是获vid为James Harden的点\\n      MATCH (n) WHERE id(n) == \'James Harden\' RETURN n\\n      \\\"\\\"\\\"                                                            # Then 表示测试结果匹配                \\n    Then the result should be, in any order, with relax comparison:\\n      | n                |                                           # 期望获取的文本结果，应该是这样一个格式。列名为 n\\n      | (\\\"James Harden\\\") |                                # 内容为 \\\"James Harden\\\", 圆括号表示这是一个点\\n    When executing query:                             # 开始下一个命令。\\n      \\\"\\\"\\\"\\n      MATCH (n) WHERE id(n) == \'not_exist_vertex\' RETURN n\\n      \\\"\\\"\\\"\\n    Then the result should be, in any order, with relax comparison:\\n      | n |\\n```\\n\\nnebula-test 是基于 BDD 思想撰写的，这些 feature 文件基本是自然语言（gherkin文本），BDD 介绍文章可参考：[《基于 BDD 理论的 Nebula 集成测试框架重构（上篇）》](https://mp.weixin.qq.com/s/gw1hJetflofQc2aiiZ6frA)。\\n\\n这里简单地解释一下 case 用例模版主要的格式：\\n\\n- Feature：介绍整个文本是做什么的；\\n- Background：设置一下公共的运行环境，例子中，选用了一个已经存在的数据集 basketballplayer（建立了schema，index，写入了数据）；\\n- Scenario：一组 `When-Then` 的组合，是一个最小的并发执行单位；\\n- When executing query：向 Nebula Graph 发送一组命令；\\n- Then the result should be：从 Nebula Graph 获取结果，和下面的期望结果对比；\\n\\n\\n这个对比方式可以有以下几种：\\n\\n- the result should be：需完全一样 （行、列、单元格内容都必须一模一样）；\\n- the result should contain：只包含以下内容即可；\\n- the result should be, in any order：返回结果的行顺序无关（对于行 1 和行 2 的顺序没有要求）；\\n- the result should be, in any order, with relax comparison：结果集需要是以下形式，行顺序无关，并且至少包括以下内容（例如，每个单元格至少包括\\\"Tiago Splitter\\\"，但可以比这个多）；\\n- the execution should be successful：返回码为成功；\\n- an ExecutionError should be raised at runtime: not existed! 执行失败，抛出异常ExecutionError，且返回错误码为 not existed!；\\n\\n### 尝试自己撰写一个 case\\n\\n假设现在我们的目的是检查一下`SHOW JOBS` 的返回格式，可以这么操作：在 nebula-graph/tests/tck/features/job/(https://github.com/vesoft-inc/nebula-graph/tree/master/tests/tck/features/job) 下增加一个 JobCommands.feature 的文件\\n\\n```\\n@mintest                                                          #用于调试\\n\\nFeature: Job compact, flush, rebuild_index\\n\\n  Background:                                     # 选择数据集\\n    Given a graph with space named \\\"basketballplayer\\\"\\n\\n  Scenario: submit job\\n    When executing query:\\n      \\\"\\\"\\\"\\n      SUBMIT JOB COMPACT;\\n      \\\"\\\"\\\"\\n    Then the result should contain:\\n      | New Job Id |\\n      | /\\\\d+/          |              # 用正则表达式检查为正数\\n    When executing query:\\n      \\\"\\\"\\\"\\n      SUBMIT JOB FLUSH;\\n      \\\"\\\"\\\"\\n     When executing query:\\n      \\\"\\\"\\\"\\n      SUBMIT JOB STATS;\\n\\n      SHOW JOBS;\\n      \\\"\\\"\\\"\\n    Then the result should contain:   # 检查返回形式\\n      | Job Id | Command | Status  | Start Time                               | Stop Time                 |\\n      | /\\\\d+/  | \\\"STATS\\\"      | /\\\\w+/  | /\\\\d+-\\\\d+-\\\\d+T\\\\d+:\\\\d+:\\\\d+/ | /\\\\d+-\\\\d+-\\\\d+T\\\\d+:\\\\d+:\\\\d+/ |\\n```\\n\\n### 调试 case\\n\\n```\\nnebula-graph/tests> make fmt\\n```\\n\\n检查格式错误，并格式化文件。\\n\\n```\\nnebula-graph/tests>  pytest -m \\\"mintest\\\"\\n```\\n\\n运行刚撰写的 case，通常要来回更改多次。用`#`号注释。也可以用 `@skip` 标注跳过整个 Scenario。\\n\\n```\\nnebula-graph/tests>  pytest -n4\\n```\\n\\n如果内存有限，-n4 控制并发度。\\n\\n更多说明可以参见这里：https://github.com/vesoft-inc/nebula-graph/tree/master/tests#nebula-graph-test-manual 。\\n\\n### 通过 git 向 Nebula Graph repo 增加该 case\\n\\n如果所有的测试都已经通过，将调试标记 `@mintest` 去掉，通过 git 指令向 Nebula Graph 仓库提交一个 pull request，参考 [如何贡献](https://docs.nebula-graph.com.cn/2.0.1/15.contribution/how-to-contribute/) 。\\n\\n交流图数据库技术？加入 Nebula 交流群请先[填写下你的 Nebula 名片](https://wj.qq.com/s2/8321168/8e2f/)，Nebula 小助手会拉你进群~~\\n\",\"id\":5}',_binary '',5174),(48,'新增 | 官网博客','2022-07-19 15:08:30',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','POST','{\"pic\":\"https://www-cdn.nebula-graph.com.cn/nebula-blog/DockerImage01.png\",\"title\":\"前端 Docker 镜像体积优化\",\"author\":\"Jerry1\",\"description\":\"本文主要来讲述下开源的分布式图数据库 Nebula Graph 是如何将 Docker 应用到可视化界面中，并将镜像体积从 1.3G 减到 0.3G 。\",\"publish\":\"草稿\",\"content\":\"如果 2019 年技术圈有十大流行词，**容器化**肯定占有一席之地，随着 Docker 的风靡，前端领域应用到 Docker 的场景也越来越多，本文主要来讲述下开源的分布式图数据库 Nebula Graph 是如何将 Docker 应用到可视化界面中。\\n\\n## 为什么要用 Docker\\n\\n对于前端日常开发而言，有时也会用到 Docker，结合到 Nebula Graph Studio（分布式图数据库 Nebula Graph 的图形界面工具）使用 Docker 主要基于以下考虑:\\n\\n- **统一运行环境**：我们的工具背后有好几个服务组合在一起，诸如不同技术栈的现有服务，纯前端的静态资源。\\n- **用户使用成本低**：目前云服务还在开发中，想让用户对服务组合无感，能直接在本地一键启动应用并使用。\\n- **快速部署**：团队本就提供有 [Nebula镜像版本](https://github.com/vesoft-inc/nebula-docker-compose) 实践，给了我们前端一些参考和借鉴。\\n\\n## Docker 镜像的构建\\n\\n既然要使用 Docker 来承载我们的应用，就得将项目进行镜像构建。与所有 build 镜像类似，需要配置一份命名为[Dockerfile ](https://docs.docker.com/engine/reference/builder/)的文件，文件是一些步骤的描述，简单来说就是把项目复制到镜像里，并设置好启动方式：\\n\\n```shell\\n# 选择基础镜像\\nFROM node:10\\n# 设置工作目录\\nWORKDIR /nebula-web-console\\n# 把当前项目内容拷贝到镜像中的 /nebula-web-console 目录下\\nADD . /nebula-web-console\\n# 在镜像中下载前端依赖\\nRUN npm install\\n# 执行构建\\nRUN npm run build\\nEXPOSE 7001\\n# 镜像启动时执行的部署命令\\nCMD [\\\"npm\\\", \\\"run\\\", \\\"docker-start\\\"]\\n```\\n\\n## Docker 镜像体积优化\\n\\n如果按照上述的配置文件来构建 Docker 镜像，以我们的项目为例，将会生成一个体积约为 1.3GB 的镜像，这个看起来有点吓人，因为即使在网速快的用户电脑光下载镜像也需要等待不少时间，这是不能接受的。\\n\\n在调研了相应的资料后，了解到可以从以下几个方面缩小 Docker 镜像体积进行优化：\\n\\n### 基础镜像源的选择\\n\\n所谓基础镜像源，就是我们在进行构建步骤时，选择的一个基础环境（如上 `node:10` )，通过查看 [Dockerhub](https://hub.docker.com/_/node) 上有关 Node.js 的基础环境镜像时，我们会发现有**多个版本**，虽然都是 Node.js 相关基础镜像，但不同版本，他们除了 Node.js 版本不同外，在**内部集成的环境也不一样**，例如带有 [alpine](https://yeasy.gitbooks.io/docker_practice/cases/os/alpine.html) 的版本，相当于是一个比较精巧的 Linux 系统镜像，在此版本运行的容器中会发现不存在我们常规系统中所附带的工具，比如 bash、curl 等，由此来缩小体积。\\n\\n根据项目实际需要，当我把基础镜像换为 [alpine](https://yeasy.gitbooks.io/docker_practice/cases/os/alpine.html) 版本后，再次进行构建，此时镜像体积已大幅度减小，从 1.3GB 直降为 500+MB，体积优化效果明显，所以当你发现自己构建的镜像体积过大时，可以**考虑从更换基础镜像源的方式**来着手，看看是否使用了过于臃肿的镜像源。\\n\\n### Multi-stage 构建镜像\\n\\n所谓 [multi-stage](https://docs.docker.com/develop/develop-images/multistage-build/) 即是 Docker 镜像构建的时候采取的策略，详细可点击链接提供的资料。\\n\\n#### Docker 构建规则\\n\\n简言之就是利用 Docker 构建提供的规则：Dockerfile 的操作都会增加一个所谓镜像的“层”，每一层都会增加镜像体积，通过采用多步骤策略，每一步骤包含具有相同意义的一系列操作（例如构建，部署），步骤与步骤之间通过产物镜像引用的方式，由此来缩减最终构建镜像所需要的层数，具体操作比如：\\n\\n```shell\\n# 设置第一步骤产生的镜像，并命名为builder\\nFROM node:10-alpine as builder\\nWORKDIR /nebula-web-console\\n# 复制当前项目内容至镜像中\\nADD . /nebula-web-console\\n# 进行相应的构建\\nRUN npm install\\nRUN npm run build\\n....\\n\\n# 进行第二步骤构建\\nFROM node:10-alpine\\nWORKDIR /nebula-web-console\\n# 复制第一步构建镜像的产物内容至当前镜像，只用到了一层镜像层从而节约了之前构建步骤的镜像层数\\nCOPY --from=builder . /nebula-web-console\\nCMD [\\\"npm\\\", \\\"run\\\", \\\"docker-start\\\"]\\n\\n```\\n\\n### .dockerignore\\n\\n类似我们熟悉的 `.gitignore` ，就是当我们在进行 `COPY` 或 `ADD` 文件复制操作时，将不必要的文件忽略掉（诸如文档文件、git文件、node_modules以及一些非生成必要文件等），从而减小镜像体积，更详细内容可参考文档连接：[.dockerignore](https://docs.docker.com/engine/reference/builder/#dockerignore-file)。\\n\\n### 操作合并\\n\\n基于上述提到在 Dockerfile 构建镜像的过程做，每一个操作都会在前一步镜像基础上增加一“层”，可以利用 `&` 来合并多个操作，减少层数，比如：\\n```shell\\n# 以下两个操作分别代表两层\\nRUN npm install\\nRUN npm run build\\n```\\n改为：\\n```shell\\n# 使用 & 后变了为一层\\nRUN npm install && npm run build\\n```\\n由此我们减少了层数的增加，即减少了镜像的体积。同时，在构建镜像的过程中，我们也可以通过在达到相同目的的前提下，尽量减少不必要的操作来减少“层数”的添加。\\n\\n### 前端常规性体积优化\\n\\n- 压缩丑化代码，移除源码\\n     此操作可以放在构建步骤阶段，这样会进一步缩小镜像的文件体积。\\n- node_modules 只下载生产环境需要的代码\\n     此操作可以放在部署阶段，只下载生产环境所需要的第三方依赖代码: `npm install --production` 。\\n- 公共资源放在CDN\\n     如果镜像被期待运行在联网环境，可以考虑将一些体积相比较大的公共文件（图片、第三方库等）放在CDN服务 器上，将部分资源剥离出去，也会进一步缩小体积。\\n- ...\\n\\n以上只作为一个线索参考，更多前端常规的优化步骤，都可以迁移至镜像中进行，毕竟和我们本地开发一样，镜像构建也是一个运行代码的环境嘛。\\n\\n## 小结\\n\\n以上便是我在此次使用 Docker 镜像来运行我们 [Nebula Studio](Nebula/blob/master/README.md) 所用到的一些优化镜像体积的方法，希望能给需要的人一些帮助和参考，可能还有一些认识不准确的地方，欢迎指出，同样欢迎你来试用 Nebula Graph Studio：[Nebula](Nebula) \\n\",\"id\":\"9\"}',_binary '',5197),(49,'新增 | 官网博客','2022-07-19 15:09:35',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','POST','{\"pic\":\"https://www-cdn.nebula-graph.com.cn/nebula-blog/DockerImage01.png\",\"title\":\"前端 Docker 镜像体积优化\",\"author\":\"Jerry2\",\"description\":\"本文主要来讲述下开源的分布式图数据库 Nebula Graph 是如何将 Docker 应用到可视化界面中，并将镜像体积从 1.3G 减到 0.3G 。\",\"publish\":\"草稿\",\"content\":\"如果 2019 年技术圈有十大流行词，**容器化**肯定占有一席之地，随着 Docker 的风靡，前端领域应用到 Docker 的场景也越来越多，本文主要来讲述下开源的分布式图数据库 Nebula Graph 是如何将 Docker 应用到可视化界面中。\\n\\n## 为什么要用 Docker\\n\\n对于前端日常开发而言，有时也会用到 Docker，结合到 Nebula Graph Studio（分布式图数据库 Nebula Graph 的图形界面工具）使用 Docker 主要基于以下考虑:\\n\\n- **统一运行环境**：我们的工具背后有好几个服务组合在一起，诸如不同技术栈的现有服务，纯前端的静态资源。\\n- **用户使用成本低**：目前云服务还在开发中，想让用户对服务组合无感，能直接在本地一键启动应用并使用。\\n- **快速部署**：团队本就提供有 [Nebula镜像版本](https://github.com/vesoft-inc/nebula-docker-compose) 实践，给了我们前端一些参考和借鉴。\\n\\n## Docker 镜像的构建\\n\\n既然要使用 Docker 来承载我们的应用，就得将项目进行镜像构建。与所有 build 镜像类似，需要配置一份命名为[Dockerfile ](https://docs.docker.com/engine/reference/builder/)的文件，文件是一些步骤的描述，简单来说就是把项目复制到镜像里，并设置好启动方式：\\n\\n```shell\\n# 选择基础镜像\\nFROM node:10\\n# 设置工作目录\\nWORKDIR /nebula-web-console\\n# 把当前项目内容拷贝到镜像中的 /nebula-web-console 目录下\\nADD . /nebula-web-console\\n# 在镜像中下载前端依赖\\nRUN npm install\\n# 执行构建\\nRUN npm run build\\nEXPOSE 7001\\n# 镜像启动时执行的部署命令\\nCMD [\\\"npm\\\", \\\"run\\\", \\\"docker-start\\\"]\\n```\\n\\n## Docker 镜像体积优化\\n\\n如果按照上述的配置文件来构建 Docker 镜像，以我们的项目为例，将会生成一个体积约为 1.3GB 的镜像，这个看起来有点吓人，因为即使在网速快的用户电脑光下载镜像也需要等待不少时间，这是不能接受的。\\n\\n在调研了相应的资料后，了解到可以从以下几个方面缩小 Docker 镜像体积进行优化：\\n\\n### 基础镜像源的选择\\n\\n所谓基础镜像源，就是我们在进行构建步骤时，选择的一个基础环境（如上 `node:10` )，通过查看 [Dockerhub](https://hub.docker.com/_/node) 上有关 Node.js 的基础环境镜像时，我们会发现有**多个版本**，虽然都是 Node.js 相关基础镜像，但不同版本，他们除了 Node.js 版本不同外，在**内部集成的环境也不一样**，例如带有 [alpine](https://yeasy.gitbooks.io/docker_practice/cases/os/alpine.html) 的版本，相当于是一个比较精巧的 Linux 系统镜像，在此版本运行的容器中会发现不存在我们常规系统中所附带的工具，比如 bash、curl 等，由此来缩小体积。\\n\\n根据项目实际需要，当我把基础镜像换为 [alpine](https://yeasy.gitbooks.io/docker_practice/cases/os/alpine.html) 版本后，再次进行构建，此时镜像体积已大幅度减小，从 1.3GB 直降为 500+MB，体积优化效果明显，所以当你发现自己构建的镜像体积过大时，可以**考虑从更换基础镜像源的方式**来着手，看看是否使用了过于臃肿的镜像源。\\n\\n### Multi-stage 构建镜像\\n\\n所谓 [multi-stage](https://docs.docker.com/develop/develop-images/multistage-build/) 即是 Docker 镜像构建的时候采取的策略，详细可点击链接提供的资料。\\n\\n#### Docker 构建规则\\n\\n简言之就是利用 Docker 构建提供的规则：Dockerfile 的操作都会增加一个所谓镜像的“层”，每一层都会增加镜像体积，通过采用多步骤策略，每一步骤包含具有相同意义的一系列操作（例如构建，部署），步骤与步骤之间通过产物镜像引用的方式，由此来缩减最终构建镜像所需要的层数，具体操作比如：\\n\\n```shell\\n# 设置第一步骤产生的镜像，并命名为builder\\nFROM node:10-alpine as builder\\nWORKDIR /nebula-web-console\\n# 复制当前项目内容至镜像中\\nADD . /nebula-web-console\\n# 进行相应的构建\\nRUN npm install\\nRUN npm run build\\n....\\n\\n# 进行第二步骤构建\\nFROM node:10-alpine\\nWORKDIR /nebula-web-console\\n# 复制第一步构建镜像的产物内容至当前镜像，只用到了一层镜像层从而节约了之前构建步骤的镜像层数\\nCOPY --from=builder . /nebula-web-console\\nCMD [\\\"npm\\\", \\\"run\\\", \\\"docker-start\\\"]\\n\\n```\\n\\n### .dockerignore\\n\\n类似我们熟悉的 `.gitignore` ，就是当我们在进行 `COPY` 或 `ADD` 文件复制操作时，将不必要的文件忽略掉（诸如文档文件、git文件、node_modules以及一些非生成必要文件等），从而减小镜像体积，更详细内容可参考文档连接：[.dockerignore](https://docs.docker.com/engine/reference/builder/#dockerignore-file)。\\n\\n### 操作合并\\n\\n基于上述提到在 Dockerfile 构建镜像的过程做，每一个操作都会在前一步镜像基础上增加一“层”，可以利用 `&` 来合并多个操作，减少层数，比如：\\n```shell\\n# 以下两个操作分别代表两层\\nRUN npm install\\nRUN npm run build\\n```\\n改为：\\n```shell\\n# 使用 & 后变了为一层\\nRUN npm install && npm run build\\n```\\n由此我们减少了层数的增加，即减少了镜像的体积。同时，在构建镜像的过程中，我们也可以通过在达到相同目的的前提下，尽量减少不必要的操作来减少“层数”的添加。\\n\\n### 前端常规性体积优化\\n\\n- 压缩丑化代码，移除源码\\n     此操作可以放在构建步骤阶段，这样会进一步缩小镜像的文件体积。\\n- node_modules 只下载生产环境需要的代码\\n     此操作可以放在部署阶段，只下载生产环境所需要的第三方依赖代码: `npm install --production` 。\\n- 公共资源放在CDN\\n     如果镜像被期待运行在联网环境，可以考虑将一些体积相比较大的公共文件（图片、第三方库等）放在CDN服务 器上，将部分资源剥离出去，也会进一步缩小体积。\\n- ...\\n\\n以上只作为一个线索参考，更多前端常规的优化步骤，都可以迁移至镜像中进行，毕竟和我们本地开发一样，镜像构建也是一个运行代码的环境嘛。\\n\\n## 小结\\n\\n以上便是我在此次使用 Docker 镜像来运行我们 [Nebula Studio](Nebula/blob/master/README.md) 所用到的一些优化镜像体积的方法，希望能给需要的人一些帮助和参考，可能还有一些认识不准确的地方，欢迎指出，同样欢迎你来试用 Nebula Graph Studio：[Nebula](Nebula) \\n\",\"id\":12}',_binary '',5161),(50,'修改 | 官网博客','2022-07-19 15:10:53',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','PUT','{\"pic\":\"https://www-cdn.nebula-graph.com.cn/nebula-blog/bdd.png\",\"title\":\"基于 BDD 理论的 Nebula 集成测试框架重构（下篇）\",\"author\":\"11\",\"description\":\"这回，我们来给 Nebula Graph 添加一个测试用例，步骤很简单，首先：打开文章，然后准备好环境，开发 case，提交上线…\",\"publish\":true,\"content\":\"## 引子\\n\\n由于 Nebula Graph 在持续研发过程中会频繁地更改返回数据的格式，这样就会造成了上层应用程序无法正确解析数据。\\n\\n比如在 v2.0.0 发布的时候，改变了 SHOW JOBS 的格式，造成了 Studio 解析的时候页面崩溃。\\n\\n为了避免再次发生这样的悲剧问题，可以使用 Nebula Graph 提供的测试框架，方便地增加测试用例。\\n\\n## 环境准备   \\n\\n按照文档[《源码编译安装》](https://docs.nebula-graph.com.cn/2.0.1/4.deployment-and-installation/2.compile-and-install-nebula-graph/1.install-nebula-graph-by-compiling-the-source-code/) 中所示，我们可以参考以下步骤进行操作：\\n\\na. 准备一台开发机，这里给出了开发环境的配置要求。\\n\\n- Python3 要求的最低版本为 Python 3.7.\\n\\n```\\npython3 --version\\n``` \\n\\nb. 按照文档中步骤编译源代码。选择 master 版本,并拉一个分支\\n\\n```\\ngit checkout -b  dev tck\\n```\\n\\n具体步骤可以见 Nebula 文档站中如何贡献中的 GitHub [使用步骤部分](https://docs.nebula-graph.com.cn/2.0.1/15.contribution/how-to-contribute/) 。\\n\\nc. 安装 case 运行环境\\n\\n```\\n$ cd nebula-graph/tests/\\n$ make init-all\\n```\\n\\n如果遇到模块版本过低，可以根据提示升级版本，比如：命令 `pip3 install --upgrade keyrings.alt` 。\\n\\nd. 运行已有case \\n\\n```\\nmake test\\n```\\n\\n## 开发 case\\n\\n### 研究一下已有 case\\n\\n大多数已有 case 都在 https://github.com/vesoft-inc/nebula-graph/tree/master/tests/tck/features 目录下，根据主要功能放在不同目录下。\\n\\n例如，以最常用的 MATCH 功能举例。打开 GitHub 目录下的 [match/MatchById.feature](https://github.com/vesoft-inc/nebula-graph/blob/master/tests/tck/features/match/MatchById.feature) 文件\\n\\n```\\nFeature: Match By Id\\n\\n  Background:\\n    Given a graph with space named \\\"basketballplayer\\\"     # 选择一个已有的单元测试数据集 basketballplayer\\n\\n  Scenario: single node                                   # 给这个 case 取个名字\\n    When executing query:                              # 以下三引号之间的部分，为发送给 Nebula Graph 的文本。\\n      \\\"\\\"\\\"                                                            # 这句话的目的，是获vid为James Harden的点\\n      MATCH (n) WHERE id(n) == \'James Harden\' RETURN n\\n      \\\"\\\"\\\"                                                            # Then 表示测试结果匹配                \\n    Then the result should be, in any order, with relax comparison:\\n      | n                |                                           # 期望获取的文本结果，应该是这样一个格式。列名为 n\\n      | (\\\"James Harden\\\") |                                # 内容为 \\\"James Harden\\\", 圆括号表示这是一个点\\n    When executing query:                             # 开始下一个命令。\\n      \\\"\\\"\\\"\\n      MATCH (n) WHERE id(n) == \'not_exist_vertex\' RETURN n\\n      \\\"\\\"\\\"\\n    Then the result should be, in any order, with relax comparison:\\n      | n |\\n```\\n\\nnebula-test 是基于 BDD 思想撰写的，这些 feature 文件基本是自然语言（gherkin文本），BDD 介绍文章可参考：[《基于 BDD 理论的 Nebula 集成测试框架重构（上篇）》](https://mp.weixin.qq.com/s/gw1hJetflofQc2aiiZ6frA)。\\n\\n这里简单地解释一下 case 用例模版主要的格式：\\n\\n- Feature：介绍整个文本是做什么的；\\n- Background：设置一下公共的运行环境，例子中，选用了一个已经存在的数据集 basketballplayer（建立了schema，index，写入了数据）；\\n- Scenario：一组 `When-Then` 的组合，是一个最小的并发执行单位；\\n- When executing query：向 Nebula Graph 发送一组命令；\\n- Then the result should be：从 Nebula Graph 获取结果，和下面的期望结果对比；\\n\\n\\n这个对比方式可以有以下几种：\\n\\n- the result should be：需完全一样 （行、列、单元格内容都必须一模一样）；\\n- the result should contain：只包含以下内容即可；\\n- the result should be, in any order：返回结果的行顺序无关（对于行 1 和行 2 的顺序没有要求）；\\n- the result should be, in any order, with relax comparison：结果集需要是以下形式，行顺序无关，并且至少包括以下内容（例如，每个单元格至少包括\\\"Tiago Splitter\\\"，但可以比这个多）；\\n- the execution should be successful：返回码为成功；\\n- an ExecutionError should be raised at runtime: not existed! 执行失败，抛出异常ExecutionError，且返回错误码为 not existed!；\\n\\n### 尝试自己撰写一个 case\\n\\n假设现在我们的目的是检查一下`SHOW JOBS` 的返回格式，可以这么操作：在 nebula-graph/tests/tck/features/job/(https://github.com/vesoft-inc/nebula-graph/tree/master/tests/tck/features/job) 下增加一个 JobCommands.feature 的文件\\n\\n```\\n@mintest                                                          #用于调试\\n\\nFeature: Job compact, flush, rebuild_index\\n\\n  Background:                                     # 选择数据集\\n    Given a graph with space named \\\"basketballplayer\\\"\\n\\n  Scenario: submit job\\n    When executing query:\\n      \\\"\\\"\\\"\\n      SUBMIT JOB COMPACT;\\n      \\\"\\\"\\\"\\n    Then the result should contain:\\n      | New Job Id |\\n      | /\\\\d+/          |              # 用正则表达式检查为正数\\n    When executing query:\\n      \\\"\\\"\\\"\\n      SUBMIT JOB FLUSH;\\n      \\\"\\\"\\\"\\n     When executing query:\\n      \\\"\\\"\\\"\\n      SUBMIT JOB STATS;\\n\\n      SHOW JOBS;\\n      \\\"\\\"\\\"\\n    Then the result should contain:   # 检查返回形式\\n      | Job Id | Command | Status  | Start Time                               | Stop Time                 |\\n      | /\\\\d+/  | \\\"STATS\\\"      | /\\\\w+/  | /\\\\d+-\\\\d+-\\\\d+T\\\\d+:\\\\d+:\\\\d+/ | /\\\\d+-\\\\d+-\\\\d+T\\\\d+:\\\\d+:\\\\d+/ |\\n```\\n\\n### 调试 case\\n\\n```\\nnebula-graph/tests> make fmt\\n```\\n\\n检查格式错误，并格式化文件。\\n\\n```\\nnebula-graph/tests>  pytest -m \\\"mintest\\\"\\n```\\n\\n运行刚撰写的 case，通常要来回更改多次。用`#`号注释。也可以用 `@skip` 标注跳过整个 Scenario。\\n\\n```\\nnebula-graph/tests>  pytest -n4\\n```\\n\\n如果内存有限，-n4 控制并发度。\\n\\n更多说明可以参见这里：https://github.com/vesoft-inc/nebula-graph/tree/master/tests#nebula-graph-test-manual 。\\n\\n### 通过 git 向 Nebula Graph repo 增加该 case\\n\\n如果所有的测试都已经通过，将调试标记 `@mintest` 去掉，通过 git 指令向 Nebula Graph 仓库提交一个 pull request，参考 [如何贡献](https://docs.nebula-graph.com.cn/2.0.1/15.contribution/how-to-contribute/) 。\\n\\n交流图数据库技术？加入 Nebula 交流群请先[填写下你的 Nebula 名片](https://wj.qq.com/s2/8321168/8e2f/)，Nebula 小助手会拉你进群~~\\n\",\"id\":5}',_binary '',5271),(51,'修改 | 官网博客','2022-07-19 15:12:27',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','PUT','{\"pic\":\"https://www-cdn.nebula-graph.com.cn/nebula-blog/DockerImage01.png\",\"title\":\"前端 Docker 镜像体积优化\",\"author\":\"Jerry233\",\"description\":\"本文主要来讲述下开源的分布式图数据库 Nebula Graph 是如何将 Docker 应用到可视化界面中，并将镜像体积从 1.3G 减到 0.3G 。\",\"publish\":\"草稿\",\"content\":\"如果 2019 年技术圈有十大流行词，**容器化**肯定占有一席之地，随着 Docker 的风靡，前端领域应用到 Docker 的场景也越来越多，本文主要来讲述下开源的分布式图数据库 Nebula Graph 是如何将 Docker 应用到可视化界面中。\\n\\n## 为什么要用 Docker\\n\\n对于前端日常开发而言，有时也会用到 Docker，结合到 Nebula Graph Studio（分布式图数据库 Nebula Graph 的图形界面工具）使用 Docker 主要基于以下考虑:\\n\\n- **统一运行环境**：我们的工具背后有好几个服务组合在一起，诸如不同技术栈的现有服务，纯前端的静态资源。\\n- **用户使用成本低**：目前云服务还在开发中，想让用户对服务组合无感，能直接在本地一键启动应用并使用。\\n- **快速部署**：团队本就提供有 [Nebula镜像版本](https://github.com/vesoft-inc/nebula-docker-compose) 实践，给了我们前端一些参考和借鉴。\\n\\n## Docker 镜像的构建\\n\\n既然要使用 Docker 来承载我们的应用，就得将项目进行镜像构建。与所有 build 镜像类似，需要配置一份命名为[Dockerfile ](https://docs.docker.com/engine/reference/builder/)的文件，文件是一些步骤的描述，简单来说就是把项目复制到镜像里，并设置好启动方式：\\n\\n```shell\\n# 选择基础镜像\\nFROM node:10\\n# 设置工作目录\\nWORKDIR /nebula-web-console\\n# 把当前项目内容拷贝到镜像中的 /nebula-web-console 目录下\\nADD . /nebula-web-console\\n# 在镜像中下载前端依赖\\nRUN npm install\\n# 执行构建\\nRUN npm run build\\nEXPOSE 7001\\n# 镜像启动时执行的部署命令\\nCMD [\\\"npm\\\", \\\"run\\\", \\\"docker-start\\\"]\\n```\\n\\n## Docker 镜像体积优化\\n\\n如果按照上述的配置文件来构建 Docker 镜像，以我们的项目为例，将会生成一个体积约为 1.3GB 的镜像，这个看起来有点吓人，因为即使在网速快的用户电脑光下载镜像也需要等待不少时间，这是不能接受的。\\n\\n在调研了相应的资料后，了解到可以从以下几个方面缩小 Docker 镜像体积进行优化：\\n\\n### 基础镜像源的选择\\n\\n所谓基础镜像源，就是我们在进行构建步骤时，选择的一个基础环境（如上 `node:10` )，通过查看 [Dockerhub](https://hub.docker.com/_/node) 上有关 Node.js 的基础环境镜像时，我们会发现有**多个版本**，虽然都是 Node.js 相关基础镜像，但不同版本，他们除了 Node.js 版本不同外，在**内部集成的环境也不一样**，例如带有 [alpine](https://yeasy.gitbooks.io/docker_practice/cases/os/alpine.html) 的版本，相当于是一个比较精巧的 Linux 系统镜像，在此版本运行的容器中会发现不存在我们常规系统中所附带的工具，比如 bash、curl 等，由此来缩小体积。\\n\\n根据项目实际需要，当我把基础镜像换为 [alpine](https://yeasy.gitbooks.io/docker_practice/cases/os/alpine.html) 版本后，再次进行构建，此时镜像体积已大幅度减小，从 1.3GB 直降为 500+MB，体积优化效果明显，所以当你发现自己构建的镜像体积过大时，可以**考虑从更换基础镜像源的方式**来着手，看看是否使用了过于臃肿的镜像源。\\n\\n### Multi-stage 构建镜像\\n\\n所谓 [multi-stage](https://docs.docker.com/develop/develop-images/multistage-build/) 即是 Docker 镜像构建的时候采取的策略，详细可点击链接提供的资料。\\n\\n#### Docker 构建规则\\n\\n简言之就是利用 Docker 构建提供的规则：Dockerfile 的操作都会增加一个所谓镜像的“层”，每一层都会增加镜像体积，通过采用多步骤策略，每一步骤包含具有相同意义的一系列操作（例如构建，部署），步骤与步骤之间通过产物镜像引用的方式，由此来缩减最终构建镜像所需要的层数，具体操作比如：\\n\\n```shell\\n# 设置第一步骤产生的镜像，并命名为builder\\nFROM node:10-alpine as builder\\nWORKDIR /nebula-web-console\\n# 复制当前项目内容至镜像中\\nADD . /nebula-web-console\\n# 进行相应的构建\\nRUN npm install\\nRUN npm run build\\n....\\n\\n# 进行第二步骤构建\\nFROM node:10-alpine\\nWORKDIR /nebula-web-console\\n# 复制第一步构建镜像的产物内容至当前镜像，只用到了一层镜像层从而节约了之前构建步骤的镜像层数\\nCOPY --from=builder . /nebula-web-console\\nCMD [\\\"npm\\\", \\\"run\\\", \\\"docker-start\\\"]\\n\\n```\\n\\n### .dockerignore\\n\\n类似我们熟悉的 `.gitignore` ，就是当我们在进行 `COPY` 或 `ADD` 文件复制操作时，将不必要的文件忽略掉（诸如文档文件、git文件、node_modules以及一些非生成必要文件等），从而减小镜像体积，更详细内容可参考文档连接：[.dockerignore](https://docs.docker.com/engine/reference/builder/#dockerignore-file)。\\n\\n### 操作合并\\n\\n基于上述提到在 Dockerfile 构建镜像的过程做，每一个操作都会在前一步镜像基础上增加一“层”，可以利用 `&` 来合并多个操作，减少层数，比如：\\n```shell\\n# 以下两个操作分别代表两层\\nRUN npm install\\nRUN npm run build\\n```\\n改为：\\n```shell\\n# 使用 & 后变了为一层\\nRUN npm install && npm run build\\n```\\n由此我们减少了层数的增加，即减少了镜像的体积。同时，在构建镜像的过程中，我们也可以通过在达到相同目的的前提下，尽量减少不必要的操作来减少“层数”的添加。\\n\\n### 前端常规性体积优化\\n\\n- 压缩丑化代码，移除源码\\n     此操作可以放在构建步骤阶段，这样会进一步缩小镜像的文件体积。\\n- node_modules 只下载生产环境需要的代码\\n     此操作可以放在部署阶段，只下载生产环境所需要的第三方依赖代码: `npm install --production` 。\\n- 公共资源放在CDN\\n     如果镜像被期待运行在联网环境，可以考虑将一些体积相比较大的公共文件（图片、第三方库等）放在CDN服务 器上，将部分资源剥离出去，也会进一步缩小体积。\\n- ...\\n\\n以上只作为一个线索参考，更多前端常规的优化步骤，都可以迁移至镜像中进行，毕竟和我们本地开发一样，镜像构建也是一个运行代码的环境嘛。\\n\\n## 小结\\n\\n以上便是我在此次使用 Docker 镜像来运行我们 [Nebula Studio](Nebula/blob/master/README.md) 所用到的一些优化镜像体积的方法，希望能给需要的人一些帮助和参考，可能还有一些认识不准确的地方，欢迎指出，同样欢迎你来试用 Nebula Graph Studio：[Nebula](Nebula) \\n\",\"id\":13}',_binary '',5209),(52,'修改 | 官网博客','2022-07-19 15:13:51',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','PUT','{\"pic\":\"https://www-cdn.nebula-graph.com.cn/nebula-blog/DockerImage01.png\",\"title\":\"前端 Docker 镜像体积优化\",\"author\":\"Jerry233\",\"description\":\"本文主要来讲述下开源的分布式图数据库 Nebula Graph 是如何将 Docker 应用到可视化界面中，并将镜像体积从 1.3G 减到 0.3G 。\",\"publish\":\"发布\",\"content\":\"如果 2019 年技术圈有十大流行词，**容器化**肯定占有一席之地，随着 Docker 的风靡，前端领域应用到 Docker 的场景也越来越多，本文主要来讲述下开源的分布式图数据库 Nebula Graph 是如何将 Docker 应用到可视化界面中。\\n\\n## 为什么要用 Docker\\n\\n对于前端日常开发而言，有时也会用到 Docker，结合到 Nebula Graph Studio（分布式图数据库 Nebula Graph 的图形界面工具）使用 Docker 主要基于以下考虑:\\n\\n- **统一运行环境**：我们的工具背后有好几个服务组合在一起，诸如不同技术栈的现有服务，纯前端的静态资源。\\n- **用户使用成本低**：目前云服务还在开发中，想让用户对服务组合无感，能直接在本地一键启动应用并使用。\\n- **快速部署**：团队本就提供有 [Nebula镜像版本](https://github.com/vesoft-inc/nebula-docker-compose) 实践，给了我们前端一些参考和借鉴。\\n\\n## Docker 镜像的构建\\n\\n既然要使用 Docker 来承载我们的应用，就得将项目进行镜像构建。与所有 build 镜像类似，需要配置一份命名为[Dockerfile ](https://docs.docker.com/engine/reference/builder/)的文件，文件是一些步骤的描述，简单来说就是把项目复制到镜像里，并设置好启动方式：\\n\\n```shell\\n# 选择基础镜像\\nFROM node:10\\n# 设置工作目录\\nWORKDIR /nebula-web-console\\n# 把当前项目内容拷贝到镜像中的 /nebula-web-console 目录下\\nADD . /nebula-web-console\\n# 在镜像中下载前端依赖\\nRUN npm install\\n# 执行构建\\nRUN npm run build\\nEXPOSE 7001\\n# 镜像启动时执行的部署命令\\nCMD [\\\"npm\\\", \\\"run\\\", \\\"docker-start\\\"]\\n```\\n\\n## Docker 镜像体积优化\\n\\n如果按照上述的配置文件来构建 Docker 镜像，以我们的项目为例，将会生成一个体积约为 1.3GB 的镜像，这个看起来有点吓人，因为即使在网速快的用户电脑光下载镜像也需要等待不少时间，这是不能接受的。\\n\\n在调研了相应的资料后，了解到可以从以下几个方面缩小 Docker 镜像体积进行优化：\\n\\n### 基础镜像源的选择\\n\\n所谓基础镜像源，就是我们在进行构建步骤时，选择的一个基础环境（如上 `node:10` )，通过查看 [Dockerhub](https://hub.docker.com/_/node) 上有关 Node.js 的基础环境镜像时，我们会发现有**多个版本**，虽然都是 Node.js 相关基础镜像，但不同版本，他们除了 Node.js 版本不同外，在**内部集成的环境也不一样**，例如带有 [alpine](https://yeasy.gitbooks.io/docker_practice/cases/os/alpine.html) 的版本，相当于是一个比较精巧的 Linux 系统镜像，在此版本运行的容器中会发现不存在我们常规系统中所附带的工具，比如 bash、curl 等，由此来缩小体积。\\n\\n根据项目实际需要，当我把基础镜像换为 [alpine](https://yeasy.gitbooks.io/docker_practice/cases/os/alpine.html) 版本后，再次进行构建，此时镜像体积已大幅度减小，从 1.3GB 直降为 500+MB，体积优化效果明显，所以当你发现自己构建的镜像体积过大时，可以**考虑从更换基础镜像源的方式**来着手，看看是否使用了过于臃肿的镜像源。\\n\\n### Multi-stage 构建镜像\\n\\n所谓 [multi-stage](https://docs.docker.com/develop/develop-images/multistage-build/) 即是 Docker 镜像构建的时候采取的策略，详细可点击链接提供的资料。\\n\\n#### Docker 构建规则\\n\\n简言之就是利用 Docker 构建提供的规则：Dockerfile 的操作都会增加一个所谓镜像的“层”，每一层都会增加镜像体积，通过采用多步骤策略，每一步骤包含具有相同意义的一系列操作（例如构建，部署），步骤与步骤之间通过产物镜像引用的方式，由此来缩减最终构建镜像所需要的层数，具体操作比如：\\n\\n```shell\\n# 设置第一步骤产生的镜像，并命名为builder\\nFROM node:10-alpine as builder\\nWORKDIR /nebula-web-console\\n# 复制当前项目内容至镜像中\\nADD . /nebula-web-console\\n# 进行相应的构建\\nRUN npm install\\nRUN npm run build\\n....\\n\\n# 进行第二步骤构建\\nFROM node:10-alpine\\nWORKDIR /nebula-web-console\\n# 复制第一步构建镜像的产物内容至当前镜像，只用到了一层镜像层从而节约了之前构建步骤的镜像层数\\nCOPY --from=builder . /nebula-web-console\\nCMD [\\\"npm\\\", \\\"run\\\", \\\"docker-start\\\"]\\n\\n```\\n\\n### .dockerignore\\n\\n类似我们熟悉的 `.gitignore` ，就是当我们在进行 `COPY` 或 `ADD` 文件复制操作时，将不必要的文件忽略掉（诸如文档文件、git文件、node_modules以及一些非生成必要文件等），从而减小镜像体积，更详细内容可参考文档连接：[.dockerignore](https://docs.docker.com/engine/reference/builder/#dockerignore-file)。\\n\\n### 操作合并\\n\\n基于上述提到在 Dockerfile 构建镜像的过程做，每一个操作都会在前一步镜像基础上增加一“层”，可以利用 `&` 来合并多个操作，减少层数，比如：\\n```shell\\n# 以下两个操作分别代表两层\\nRUN npm install\\nRUN npm run build\\n```\\n改为：\\n```shell\\n# 使用 & 后变了为一层\\nRUN npm install && npm run build\\n```\\n由此我们减少了层数的增加，即减少了镜像的体积。同时，在构建镜像的过程中，我们也可以通过在达到相同目的的前提下，尽量减少不必要的操作来减少“层数”的添加。\\n\\n### 前端常规性体积优化\\n\\n- 压缩丑化代码，移除源码\\n     此操作可以放在构建步骤阶段，这样会进一步缩小镜像的文件体积。\\n- node_modules 只下载生产环境需要的代码\\n     此操作可以放在部署阶段，只下载生产环境所需要的第三方依赖代码: `npm install --production` 。\\n- 公共资源放在CDN\\n     如果镜像被期待运行在联网环境，可以考虑将一些体积相比较大的公共文件（图片、第三方库等）放在CDN服务 器上，将部分资源剥离出去，也会进一步缩小体积。\\n- ...\\n\\n以上只作为一个线索参考，更多前端常规的优化步骤，都可以迁移至镜像中进行，毕竟和我们本地开发一样，镜像构建也是一个运行代码的环境嘛。\\n\\n## 小结\\n\\n以上便是我在此次使用 Docker 镜像来运行我们 [Nebula Studio](Nebula/blob/master/README.md) 所用到的一些优化镜像体积的方法，希望能给需要的人一些帮助和参考，可能还有一些认识不准确的地方，欢迎指出，同样欢迎你来试用 Nebula Graph Studio：[Nebula](Nebula) \\n\",\"id\":13}',_binary '',5256),(53,'修改 | 官网博客','2022-07-19 15:17:53',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','PUT','{\"pic\":\"https://www-cdn.nebula-graph.com.cn/nebula-blog/DockerImage01.png\",\"title\":\"前端 Docker 镜像体积优化\",\"author\":\"Jerry233\",\"description\":\"本文主要来讲述下开源的分布式图数据库 Nebula Graph 是如何将 Docker 应用到可视化界面中，并将镜像体积从 1.3G 减到 0.3G 。\",\"publish\":true,\"content\":\"如果 2019 年技术圈有十大流行词，**容器化**肯定占有一席之地，随着 Docker 的风靡，前端领域应用到 Docker 的场景也越来越多，本文主要来讲述下开源的分布式图数据库 Nebula Graph 是如何将 Docker 应用到可视化界面中。\\n\\n## 为什么要用 Docker\\n\\n对于前端日常开发而言，有时也会用到 Docker，结合到 Nebula Graph Studio（分布式图数据库 Nebula Graph 的图形界面工具）使用 Docker 主要基于以下考虑:\\n\\n- **统一运行环境**：我们的工具背后有好几个服务组合在一起，诸如不同技术栈的现有服务，纯前端的静态资源。\\n- **用户使用成本低**：目前云服务还在开发中，想让用户对服务组合无感，能直接在本地一键启动应用并使用。\\n- **快速部署**：团队本就提供有 [Nebula镜像版本](https://github.com/vesoft-inc/nebula-docker-compose) 实践，给了我们前端一些参考和借鉴。\\n\\n## Docker 镜像的构建\\n\\n既然要使用 Docker 来承载我们的应用，就得将项目进行镜像构建。与所有 build 镜像类似，需要配置一份命名为[Dockerfile ](https://docs.docker.com/engine/reference/builder/)的文件，文件是一些步骤的描述，简单来说就是把项目复制到镜像里，并设置好启动方式：\\n\\n```shell\\n# 选择基础镜像\\nFROM node:10\\n# 设置工作目录\\nWORKDIR /nebula-web-console\\n# 把当前项目内容拷贝到镜像中的 /nebula-web-console 目录下\\nADD . /nebula-web-console\\n# 在镜像中下载前端依赖\\nRUN npm install\\n# 执行构建\\nRUN npm run build\\nEXPOSE 7001\\n# 镜像启动时执行的部署命令\\nCMD [\\\"npm\\\", \\\"run\\\", \\\"docker-start\\\"]\\n```\\n\\n## Docker 镜像体积优化\\n\\n如果按照上述的配置文件来构建 Docker 镜像，以我们的项目为例，将会生成一个体积约为 1.3GB 的镜像，这个看起来有点吓人，因为即使在网速快的用户电脑光下载镜像也需要等待不少时间，这是不能接受的。\\n\\n在调研了相应的资料后，了解到可以从以下几个方面缩小 Docker 镜像体积进行优化：\\n\\n### 基础镜像源的选择\\n\\n所谓基础镜像源，就是我们在进行构建步骤时，选择的一个基础环境（如上 `node:10` )，通过查看 [Dockerhub](https://hub.docker.com/_/node) 上有关 Node.js 的基础环境镜像时，我们会发现有**多个版本**，虽然都是 Node.js 相关基础镜像，但不同版本，他们除了 Node.js 版本不同外，在**内部集成的环境也不一样**，例如带有 [alpine](https://yeasy.gitbooks.io/docker_practice/cases/os/alpine.html) 的版本，相当于是一个比较精巧的 Linux 系统镜像，在此版本运行的容器中会发现不存在我们常规系统中所附带的工具，比如 bash、curl 等，由此来缩小体积。\\n\\n根据项目实际需要，当我把基础镜像换为 [alpine](https://yeasy.gitbooks.io/docker_practice/cases/os/alpine.html) 版本后，再次进行构建，此时镜像体积已大幅度减小，从 1.3GB 直降为 500+MB，体积优化效果明显，所以当你发现自己构建的镜像体积过大时，可以**考虑从更换基础镜像源的方式**来着手，看看是否使用了过于臃肿的镜像源。\\n\\n### Multi-stage 构建镜像\\n\\n所谓 [multi-stage](https://docs.docker.com/develop/develop-images/multistage-build/) 即是 Docker 镜像构建的时候采取的策略，详细可点击链接提供的资料。\\n\\n#### Docker 构建规则\\n\\n简言之就是利用 Docker 构建提供的规则：Dockerfile 的操作都会增加一个所谓镜像的“层”，每一层都会增加镜像体积，通过采用多步骤策略，每一步骤包含具有相同意义的一系列操作（例如构建，部署），步骤与步骤之间通过产物镜像引用的方式，由此来缩减最终构建镜像所需要的层数，具体操作比如：\\n\\n```shell\\n# 设置第一步骤产生的镜像，并命名为builder\\nFROM node:10-alpine as builder\\nWORKDIR /nebula-web-console\\n# 复制当前项目内容至镜像中\\nADD . /nebula-web-console\\n# 进行相应的构建\\nRUN npm install\\nRUN npm run build\\n....\\n\\n# 进行第二步骤构建\\nFROM node:10-alpine\\nWORKDIR /nebula-web-console\\n# 复制第一步构建镜像的产物内容至当前镜像，只用到了一层镜像层从而节约了之前构建步骤的镜像层数\\nCOPY --from=builder . /nebula-web-console\\nCMD [\\\"npm\\\", \\\"run\\\", \\\"docker-start\\\"]\\n\\n```\\n\\n### .dockerignore\\n\\n类似我们熟悉的 `.gitignore` ，就是当我们在进行 `COPY` 或 `ADD` 文件复制操作时，将不必要的文件忽略掉（诸如文档文件、git文件、node_modules以及一些非生成必要文件等），从而减小镜像体积，更详细内容可参考文档连接：[.dockerignore](https://docs.docker.com/engine/reference/builder/#dockerignore-file)。\\n\\n### 操作合并\\n\\n基于上述提到在 Dockerfile 构建镜像的过程做，每一个操作都会在前一步镜像基础上增加一“层”，可以利用 `&` 来合并多个操作，减少层数，比如：\\n```shell\\n# 以下两个操作分别代表两层\\nRUN npm install\\nRUN npm run build\\n```\\n改为：\\n```shell\\n# 使用 & 后变了为一层\\nRUN npm install && npm run build\\n```\\n由此我们减少了层数的增加，即减少了镜像的体积。同时，在构建镜像的过程中，我们也可以通过在达到相同目的的前提下，尽量减少不必要的操作来减少“层数”的添加。\\n\\n### 前端常规性体积优化\\n\\n- 压缩丑化代码，移除源码\\n     此操作可以放在构建步骤阶段，这样会进一步缩小镜像的文件体积。\\n- node_modules 只下载生产环境需要的代码\\n     此操作可以放在部署阶段，只下载生产环境所需要的第三方依赖代码: `npm install --production` 。\\n- 公共资源放在CDN\\n     如果镜像被期待运行在联网环境，可以考虑将一些体积相比较大的公共文件（图片、第三方库等）放在CDN服务 器上，将部分资源剥离出去，也会进一步缩小体积。\\n- ...\\n\\n以上只作为一个线索参考，更多前端常规的优化步骤，都可以迁移至镜像中进行，毕竟和我们本地开发一样，镜像构建也是一个运行代码的环境嘛。\\n\\n## 小结\\n\\n以上便是我在此次使用 Docker 镜像来运行我们 [Nebula Studio](Nebula/blob/master/README.md) 所用到的一些优化镜像体积的方法，希望能给需要的人一些帮助和参考，可能还有一些认识不准确的地方，欢迎指出，同样欢迎你来试用 Nebula Graph Studio：[Nebula](Nebula) \\n\",\"id\":13}',_binary '',5214),(54,'修改 | 官网博客','2022-07-19 15:18:08',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','PUT','{\"pic\":\"https://www-cdn.nebula-graph.com.cn/nebula-blog/DockerImage01.png\",\"title\":\"前端 Docker 镜像体积优化\",\"author\":\"Jerry233\",\"description\":\"本文主要来讲述下开源的分布式图数据库 Nebula Graph 是如何将 Docker 应用到可视化界面中，并将镜像体积从 1.3G 减到 0.3G 。\",\"publish\":false,\"content\":\"如果 2019 年技术圈有十大流行词，**容器化**肯定占有一席之地，随着 Docker 的风靡，前端领域应用到 Docker 的场景也越来越多，本文主要来讲述下开源的分布式图数据库 Nebula Graph 是如何将 Docker 应用到可视化界面中。\\n\\n## 为什么要用 Docker\\n\\n对于前端日常开发而言，有时也会用到 Docker，结合到 Nebula Graph Studio（分布式图数据库 Nebula Graph 的图形界面工具）使用 Docker 主要基于以下考虑:\\n\\n- **统一运行环境**：我们的工具背后有好几个服务组合在一起，诸如不同技术栈的现有服务，纯前端的静态资源。\\n- **用户使用成本低**：目前云服务还在开发中，想让用户对服务组合无感，能直接在本地一键启动应用并使用。\\n- **快速部署**：团队本就提供有 [Nebula镜像版本](https://github.com/vesoft-inc/nebula-docker-compose) 实践，给了我们前端一些参考和借鉴。\\n\\n## Docker 镜像的构建\\n\\n既然要使用 Docker 来承载我们的应用，就得将项目进行镜像构建。与所有 build 镜像类似，需要配置一份命名为[Dockerfile ](https://docs.docker.com/engine/reference/builder/)的文件，文件是一些步骤的描述，简单来说就是把项目复制到镜像里，并设置好启动方式：\\n\\n```shell\\n# 选择基础镜像\\nFROM node:10\\n# 设置工作目录\\nWORKDIR /nebula-web-console\\n# 把当前项目内容拷贝到镜像中的 /nebula-web-console 目录下\\nADD . /nebula-web-console\\n# 在镜像中下载前端依赖\\nRUN npm install\\n# 执行构建\\nRUN npm run build\\nEXPOSE 7001\\n# 镜像启动时执行的部署命令\\nCMD [\\\"npm\\\", \\\"run\\\", \\\"docker-start\\\"]\\n```\\n\\n## Docker 镜像体积优化\\n\\n如果按照上述的配置文件来构建 Docker 镜像，以我们的项目为例，将会生成一个体积约为 1.3GB 的镜像，这个看起来有点吓人，因为即使在网速快的用户电脑光下载镜像也需要等待不少时间，这是不能接受的。\\n\\n在调研了相应的资料后，了解到可以从以下几个方面缩小 Docker 镜像体积进行优化：\\n\\n### 基础镜像源的选择\\n\\n所谓基础镜像源，就是我们在进行构建步骤时，选择的一个基础环境（如上 `node:10` )，通过查看 [Dockerhub](https://hub.docker.com/_/node) 上有关 Node.js 的基础环境镜像时，我们会发现有**多个版本**，虽然都是 Node.js 相关基础镜像，但不同版本，他们除了 Node.js 版本不同外，在**内部集成的环境也不一样**，例如带有 [alpine](https://yeasy.gitbooks.io/docker_practice/cases/os/alpine.html) 的版本，相当于是一个比较精巧的 Linux 系统镜像，在此版本运行的容器中会发现不存在我们常规系统中所附带的工具，比如 bash、curl 等，由此来缩小体积。\\n\\n根据项目实际需要，当我把基础镜像换为 [alpine](https://yeasy.gitbooks.io/docker_practice/cases/os/alpine.html) 版本后，再次进行构建，此时镜像体积已大幅度减小，从 1.3GB 直降为 500+MB，体积优化效果明显，所以当你发现自己构建的镜像体积过大时，可以**考虑从更换基础镜像源的方式**来着手，看看是否使用了过于臃肿的镜像源。\\n\\n### Multi-stage 构建镜像\\n\\n所谓 [multi-stage](https://docs.docker.com/develop/develop-images/multistage-build/) 即是 Docker 镜像构建的时候采取的策略，详细可点击链接提供的资料。\\n\\n#### Docker 构建规则\\n\\n简言之就是利用 Docker 构建提供的规则：Dockerfile 的操作都会增加一个所谓镜像的“层”，每一层都会增加镜像体积，通过采用多步骤策略，每一步骤包含具有相同意义的一系列操作（例如构建，部署），步骤与步骤之间通过产物镜像引用的方式，由此来缩减最终构建镜像所需要的层数，具体操作比如：\\n\\n```shell\\n# 设置第一步骤产生的镜像，并命名为builder\\nFROM node:10-alpine as builder\\nWORKDIR /nebula-web-console\\n# 复制当前项目内容至镜像中\\nADD . /nebula-web-console\\n# 进行相应的构建\\nRUN npm install\\nRUN npm run build\\n....\\n\\n# 进行第二步骤构建\\nFROM node:10-alpine\\nWORKDIR /nebula-web-console\\n# 复制第一步构建镜像的产物内容至当前镜像，只用到了一层镜像层从而节约了之前构建步骤的镜像层数\\nCOPY --from=builder . /nebula-web-console\\nCMD [\\\"npm\\\", \\\"run\\\", \\\"docker-start\\\"]\\n\\n```\\n\\n### .dockerignore\\n\\n类似我们熟悉的 `.gitignore` ，就是当我们在进行 `COPY` 或 `ADD` 文件复制操作时，将不必要的文件忽略掉（诸如文档文件、git文件、node_modules以及一些非生成必要文件等），从而减小镜像体积，更详细内容可参考文档连接：[.dockerignore](https://docs.docker.com/engine/reference/builder/#dockerignore-file)。\\n\\n### 操作合并\\n\\n基于上述提到在 Dockerfile 构建镜像的过程做，每一个操作都会在前一步镜像基础上增加一“层”，可以利用 `&` 来合并多个操作，减少层数，比如：\\n```shell\\n# 以下两个操作分别代表两层\\nRUN npm install\\nRUN npm run build\\n```\\n改为：\\n```shell\\n# 使用 & 后变了为一层\\nRUN npm install && npm run build\\n```\\n由此我们减少了层数的增加，即减少了镜像的体积。同时，在构建镜像的过程中，我们也可以通过在达到相同目的的前提下，尽量减少不必要的操作来减少“层数”的添加。\\n\\n### 前端常规性体积优化\\n\\n- 压缩丑化代码，移除源码\\n     此操作可以放在构建步骤阶段，这样会进一步缩小镜像的文件体积。\\n- node_modules 只下载生产环境需要的代码\\n     此操作可以放在部署阶段，只下载生产环境所需要的第三方依赖代码: `npm install --production` 。\\n- 公共资源放在CDN\\n     如果镜像被期待运行在联网环境，可以考虑将一些体积相比较大的公共文件（图片、第三方库等）放在CDN服务 器上，将部分资源剥离出去，也会进一步缩小体积。\\n- ...\\n\\n以上只作为一个线索参考，更多前端常规的优化步骤，都可以迁移至镜像中进行，毕竟和我们本地开发一样，镜像构建也是一个运行代码的环境嘛。\\n\\n## 小结\\n\\n以上便是我在此次使用 Docker 镜像来运行我们 [Nebula Studio](Nebula/blob/master/README.md) 所用到的一些优化镜像体积的方法，希望能给需要的人一些帮助和参考，可能还有一些认识不准确的地方，欢迎指出，同样欢迎你来试用 Nebula Graph Studio：[Nebula](Nebula) \\n\",\"id\":13}',_binary '',5256),(55,'删除 | 菜单管理','2022-07-19 15:26:21',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu/82','DELETE',NULL,_binary '',5360),(56,'删除 | 菜单管理','2022-07-19 15:26:27',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu/81','DELETE',NULL,_binary '',5311),(57,'删除 | 菜单管理','2022-07-19 15:26:33',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu/80','DELETE',NULL,_binary '',5280),(58,'删除 | 菜单管理','2022-07-19 15:26:40',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu/79','DELETE',NULL,_binary '',5345),(59,'删除 | 菜单管理','2022-07-19 15:26:48',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu/78','DELETE',NULL,_binary '',5273),(60,'删除 | 菜单管理','2022-07-19 15:26:55',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu/77','DELETE',NULL,_binary '',5265),(61,'删除 | 菜单管理','2022-07-19 15:27:02',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu/76','DELETE',NULL,_binary '',5281),(62,'新增 | 菜单管理','2022-07-19 15:28:48',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu','POST','{\"name\":\"官网博客\",\"status\":\"2\",\"parentMenu\":{\"id\":55,\"name\":\"官网管理\"},\"type\":\"table\",\"value\":\"Blog\",\"sort\":140}',_binary '',5390),(63,'修改 | 官网博客','2022-07-19 17:39:11',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Blog','PUT','{\"pic\":\"https://www-cdn.nebula-graph.com.cn/nebula-blog/auto01.jpeg\",\"title\":\"Nebula Graph 使用 GitHub Action 的自动化实践\",\"author\":\"Yee\",\"description\":\"在讲 Action 实践之前还需先讲下 Nebula Graph 的需求：首要目标比较明确就是自动化测试，分为单元测试和集成测试，顺带再解决一下 PM 小姐姐的发布需求，构建起来了第一版的 CI/CD 流程。\",\"publish\":false,\"content\":\"\\n## 缘起\\n\\nNebula Graph 最早的自动化测试是使用搭建在 Azure 上的 [Jenkins](https://jenkins.io/zh/)，配合着 GitHub 的 Webhook 实现的，在用户提交 Pull Request 时，加个 `ready-for-testing` 的 label 再评论一句 `Jenkins go` 就可以自动的运行相应的 UT 测试，效果如下：\\n\\n![Jenkins](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto02.png)\\n\\n因为是租用的 Azure 的云主机，加上 nebula 的编译要求的机器配置较高，而且任务的触发主要集中在白天。所以上述的方案性价比较低，从去年团队就在考虑寻找替代的方案，准备下线 Azure 上的测试机，并且还要能提供多环境的测试方案。\\n\\n调研了一圈现有的产品主要有：\\n1. TravisCI\\n1. CircleCI\\n1. Azure Pipeline\\n1. Jenkins on k8s（自建）\\n\\n虽然上面的产品对开源项目有些限制，但整体都还算比较友好。\\n\\n鉴于之前 GitLab CI 的使用经验，体会到如果能跟 GitHub 深度集成那当然是首选。所谓“深度”表示可以共享 GitHub 的整个开源的生态以及完美的 API 调用（后话）。恰巧 2019，GitHub Action 2.0 横空出世，Nebula Graph 便勇敢的入了坑。\\n\\n这里简单概述一下我们在使用 GitHub Action 时体会到的优点：\\n1. 免费。开源项目可以免费使用 Action 的所有功能，而且机器[配置较高](https://help.github.com/en/actions/reference/virtual-environments-for-github-hosted-runners#supported-runners-and-hardware-resources)。\\n1. 开源生态好。在整个 CI 的流程里，可以直接使用 GitHub 上的所有开源的 Action，哪怕就是没有满足需求的 Action，自己上手写也不是很麻烦，而且还支持 docker 定制，用 bash 就可以完成一个专属的 Action。\\n1. 支持多种系统。Windows、macOS 和 Linux 都可以一键使用，跨平台简单方便。\\n1. 可跟 GitHub 的 API 互动。通过 `GITHUB_TOKEN` 可以直接访问 [GitHub API V3](https://developer.github.com/v3/)，想上传文件，检查 PR 状态，使用 curl 命令即可完成。\\n1. 自托管。只要提供 workflow 的描述文件，将其放置到 `.github/workflows/` 目录下，每次提交便会自动触发执行新的 action run。\\n1. Workflow 描述文件改为 YAML 格式。目前的描述方式要比 Action 1.0 中的 workflow 文件更加简洁易读。\\n\\n下面在讲实践之前还是要先讲讲 Nebula Graph 的需求：首要目标比较明确就是自动化测试。\\n\\n作为数据库产品，测试怎么强调也不为过。Nebula Graph 的测试主要分单元测试和集成测试。用 GitHub Action 其实主要瞄准的是单元测试，然后再给集成测试做些准备，比如 docker 镜像构建和安装程序打包。顺带再解决一下 PM 小姐姐的发布需求，就整个构建起来了第一版的 CI/CD 流程。\\n\\n## PR 测试\\n\\nNebula Graph 作为托管在 GitHub 上的开源项目，首先要解决的测试问题就是当贡献者提交了 PR 请求后，如何才能快速地进行变更验证？主要有以下几个方面。\\n\\n1. 符不符合编码规范；\\n1. 能不能在不同系统上都编译通过；\\n1. 单测有没有失败；\\n1. 代码覆盖率有没有下降等。\\n\\n只有上述的要求全部满足并且有至少两位 reviewer 的同意，变更才能进入主干分支。\\n\\n借助于 cpplint 或者 clang-format 等开源工具可以比较简单地实现要求 1，如果此要求未通过验证，后面的步骤就自动跳过，不再继续执行。\\n\\n对于要求 2，我们希望能同时在目前支持的几个系统上运行 Nebula 源码的编译验证。那么像之前在物理机上直接构建的方式就不再可取，毕竟一台物理机的价格已经高昂，何况一台还不足够。为了保证编译环境的一致性，还要尽可能的减少机器的性能损失，最终采用了 docker 的容器化构建方式。再借助 Action 的 [matrix 运行策略](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idstrategymatrix)和对 [docker 的支持](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idcontainer)，还算顺利地将整个流程走通。\\n\\n![action-workflow](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto03.svg)\\n\\n运行的大概流程如上图所示，在 [vesoft-inc/nebula-dev-docker](https://github.com/vesoft-inc/nebula-dev-docker) 项目中维护 nebula 编译环境的 docker 镜像，当编译器或者 thirdparty 依赖升级变更时，自动触发 docker hub 的 Build 任务（见下图）。当新的 Pull Request 提交以后，Action 便会被触发开始拉取最新的编译环境镜像，执行编译。\\n\\n![build-activity](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto04.png)\\n\\n针对 PR 的 workflow 完整描述见文件 [pull_request.yaml](https://github.com/vesoft-inc/nebula/blob/master/.github/workflows/pull_request.yaml)。同时，考虑到并不是每个人提交的 PR 都需要立即运行 CI 测试，且自建的机器资源有限，对 CI 的触发做了如下限制：\\n\\n1. 只有 lint 校验通过的 PR 才会将后续的 job 下发到自建的 runner，lint 的任务比较轻量，可以使用 GitHub Action 托管的机器来执行，无需占用线下的资源。\\n1. 只有添加了 `ready-for-testing`  label 的 PR 才会触发 action 的执行，而 label 的添加有权限的控制。进一步优化 runner 被随意触发的情况。对 label 的限制如下所示：\\n\\n```yaml\\njobs:\\n  lint:\\n    name: cpplint\\n    if: contains(join(toJson(github.event.pull_request.labels.*.name)), \'ready-for-testing\')\\n```\\n\\n在 PR 中执行完成后的效果如下所示：\\n\\n![pr-workflow-result](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto05.png)\\n\\nCode Coverage 的说明见博文：[图数据库 Nebula Graph 的代码变更测试覆盖率实践](https://nebula-graph.io/cn/posts/integrate-codecov-test-coverage-with-nebula-graph/)。\\n\\n## Nightly 构建\\n\\n在 Nebula Graph 的集成测试框架中，希望能够在每天晚上对 codebase 中的代码全量跑一遍所有的测试用例。同时有些新的特性，有时也希望能快速地打包交给用户体验使用。这就需要 CI 系统能在每天给出当日代码的 docker 镜像和 rpm/deb 安装包。\\n\\nGitHub Action 被触发的事件类型除了 pull_request，还可以执行 [schedule](https://help.github.com/en/actions/reference/events-that-trigger-workflows#scheduled-events-schedule) 类型。schedule 类型的事件可以像 crontab 一样，让用户指定任何重复任务的触发时间，比如每天凌晨两点执行任务如下所示：\\n\\n```yaml\\non:\\n  schedule:\\n    - cron: \'0 18 * * *\'\\n```\\n\\n因为 GitHub 采用的是 UTC 时间，所以东八区的凌晨 2 点，就对应到 UTC 的前日 18 时。\\n\\n### docker\\n\\n每日构建的 docker 镜像需要 push 到 docker hub 上，并打上 nightly 的标签，集成测试的 k8s 集群，将 image 的拉取策略设置为 Always，每日触发便能滚动升级到当日最新进行测试。因为当日的问题目前都会尽量当日解决，便没有再给 nightly 的镜像再额外打一个日期的 tag。对应的 action 部分如下所示：\\n\\n```yaml\\n      - name: Build image\\n        env:\\n          IMAGE_NAME: ${{ secrets.DOCKER_USERNAME }}/nebula-${{ matrix.service }}:nightly\\n        run: |\\n          docker build -t ${IMAGE_NAME} -f docker/Dockerfile.${{ matrix.service }} .\\n          docker push ${IMAGE_NAME}\\n        shell: bash\\n```\\n\\n### package\\n\\nGitHub Action 提供了 [artifacts](https://help.github.com/en/actions/configuring-and-managing-workflows/persisting-workflow-data-using-artifacts) 的功能，可以让用户持久化 workflow 运行过程中的数据，这些数据可以保留 90 天。对于 nightly 版本安装包的存储而言，已经绰绰有余。利用官方提供的 `actions/upload-artifact@v1`  action，可以方便的将指定目录下的文件上传到 artifacts。最后 nightly 版本的 nebula 的安装包如下图所示。\\n\\n![package](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto06.png)\\n\\n上述完整的 workflow 文件见 [package.yaml](https://github.com/vesoft-inc/nebula/blob/master/.github/workflows/package.yaml)\\n\\n## 分支发布\\n\\n为了更好地维护每个发布的版本和进行 bugfix，Nebula Graph 采用分支发布的方式。即每次发布之前进行 code freeze，并创建新的 release 分支，在 release 分支上只接受 bugfix，而不进行 feature 的开发。bugfix 还是会在开发分支上提交，最后 cherrypick 到 release 分支。\\n\\n在每次 release 时，除了 source 外，我们希望能把安装包也追加到 assets 中方便用户直接下载。如果每次都手工上传，既容易出错，也非常耗时。这就比较适合 Action 来自动化这块的工作，而且，打包和上传都走 GitHub 内部网络，速度更快。\\n\\n在安装包编译好后，通过 curl 命令直接调用 GitHub 的 API，就能上传到 assets 中，[具体脚本](https://github.com/vesoft-inc/nebula/blob/master/ci/scripts/upload-github-release-asset.sh)内容如下所示：\\n\\n```bash\\ncurl --silent \\\\\\n     --request POST \\\\\\n     --url \\\"$upload_url?name=$filename\\\" \\\\\\n     --header \\\"authorization: Bearer $github_token\\\" \\\\\\n     --header \\\"content-type: $content_type\\\" \\\\\\n     --data-binary @\\\"$filepath\\\"\\n```\\n\\n同时，为了安全起见，在每次的安装包发布时，希望可以计算安装包的 checksum 值，并将其一同上传到 assets 中，以便用户下载后进行完整性校验。具体步骤如下所示：\\n\\n```yaml\\njobs:\\n  package:\\n    name: package and upload release assets\\n    runs-on: ubuntu-latest\\n    strategy:\\n      matrix:\\n        os:\\n          - ubuntu1604\\n          - ubuntu1804\\n          - centos6\\n          - centos7\\n    container:\\n      image: vesoft/nebula-dev:${{ matrix.os }}\\n    steps:\\n      - uses: actions/checkout@v1\\n      - name: package\\n        run: ./package/package.sh\\n      - name: vars\\n        id: vars\\n        env:\\n          CPACK_OUTPUT_DIR: build/cpack_output\\n          SHA_EXT: sha256sum.txt\\n        run: |\\n          tag=$(echo ${{ github.ref }} | rev | cut -d/ -f1 | rev)\\n          cd $CPACK_OUTPUT_DIR\\n          filename=$(find . -type f \\\\( -iname \\\\*.deb -o -iname \\\\*.rpm \\\\) -exec basename {} \\\\;)\\n          sha256sum $filename > $filename.$SHA_EXT\\n          echo \\\"::set-output name=tag::$tag\\\"\\n          echo \\\"::set-output name=filepath::$CPACK_OUTPUT_DIR/$filename\\\"\\n          echo \\\"::set-output name=shafilepath::$CPACK_OUTPUT_DIR/$filename.$SHA_EXT\\\"\\n        shell: bash\\n      - name: upload release asset\\n        run: |\\n          ./ci/scripts/upload-github-release-asset.sh github_token=${{ secrets.GITHUB_TOKEN }} repo=${{ github.repository }} tag=${{ steps.vars.outputs.tag }} filepath=${{ steps.vars.outputs.filepath }}\\n          ./ci/scripts/upload-github-release-asset.sh github_token=${{ secrets.GITHUB_TOKEN }} repo=${{ github.repository }} tag=${{ steps.vars.outputs.tag }} filepath=${{ steps.vars.outputs.shafilepath }}\\n```\\n\\n上述完整的 workflow 文件见 [release.yaml](https://github.com/vesoft-inc/nebula/blob/master/.github/workflows/release.yaml)。\\n\\n## 命令\\n\\nGitHub Action 为 workflow 提供了一些[命令](https://help.github.com/en/actions/reference/workflow-commands-for-github-actions)方便在 shell 中进行调用，来更精细地控制和调试每个步骤的执行。常用的命令如下：\\n\\n### set-output\\n\\n有时在 job 的 steps 之间需要传递一些结果，这时就可以通过 `echo \\\"::set-output name=output_name::output_value\\\"` 的命令形式将想要输出的 `output_value` 值设置到 `output_name` 变量中。\\n\\n在接下来的 step 中，可以通过 `${{ steps.step_id.outputs.output_name }}` 的方式引用上述的输出值。\\n\\n上节中上传 asset 的 job 中就使用了上述的方式来传递文件名称。一个步骤可以通过多次执行上述命令来设置多个输出。\\n\\n### set-env\\n\\n同 `set-output` 一样，可以为后续的步骤设置环境变量。语法： `echo \\\"::set-env name={name}::{value}\\\"` 。\\n\\n### add-path\\n\\n将某路径加入到 `PATH` 变量中，为后续步骤使用。语法： `echo \\\"::add-path::{path}\\\"` 。\\n\\n## Self-Hosted Runner\\n\\n除了 GitHub 官方托管的 runner 之外，Action 还允许使用线下自己的机器作为 Runner 来跑 Action 的 job。在机器上安装好 Action Runner 之后，按照[教程](https://help.github.com/en/actions/hosting-your-own-runners/adding-self-hosted-runners)，将其注册到项目后，在 workflow 文件中通过配置 `runs-on: self-hosted` 即可使用。\\n\\nself-hosted 的机器可以打上不同的 label，这样便可以通过[不同的标签](https://help.github.com/en/actions/hosting-your-own-runners/using-labels-with-self-hosted-runners)来将任务分发到特定的机器上。比如线下的机器安装有不同的操作系统，那么 job 就可以根据 `runs-on` 的 label [在特定的机器](https://help.github.com/en/actions/hosting-your-own-runners/using-self-hosted-runners-in-a-workflow)上运行。 `self-hosted` 也是一个特定的标签。\\n\\n![self-hosted-runner-label](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto07.png)\\n\\n### 安全\\n\\nGitHub 官方是不推荐开源项目使用 Self-Hosted 的 runner 的，原因是任何人都可以通过提交 PR 的方式，让 runner 的机器运行危险的代码对其所在的环境进行攻击。\\n\\n但是 Nebula Graph 的编译需要的存储空间较大，且 GitHub 只能提供 2 核的环境来编译，不得已还是选择了自建 Runner。考虑到安全的因素，进行了如下方面的安全加固：\\n\\n#### 虚拟机部署\\n\\n所有注册到 GitHub Action 的 runner 都是采用虚拟机部署，跟宿主机做好第一层的隔离，也更方便对每个虚拟机做资源分配。一台高配置的宿主机可以分配多个虚拟机让 runner 来并行地跑所有收到的任务。\\n\\n如果虚拟机出了问题，可以方便地进行环境复原的操作。\\n\\n#### 网络隔离\\n\\n将所有 runner 所在的虚拟机隔离在办公网络之外，使其无法直接访问公司内部资源。即便有人通过 PR 提交了恶意代码，也让其无法访问公司内部网络，造成进一步的攻击。\\n\\n#### Action 选择\\n\\n尽量选择大厂和官方发布的 action，如果是使用个人开发者的作品，最好能检视一下其具体实现代码，免得出现网上爆出来的[泄漏隐私密钥](https://julienrenaux.fr/2019/12/20/github-actions-security-risk/)等事情发生。\\n\\n比如 GitHub 官方维护的 action 列表：[https://github.com/actions](https://github.com/actions)。\\n\\n#### 私钥校验\\n\\nGitHub Action 会自动校验 PR 中是否使用了一些私钥，除却 `GITHUB_TOKEN` 之外的其他私钥（通过 `${{ secrets.MY_TOKENS }}` 形式引用）均是不可以在 PR 事件触发的相关任务中使用，以防用户通过 PR 的方式私自打印输出窃取密钥。\\n\\n### 环境搭建与清理\\n\\n对于自建的 runner，在不同任务（job）之间做文件共享是方便的，但是最后不要忘记每次在整个 action 执行结束后，清理产生的中间文件，不然这些文件有可能会影响接下来的任务执行和不断地占用磁盘空间。\\n\\n```yaml\\n      - name: Cleanup\\n        if: always()\\n        run: rm -rf build\\n```\\n\\n将 step 的运行条件设置为 `always()` 确保每次任务都要执行该步骤，即便中途出错。\\n\\n### 基于 Docker 的 Matrix 并行构建\\n\\n因为 Nebula Graph 需要在不同的系统上做编译验证，在构建方式上采用了容器的方案，原因是构建时不同环境的隔离简单方便，GitHub Action 可以原生支持基于 docker 的任务。\\n\\nAction 支持 matrix 策略运行任务的方式，类似于 TravisCI 的 [build matrix](https://docs.travis-ci.com/user/build-matrix/)。通过配置不同系统和编译器的组合，我们可以方便地设置在每个系统下使用 `gcc` 和 `clang` 来同时编译 nebula 的源码，如下所示：\\n\\n```yaml\\njobs:\\n  build:\\n    name: build\\n    runs-on: ubuntu-latest\\n    strategy:\\n      fail-fast: false\\n      matrix:\\n        os:\\n          - centos6\\n          - centos7\\n          - ubuntu1604\\n          - ubuntu1804\\n        compiler:\\n          - gcc-9.2\\n          - clang-9\\n        exclude:\\n          - os: centos7\\n            compiler: clang-9\\n```\\n\\n上述的 strategy 会生成 8 个并行的任务（4 os x 2 compiler），每个任务都是（os, compiler）的一个组合。这种类似矩阵的表达方式，可以极大的减少不同纬度上的任务组合的定义。\\n\\n如果想排除 matrix 中的某个组合，只要将组合的值配置到 `exclude` 选项下面即可。如果想在任务中访问 matrix 中的值，也只要通过类似 `${{ matrix.os }}` 获取上下文变量值的方式拿到。这些方式让你定制自己的任务时都变得十分方便。\\n\\n#### 运行时容器\\n\\n我们可以为每个任务指定运行时的一个容器环境，这样该任务下的所有步骤（steps）都会在容器的内部环境中执行。相较于在每个步骤中都套用 docker 命令要简洁明了。\\n\\n```yaml\\n    container:\\n      image: vesoft/nebula-dev:${{ matrix.os }}\\n      env:\\n        CCACHE_DIR: /tmp/ccache/${{ matrix.os }}-${{ matrix.compiler }}\\n```\\n\\n对容器的配置，像在 docker compose 中配置 service 一样，可以指定 image/env/ports/volumes/options 等等[参数](https://help.github.com/en/actions/reference/workflow-syntax-for-github-actions#jobsjob_idcontainer)。在 self-hosted 的 runner 中，可以方便地将宿主机上的目录挂载到容器中做文件的共享。\\n\\n正是基于 Action 上面的容器特性，才方便的在 docker 内做后续编译的缓存加速。\\n\\n## 编译加速\\n\\nNebula Graph 的源码采用 C++ 编写，整个构建过程时间较长，如果每次 CI 都完全地重新开始，会浪费许多计算资源。因为每台 runner 跑的（容器）任务不定，需要对每个源文件及对应的编译过程进行精准判别才能确认该源文件是否真的被修改。目前使用最新版本的 [ccache](https://ccache.dev/) 来完成缓存的任务。\\n\\n虽然 GitHub Action 本身提供 [cache 的功能](https://help.github.com/en/actions/configuring-and-managing-workflows/caching-dependencies-to-speed-up-workflows)，由于 Nebula Graph 目前单元测试的用例采用静态链接，编译后体积较大，超出其可用的配额，遂使用本地缓存的策略。\\n\\n### ccache\\n\\n[ccache](https://ccache.dev/) 是个编译器的缓存工具，可以有效地加速编译的过程，同时支持 gcc/clang 等编译器。Nebula Graph 使用 C++ 14 标准，低版本的 ccache 在兼容性上有问题，所以在所有的 `vesoft/nebula-dev` [镜像](https://github.com/vesoft-inc/nebula-dev-docker)中都采用手动编译的方式安装。\\n\\nNebula Graph 在 cmake 的配置中自动识别是否安装了 ccache，并决定是否对其打开启用。所以只要在容器环境中对 ccache 做些配置即可，比如在[ ccache.conf ](https://github.com/vesoft-inc/nebula/blob/master/ci/ccache.conf)中配置其最大缓存容量为 1 G，超出后自动替换较旧缓存。\\n\\n```yaml\\nmax_size = 1.0G\\n```\\n\\nccache.conf 配置文件最好放置在缓存目录下，这样 ccache 可方便读取其中内容。\\n\\n### tmpfs\\n\\ntmpfs 是位于内存或者 swap 分区的临时文件系统，可以有效地缓解磁盘 IO 带来的延迟，因为 self-hosted 的主机内存足够，所以将 ccache 的目录挂载类型改为 tmpfs，来减少 ccache 读写时间。在 docker 中使用 tmpfs 的挂载类型可以参考[相应文档](https://docs.docker.com/storage/tmpfs/)。相应的配置参数如下：\\n\\n```yaml\\n    env:\\n      CCACHE_DIR: /tmp/ccache/${{ matrix.os }}-${{ matrix.compiler }}\\n    options: --mount type=tmpfs,destination=/tmp/ccache,tmpfs-size=1073741824 -v /tmp/ccache/${{ matrix.os }}-${{ matrix.compiler }}:/tmp/ccache/${{ matrix.os }}-${{ matrix.compiler }} \\n```\\n\\n将所有 ccache 产生的缓存文件，放置到挂载为 tmpfs 类型的目录下。\\n\\n### 并行编译\\n\\nmake 本身即支持多个源文件的并行编译，在编译时配置 `-j $(nproc)` 便可同时启动与核数相同的任务数。在 action 的 steps 中配置如下：\\n\\n```yaml\\n      - name: Make\\n        run: cmake --build build/ -j $(nproc)\\n```\\n\\n## 坑\\n\\n说了那么多的优点，那有没有不足呢？使用下来主要体会到如下几点：\\n\\n1. 只支持较新版本的系统。很多 Action 是基于较新的 Nodejs 版本开发，没法方便地在类似 CentOS 6 等老版本 docker 容器中直接使用。否则会报 Nodejs 依赖的库文件找不到，从而无法正常启动 action 的执行。因为 Nebula Graph 希望可以支持 CentOS 6，所以在该系统下的任务不得不需要特殊处理。\\n\\n2. 不能方便地进行本地验证。虽然社区有个开源项目 [act](https://github.com/nektos/act)，但使用下来还是有诸多限制，有时不得不通过在自己仓库中反复提交验证才能确保 action 的修改正确。\\n\\n3. 目前还缺少比较好的指导规范，当定制的任务较多时，总有种在 YAML 配置中写程序的感受。目前的做法主要有以下三种：\\n\\n    1. 根据任务拆分配置文件。\\n    1. 定制专属 action，通过 GitHub 的 SDK 来实现想要的功能。\\n    1. 编写大的 shell 脚本来完成任务内容，在任务中调用该脚本。\\n\\n\\n目前针对尽量多使用小任务的组合还是使用大任务的方式，社区也没有定论。不过小任务组合的方式可以方便地定位任务失败位置以及确定每步的执行时间。\\n\\n![action](https://www-cdn.nebula-graph.com.cn/nebula-blog/auto08.png)\\n\\n4. Action 的一些历史记录目前无法清理，如果中途更改了 workflows 的名字，那么老的 check runs 记录还是会一直保留在 Action 页面，影响使用体验。\\n\\n5. 目前还缺少像 GitLab CI 中手动触发 job/task 运行的功能。无法运行中间进行人工干预。\\n\\n6. action 的开发也在不停的迭代中，有时需要维护一下新版的升级，比如：[checkout@v2](https://github.com/actions/checkout/issues/23)\\n\\n不过总体来说，GitHub Action 是一个相对优秀的 CI/CD 系统，毕竟站在 GitLab CI/Travis CI 等前人肩膀上的产品，还是有很多经验可以借鉴使用。\\n\\n## 后续\\n\\n### 定制 Action\\n\\n前段时间 [docker 发布了自己的第一款 Action](https://www.docker.com/blog/first-docker-github-action-is-here/)，简化用户与 docker 相关的任务。后续，针对 Nebula Graph 的一些 CI/CD 的复杂需求，我们亦会定制一些专属的 action 来给 nebula 的所有 repo 使用。通用的就会创建独立的 repo，发布到 action 市场里，比如追加 assets 到 release 功能。专属的就可以放置 repo 的 `.github/actions` 目录下。\\n\\n这样就可以简化 workflows 中的 YAML 配置，只要 use 某个定制 action 即可。灵活性和拓展性都更优。\\n\\n### 跟钉钉/slack 等 IM 集成\\n\\n通过 GitHub 的 SDK 可以开发复杂的 action 应用，再结合[钉钉](https://ding-doc.dingtalk.com/doc#/serverapi2/qf2nxq)/slack 等 bot 的定制，可以实现许多自动化的有意思的小应用。比如，当一个 PR 被 2 个以上的 reviewer approve 并且所有的 check runs 都通过，那么就可以向钉钉群里发消息并 @ 一些人让其去 merge 该 PR。免去了每次都去 PR list 里面 check 每个 PR 状态的辛苦。\\n\\n当然围绕 GitHub 的周边通过一些 bot 还可以迸发许多有意思的玩法。\\n\\n## One More Thing...\\n\\n~~图数据库 Nebula Graph 1.0 GA 快要发布啦。欢迎大家来围观。~~\\n\\n本文中如有任何错误或疏漏欢迎去 GitHub：[https://github.com/vesoft-inc/nebula](https://github.com/vesoft-inc/nebula) issue 区向我们提 issue 或者前往官方论坛：[https://discuss.nebula-graph.com.cn/](https://discuss.nebula-graph.com.cn/) 的 `建议反馈` 分类下提建议 ?；交流图数据库技术？加入 Nebula 交流群请先[填写下你的 Nebula 名片](https://wj.qq.com/s2/8321168/8e2f/)，Nebula 小助手会拉你进群~~\\n\\n> 作者有话说：Hi，我是 Yee，是[图数据 Nebula Graph](https://github.com/vesoft-inc/nebula) 研发工程师，对数据库查询引擎有浓厚的兴趣，希望本次的经验分享能给大家带来帮助，如有不当之处也希望能帮忙纠正，谢谢~\\n\\n\",\"id\":11}',_binary '',5938),(64,'新增 | 菜单管理','2022-07-22 17:01:17',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/EruptMenu','POST','{\"name\":\"产品信息\",\"status\":\"1\",\"parentMenu\":{\"id\":55,\"name\":\"官网管理\"},\"type\":\"table\",\"value\":\"Product\",\"sort\":150}',_binary '',5579),(65,'新增 | 产品信息','2022-07-22 17:03:58',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Product','POST','{\"name\":\"The fastest way to deploy a Nebula Graph cluster\",\"description\":\"With NebulaGraph Cloud, you can deploy NebulaGraph Databases on Microsoft Azure, AWS, and Google Cloud Platform within minutes, free from tedious installation, optimization, and maintenance. Its various visualized toolkits for Graph Database Management al\",\"type\":\"NebulaGraph\",\"features\":[{\"title\":\"Seamless graph database integrations\",\"desc\":\"Nebula Graph Cloud offers an end-to-end solution: a distributed and extensible graph database, sophisticated tools to manage data, and efficient dashboards to import graph data and run queries. It comes with integrated database management tools and visual\",\"link\":\"123\",\"createTime\":\"2022-07-22 17:03:38\",\"updateTime\":\"2022-07-22 17:03:38\",\"createUser\":{\"name\":null,\"id\":\"1\"},\"updateUser\":{\"name\":null,\"id\":\"1\"},\"id\":-594,\"createUser_name\":null,\"createUser_id\":\"1\",\"updateUser_name\":null,\"updateUser_id\":\"1\"}]}',_binary '',5287),(66,'新增 | 产品信息','2022-07-22 17:56:50',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Product','POST','{\"name\":\"2123\",\"description\":\"123\",\"type\":\"NebulaGraph\",\"summary\":\"123\",\"summary_features\":[{\"content\":\"asdfadf发送到\",\"createTime\":\"2022-07-22 17:56:41\",\"updateTime\":\"2022-07-22 17:56:41\",\"createUser\":{\"name\":null,\"id\":\"1\"},\"updateUser\":{\"name\":null,\"id\":\"1\"},\"id\":-580,\"createUser_name\":null,\"createUser_id\":\"1\",\"updateUser_name\":null,\"updateUser_id\":\"1\"}],\"features\":[],\"advantages\":[],\"video_url\":\"afasd\"}',_binary '',5338),(67,'新增 | 产品信息','2022-07-22 19:34:21',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Product','POST','{\"name\":\"主标题\",\"description\":\"测试描述\",\"type\":\"NebulaGraph\",\"summary\":\"测试Summary\",\"summary_features\":[{\"content\":\"v自行车v自行车v\",\"createTime\":\"2022-07-22 19:34:13\",\"updateTime\":\"2022-07-22 19:34:13\",\"createUser\":{\"name\":null,\"id\":\"1\"},\"updateUser\":{\"name\":null,\"id\":\"1\"},\"id\":-914,\"createUser_name\":null,\"createUser_id\":\"1\",\"updateUser_name\":null,\"updateUser_id\":\"1\"}],\"features\":[{\"content\":\"fasdfasdf \",\"createTime\":\"2022-07-22 19:34:04\",\"updateTime\":\"2022-07-22 19:34:04\",\"createUser\":{\"name\":null,\"id\":\"1\"},\"updateUser\":{\"name\":null,\"id\":\"1\"},\"id\":-240,\"createUser_name\":null,\"createUser_id\":\"1\",\"updateUser_name\":null,\"updateUser_id\":\"1\"},{\"content\":\"阿斯顿发地方\",\"createTime\":\"2022-07-22 19:34:08\",\"updateTime\":\"2022-07-22 19:34:08\",\"createUser\":{\"name\":null,\"id\":\"1\"},\"updateUser\":{\"name\":null,\"id\":\"1\"},\"id\":-266,\"createUser_name\":null,\"createUser_id\":\"1\",\"updateUser_name\":null,\"updateUser_id\":\"1\"}],\"advantages\":[{\"content\":\"fasdfad\",\"createTime\":\"2022-07-22 19:33:54\",\"updateTime\":\"2022-07-22 19:33:54\",\"createUser\":{\"name\":null,\"id\":\"1\"},\"updateUser\":{\"name\":null,\"id\":\"1\"},\"id\":-246,\"createUser_name\":null,\"createUser_id\":\"1\",\"updateUser_name\":null,\"updateUser_id\":\"1\"},{\"content\":\"1232rqwerer\",\"createTime\":\"2022-07-22 19:33:59\",\"updateTime\":\"2022-07-22 19:33:59\",\"createUser\":{\"name\":null,\"id\":\"1\"},\"updateUser\":{\"name\":null,\"id\":\"1\"},\"id\":-933,\"createUser_name\":null,\"createUser_id\":\"1\",\"updateUser_name\":null,\"updateUser_id\":\"1\"}],\"video_url\":\"fasdfasdf\"}',_binary '',5535),(68,'新增 | 产品信息','2022-07-22 19:38:42',NULL,'192.168.10.233','admin','0|0|0|内网IP|内网IP','http://localhost:8080/erupt-api/data/modify/Product','POST','{\"name\":\"测试标题\",\"description\":\"测试标题描述\",\"type\":\"NebulaGraph\",\"summary\":\"饭撒点发送到发多少\",\"summary_features\":[{\"content\":\"发送到发多少\",\"createTime\":\"2022-07-22 19:38:31\",\"updateTime\":\"2022-07-22 19:38:31\",\"createUser\":{\"name\":null,\"id\":\"1\"},\"updateUser\":{\"name\":null,\"id\":\"1\"},\"id\":-592,\"createUser_name\":null,\"createUser_id\":\"1\",\"updateUser_name\":null,\"updateUser_id\":\"1\"},{\"content\":\"发送到发送到发多少分\",\"createTime\":\"2022-07-22 19:38:34\",\"updateTime\":\"2022-07-22 19:38:34\",\"createUser\":{\"name\":null,\"id\":\"1\"},\"updateUser\":{\"name\":null,\"id\":\"1\"},\"id\":-548,\"createUser_name\":null,\"createUser_id\":\"1\",\"updateUser_name\":null,\"updateUser_id\":\"1\"}],\"features\":[{\"content\":\"发送到发送到发\",\"description\":\"发送到发送到发送到\",\"link\":\"\",\"createTime\":\"2022-07-22 19:38:25\",\"updateTime\":\"2022-07-22 19:38:25\",\"createUser\":{\"name\":null,\"id\":\"1\"},\"updateUser\":{\"name\":null,\"id\":\"1\"},\"id\":-894,\"createUser_name\":null,\"createUser_id\":\"1\",\"updateUser_name\":null,\"updateUser_id\":\"1\"}],\"advantages\":[{\"content\":\"发送到发\",\"description\":\"发送到发多少分\",\"link\":\"\",\"createTime\":\"2022-07-22 19:38:13\",\"updateTime\":\"2022-07-22 19:38:13\",\"createUser\":{\"name\":null,\"id\":\"1\"},\"updateUser\":{\"name\":null,\"id\":\"1\"},\"id\":-955,\"createUser_name\":null,\"createUser_id\":\"1\",\"updateUser_name\":null,\"updateUser_id\":\"1\"},{\"content\":\"发送到发送到\",\"description\":\"发送到发送到发\",\"link\":\"\",\"createTime\":\"2022-07-22 19:38:18\",\"updateTime\":\"2022-07-22 19:38:18\",\"createUser\":{\"name\":null,\"id\":\"1\"},\"updateUser\":{\"name\":null,\"id\":\"1\"},\"id\":-309,\"createUser_name\":null,\"createUser_id\":\"1\",\"updateUser_name\":null,\"updateUser_id\":\"1\"}],\"video_url\":\"sadfasdf\"}',_binary '',5466);
/*!40000 ALTER TABLE `e_upms_operate_log` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `e_upms_org`
--

DROP TABLE IF EXISTS `e_upms_org`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `e_upms_org` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `code` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `name` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `sort` int(11) DEFAULT NULL,
  `parent_org_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `UKc2wj35ujq2m84uw59dx6wy3gj` (`code`),
  KEY `FKtj7222kjnkt7pv9kfn9g8ck4h` (`parent_org_id`),
  CONSTRAINT `FKtj7222kjnkt7pv9kfn9g8ck4h` FOREIGN KEY (`parent_org_id`) REFERENCES `e_upms_org` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `e_upms_org`
--

LOCK TABLES `e_upms_org` WRITE;
/*!40000 ALTER TABLE `e_upms_org` DISABLE KEYS */;
/*!40000 ALTER TABLE `e_upms_org` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `e_upms_post`
--

DROP TABLE IF EXISTS `e_upms_post`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `e_upms_post` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `code` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `name` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `weight` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `UKltq5h3n5cyyk5nxtjhg9lhidg` (`code`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `e_upms_post`
--

LOCK TABLES `e_upms_post` WRITE;
/*!40000 ALTER TABLE `e_upms_post` DISABLE KEYS */;
/*!40000 ALTER TABLE `e_upms_post` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `e_upms_role`
--

DROP TABLE IF EXISTS `e_upms_role`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `e_upms_role` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `code` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `name` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `sort` int(11) DEFAULT NULL,
  `status` bit(1) DEFAULT NULL,
  `create_user_id` bigint(20) DEFAULT NULL,
  `update_user_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `UKjgxkp7mr4183tcwosrbqpsl3a` (`code`),
  KEY `FKad39xpgtpmhq0fp5newnabv1g` (`create_user_id`),
  KEY `FKbghup2p4f1x9eokeygyg8p658` (`update_user_id`),
  CONSTRAINT `FKad39xpgtpmhq0fp5newnabv1g` FOREIGN KEY (`create_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKbghup2p4f1x9eokeygyg8p658` FOREIGN KEY (`update_user_id`) REFERENCES `e_upms_user` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `e_upms_role`
--

LOCK TABLES `e_upms_role` WRITE;
/*!40000 ALTER TABLE `e_upms_role` DISABLE KEYS */;
INSERT INTO `e_upms_role` VALUES (1,'2022-07-12 21:35:10','2022-07-13 14:38:35','1','官网维护',1,_binary '',1,1);
/*!40000 ALTER TABLE `e_upms_role` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `e_upms_role_menu`
--

DROP TABLE IF EXISTS `e_upms_role_menu`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `e_upms_role_menu` (
  `role_id` bigint(20) NOT NULL,
  `menu_id` bigint(20) NOT NULL,
  PRIMARY KEY (`role_id`,`menu_id`),
  KEY `FKr6bl403chgwjnb6jk0uqqd9x8` (`menu_id`),
  CONSTRAINT `FKgsdnakqsme4htxkiapwmf6tbi` FOREIGN KEY (`role_id`) REFERENCES `e_upms_role` (`id`),
  CONSTRAINT `FKr6bl403chgwjnb6jk0uqqd9x8` FOREIGN KEY (`menu_id`) REFERENCES `e_upms_menu` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `e_upms_role_menu`
--

LOCK TABLES `e_upms_role_menu` WRITE;
/*!40000 ALTER TABLE `e_upms_role_menu` DISABLE KEYS */;
INSERT INTO `e_upms_role_menu` VALUES (1,55);
/*!40000 ALTER TABLE `e_upms_role_menu` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `e_upms_user`
--

DROP TABLE IF EXISTS `e_upms_user`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `e_upms_user` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `account` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `is_admin` bit(1) DEFAULT NULL,
  `status` bit(1) DEFAULT NULL,
  `create_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `email` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `is_md5` bit(1) DEFAULT NULL,
  `password` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `phone` varchar(255) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `remark` varchar(2000) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `reset_pwd_time` datetime DEFAULT NULL,
  `white_ip` varchar(2000) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  `erupt_org_id` bigint(20) DEFAULT NULL,
  `erupt_post_id` bigint(20) DEFAULT NULL,
  `create_user_id` bigint(20) DEFAULT NULL,
  `update_user_id` bigint(20) DEFAULT NULL,
  `erupt_menu_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  UNIQUE KEY `UK812t22yn0295dkkvx5gjgahax` (`account`),
  KEY `FK1re8jv3614mkk2wfxscvgvmnm` (`erupt_org_id`),
  KEY `FK53cice19aydjcuykpv847ocdv` (`erupt_post_id`),
  KEY `FKdvwfw4x66ahh1tavd69cnx4i0` (`create_user_id`),
  KEY `FKct3f9stm4eti10401f7rbh5ey` (`update_user_id`),
  KEY `FKga0jd7sahnn1tv14mq4dy5kba` (`erupt_menu_id`),
  CONSTRAINT `FK1re8jv3614mkk2wfxscvgvmnm` FOREIGN KEY (`erupt_org_id`) REFERENCES `e_upms_org` (`id`),
  CONSTRAINT `FK53cice19aydjcuykpv847ocdv` FOREIGN KEY (`erupt_post_id`) REFERENCES `e_upms_post` (`id`),
  CONSTRAINT `FKct3f9stm4eti10401f7rbh5ey` FOREIGN KEY (`update_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKdvwfw4x66ahh1tavd69cnx4i0` FOREIGN KEY (`create_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKga0jd7sahnn1tv14mq4dy5kba` FOREIGN KEY (`erupt_menu_id`) REFERENCES `e_upms_menu` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `e_upms_user`
--

LOCK TABLES `e_upms_user` WRITE;
/*!40000 ALTER TABLE `e_upms_user` DISABLE KEYS */;
INSERT INTO `e_upms_user` VALUES (1,'admin','admin',_binary '',_binary '','2022-07-11 20:41:10','2022-07-12 21:32:01',NULL,_binary '','e10adc3949ba59abbe56e057f20f883e',NULL,NULL,'2022-07-12 19:29:18',NULL,NULL,NULL,NULL,1,NULL),(2,'test1','test1',_binary '\0',_binary '','2022-07-12 21:36:23','2022-07-12 21:36:23',NULL,_binary '','4297f44b13955235245b2497399d7a93',NULL,NULL,'2022-07-12 21:37:45',NULL,NULL,NULL,1,1,NULL);
/*!40000 ALTER TABLE `e_upms_user` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `e_upms_user_role`
--

DROP TABLE IF EXISTS `e_upms_user_role`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `e_upms_user_role` (
  `user_id` bigint(20) NOT NULL,
  `role_id` bigint(20) NOT NULL,
  PRIMARY KEY (`role_id`,`user_id`),
  KEY `FKes2ylim5w3ej690ss84sb956x` (`user_id`),
  CONSTRAINT `FK3h4lekfh26f5f8b7by3ejges6` FOREIGN KEY (`role_id`) REFERENCES `e_upms_role` (`id`),
  CONSTRAINT `FKes2ylim5w3ej690ss84sb956x` FOREIGN KEY (`user_id`) REFERENCES `e_upms_user` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `e_upms_user_role`
--

LOCK TABLES `e_upms_user_role` WRITE;
/*!40000 ALTER TABLE `e_upms_user_role` DISABLE KEYS */;
INSERT INTO `e_upms_user_role` VALUES (1,1),(2,1);
/*!40000 ALTER TABLE `e_upms_user_role` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `website_blog`
--

DROP TABLE IF EXISTS `website_blog`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `website_blog` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `author` varchar(255) DEFAULT NULL,
  `content` longtext,
  `description` varchar(255) DEFAULT NULL,
  `pic` varchar(255) DEFAULT NULL,
  `publish` bit(1) DEFAULT NULL,
  `title` varchar(255) DEFAULT NULL,
  `create_user_id` bigint(20) DEFAULT NULL,
  `update_user_id` bigint(20) DEFAULT NULL,
  `slug` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FKopwbfs6neoigyu0kjgi367bg2` (`create_user_id`),
  KEY `FKrcglasy30p7icn0fh8aa5cve8` (`update_user_id`),
  CONSTRAINT `FKopwbfs6neoigyu0kjgi367bg2` FOREIGN KEY (`create_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKrcglasy30p7icn0fh8aa5cve8` FOREIGN KEY (`update_user_id`) REFERENCES `e_upms_user` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `website_blog`
--

LOCK TABLES `website_blog` WRITE;
/*!40000 ALTER TABLE `website_blog` DISABLE KEYS */;
/*!40000 ALTER TABLE `website_blog` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `website_blog_category`
--

DROP TABLE IF EXISTS `website_blog_category`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `website_blog_category` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `is_show` bit(1) DEFAULT NULL,
  `name` varchar(255) DEFAULT NULL,
  `remark` varchar(255) DEFAULT NULL,
  `sort` int(11) DEFAULT NULL,
  `create_user_id` bigint(20) DEFAULT NULL,
  `update_user_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FKcj8f2b9h4ncli73lxdy5nt4yl` (`create_user_id`),
  KEY `FKqq00amwplaf2a4vj0yuain7s6` (`update_user_id`),
  CONSTRAINT `FKcj8f2b9h4ncli73lxdy5nt4yl` FOREIGN KEY (`create_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKqq00amwplaf2a4vj0yuain7s6` FOREIGN KEY (`update_user_id`) REFERENCES `e_upms_user` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `website_blog_category`
--

LOCK TABLES `website_blog_category` WRITE;
/*!40000 ALTER TABLE `website_blog_category` DISABLE KEYS */;
/*!40000 ALTER TABLE `website_blog_category` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `website_blog_tag`
--

DROP TABLE IF EXISTS `website_blog_tag`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `website_blog_tag` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `name` varchar(255) DEFAULT NULL,
  `create_user_id` bigint(20) DEFAULT NULL,
  `update_user_id` bigint(20) DEFAULT NULL,
  `blog_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FKqo0bcfau07q1bhj0a56xctlbd` (`create_user_id`),
  KEY `FKeh0u8njl5sf6cjvip8skkmxhj` (`update_user_id`),
  KEY `FKaj72f6d39g5frs7uoap290j93` (`blog_id`),
  CONSTRAINT `FKaj72f6d39g5frs7uoap290j93` FOREIGN KEY (`blog_id`) REFERENCES `website_blog` (`id`),
  CONSTRAINT `FKeh0u8njl5sf6cjvip8skkmxhj` FOREIGN KEY (`update_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKqo0bcfau07q1bhj0a56xctlbd` FOREIGN KEY (`create_user_id`) REFERENCES `e_upms_user` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `website_blog_tag`
--

LOCK TABLES `website_blog_tag` WRITE;
/*!40000 ALTER TABLE `website_blog_tag` DISABLE KEYS */;
/*!40000 ALTER TABLE `website_blog_tag` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `website_company`
--

DROP TABLE IF EXISTS `website_company`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `website_company` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `blog_id` varchar(255) DEFAULT NULL,
  `description` varchar(255) DEFAULT NULL,
  `logo` varchar(255) DEFAULT NULL,
  `name` varchar(255) DEFAULT NULL,
  `other` varchar(255) DEFAULT NULL,
  `create_user_id` bigint(20) DEFAULT NULL,
  `update_user_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FK5mq1qlfpk32hfyendfqo27glf` (`create_user_id`),
  KEY `FKoyg8tss4that9ku9t4myw83gc` (`update_user_id`),
  CONSTRAINT `FK5mq1qlfpk32hfyendfqo27glf` FOREIGN KEY (`create_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKoyg8tss4that9ku9t4myw83gc` FOREIGN KEY (`update_user_id`) REFERENCES `e_upms_user` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `website_company`
--

LOCK TABLES `website_company` WRITE;
/*!40000 ALTER TABLE `website_company` DISABLE KEYS */;
/*!40000 ALTER TABLE `website_company` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `website_dictionary`
--

DROP TABLE IF EXISTS `website_dictionary`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `website_dictionary` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `dict_key` varchar(255) DEFAULT NULL,
  `dict_value` longtext NOT NULL,
  `remark` varchar(255) DEFAULT NULL,
  `create_user_id` bigint(20) DEFAULT NULL,
  `update_user_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FKjqjyevnw8dn7slbpvnvje1ggb` (`create_user_id`),
  KEY `FKj5oyotgls2nuuxm1rfhttkbcw` (`update_user_id`),
  CONSTRAINT `FKj5oyotgls2nuuxm1rfhttkbcw` FOREIGN KEY (`update_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKjqjyevnw8dn7slbpvnvje1ggb` FOREIGN KEY (`create_user_id`) REFERENCES `e_upms_user` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `website_dictionary`
--

LOCK TABLES `website_dictionary` WRITE;
/*!40000 ALTER TABLE `website_dictionary` DISABLE KEYS */;
INSERT INTO `website_dictionary` VALUES (1,'2022-07-27 07:18:41','2022-07-27 07:18:41','usecase','{\n    \"title\":\"Use Case\",\n    \"subTitle\":\"Download and explore whatever you want on Nebula Graph\",\n    \"footerTitle\":\"If you are intersted in Nebula Graph and need corporate services. Start a trial with Nebula Graph or contact us \",\n    \"footerLink\":\"/contact\",\n    \"footerLinkTitle\":\"Contact us\"\n}',NULL,1,1);
/*!40000 ALTER TABLE `website_dictionary` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `website_partner`
--

DROP TABLE IF EXISTS `website_partner`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `website_partner` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `blog_id` varchar(255) DEFAULT NULL,
  `description` varchar(255) DEFAULT NULL,
  `logo` varchar(255) DEFAULT NULL,
  `other` varchar(255) DEFAULT NULL,
  `create_user_id` bigint(20) DEFAULT NULL,
  `update_user_id` bigint(20) DEFAULT NULL,
  `partner_category_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FKgdmk19oufi87y4g5cf6q2lq52` (`create_user_id`),
  KEY `FK8vrlserdkk78f8yko8pjb564e` (`update_user_id`),
  KEY `FKddbgqdtm1sja6egv603433l90` (`partner_category_id`),
  CONSTRAINT `FK8vrlserdkk78f8yko8pjb564e` FOREIGN KEY (`update_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKddbgqdtm1sja6egv603433l90` FOREIGN KEY (`partner_category_id`) REFERENCES `website_partner_category` (`id`),
  CONSTRAINT `FKgdmk19oufi87y4g5cf6q2lq52` FOREIGN KEY (`create_user_id`) REFERENCES `e_upms_user` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `website_partner`
--

LOCK TABLES `website_partner` WRITE;
/*!40000 ALTER TABLE `website_partner` DISABLE KEYS */;
/*!40000 ALTER TABLE `website_partner` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `website_partner_category`
--

DROP TABLE IF EXISTS `website_partner_category`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `website_partner_category` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `is_show` bit(1) DEFAULT NULL,
  `name` varchar(255) DEFAULT NULL,
  `remark` varchar(255) DEFAULT NULL,
  `sort` int(11) DEFAULT NULL,
  `create_user_id` bigint(20) DEFAULT NULL,
  `update_user_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FKq97bdkmypwojg6f7bnd716661` (`create_user_id`),
  KEY `FKh3a392s5ga12rjbh0e4cqy6q2` (`update_user_id`),
  CONSTRAINT `FKh3a392s5ga12rjbh0e4cqy6q2` FOREIGN KEY (`update_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKq97bdkmypwojg6f7bnd716661` FOREIGN KEY (`create_user_id`) REFERENCES `e_upms_user` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `website_partner_category`
--

LOCK TABLES `website_partner_category` WRITE;
/*!40000 ALTER TABLE `website_partner_category` DISABLE KEYS */;
/*!40000 ALTER TABLE `website_partner_category` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `website_product`
--

DROP TABLE IF EXISTS `website_product`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `website_product` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `description` varchar(255) DEFAULT NULL,
  `name` varchar(255) DEFAULT NULL,
  `other` varchar(255) DEFAULT NULL,
  `summary` varchar(255) DEFAULT NULL,
  `summary_feature` varchar(255) DEFAULT NULL,
  `summary_feature_pic` varchar(255) DEFAULT NULL,
  `type` varchar(255) DEFAULT NULL,
  `video_url` varchar(255) DEFAULT NULL,
  `create_user_id` bigint(20) DEFAULT NULL,
  `update_user_id` bigint(20) DEFAULT NULL,
  `main_pic` varchar(255) DEFAULT NULL,
  `reason_subtitle` varchar(255) DEFAULT NULL,
  `product_category_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FKrow8iau1nsq6jeal75rn3qjpv` (`create_user_id`),
  KEY `FK6eic8oh8ogh5jha36b92d84fh` (`update_user_id`),
  KEY `FKsr2g3mx3xggl4oa2c706nykng` (`product_category_id`),
  CONSTRAINT `FK6eic8oh8ogh5jha36b92d84fh` FOREIGN KEY (`update_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKrow8iau1nsq6jeal75rn3qjpv` FOREIGN KEY (`create_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKsr2g3mx3xggl4oa2c706nykng` FOREIGN KEY (`product_category_id`) REFERENCES `website_product_category` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `website_product`
--

LOCK TABLES `website_product` WRITE;
/*!40000 ALTER TABLE `website_product` DISABLE KEYS */;
/*!40000 ALTER TABLE `website_product` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `website_product_category`
--

DROP TABLE IF EXISTS `website_product_category`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `website_product_category` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `is_show` bit(1) DEFAULT NULL,
  `name` varchar(255) DEFAULT NULL,
  `remark` varchar(255) DEFAULT NULL,
  `create_user_id` bigint(20) DEFAULT NULL,
  `update_user_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FKbp1t4xphen6ks9j961yt8fhqg` (`create_user_id`),
  KEY `FK334rfvuw43hpyrs6x57f73fbp` (`update_user_id`),
  CONSTRAINT `FK334rfvuw43hpyrs6x57f73fbp` FOREIGN KEY (`update_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKbp1t4xphen6ks9j961yt8fhqg` FOREIGN KEY (`create_user_id`) REFERENCES `e_upms_user` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `website_product_category`
--

LOCK TABLES `website_product_category` WRITE;
/*!40000 ALTER TABLE `website_product_category` DISABLE KEYS */;
/*!40000 ALTER TABLE `website_product_category` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `website_product_feature`
--

DROP TABLE IF EXISTS `website_product_feature`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `website_product_feature` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `content` varchar(255) DEFAULT NULL,
  `description` varchar(255) DEFAULT NULL,
  `link` varchar(255) DEFAULT NULL,
  `subContent` varchar(255) DEFAULT NULL,
  `create_user_id` bigint(20) DEFAULT NULL,
  `update_user_id` bigint(20) DEFAULT NULL,
  `product_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FKawglnux0ib73wvmptpuejj3en` (`create_user_id`),
  KEY `FKsr0dhccwl4ix1lk2n2ctlj5dp` (`update_user_id`),
  KEY `FK5040pla8keotexhrqn1gnm2we` (`product_id`),
  CONSTRAINT `FK5040pla8keotexhrqn1gnm2we` FOREIGN KEY (`product_id`) REFERENCES `website_product` (`id`),
  CONSTRAINT `FKawglnux0ib73wvmptpuejj3en` FOREIGN KEY (`create_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKsr0dhccwl4ix1lk2n2ctlj5dp` FOREIGN KEY (`update_user_id`) REFERENCES `e_upms_user` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `website_product_feature`
--

LOCK TABLES `website_product_feature` WRITE;
/*!40000 ALTER TABLE `website_product_feature` DISABLE KEYS */;
/*!40000 ALTER TABLE `website_product_feature` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `website_product_reason`
--

DROP TABLE IF EXISTS `website_product_reason`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `website_product_reason` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `content` varchar(255) DEFAULT NULL,
  `icon` varchar(255) DEFAULT NULL,
  `create_user_id` bigint(20) DEFAULT NULL,
  `update_user_id` bigint(20) DEFAULT NULL,
  `product_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FK3909rj28l7eyfjkk0uh5syr7g` (`create_user_id`),
  KEY `FKmu4rs1frk81t1sfhmi50a2gb0` (`update_user_id`),
  KEY `FKs0tdnndbq7c5geg57fh9lh9y1` (`product_id`),
  CONSTRAINT `FK3909rj28l7eyfjkk0uh5syr7g` FOREIGN KEY (`create_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKmu4rs1frk81t1sfhmi50a2gb0` FOREIGN KEY (`update_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKs0tdnndbq7c5geg57fh9lh9y1` FOREIGN KEY (`product_id`) REFERENCES `website_product` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `website_product_reason`
--

LOCK TABLES `website_product_reason` WRITE;
/*!40000 ALTER TABLE `website_product_reason` DISABLE KEYS */;
/*!40000 ALTER TABLE `website_product_reason` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `website_product_version`
--

DROP TABLE IF EXISTS `website_product_version`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `website_product_version` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `function_type` varchar(255) DEFAULT NULL,
  `name` varchar(255) DEFAULT NULL,
  `product_type` varchar(255) DEFAULT NULL,
  `version` varchar(255) DEFAULT NULL,
  `create_user_id` bigint(20) DEFAULT NULL,
  `update_user_id` bigint(20) DEFAULT NULL,
  `product_category_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FK51u89fxjyf74pwa0df0o8r3p5` (`create_user_id`),
  KEY `FK53nyxtg4rba57aclt6vht3696` (`update_user_id`),
  KEY `FK6v16kwvqsmvdni863qnw0lm6h` (`product_category_id`),
  CONSTRAINT `FK51u89fxjyf74pwa0df0o8r3p5` FOREIGN KEY (`create_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FK53nyxtg4rba57aclt6vht3696` FOREIGN KEY (`update_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FK6v16kwvqsmvdni863qnw0lm6h` FOREIGN KEY (`product_category_id`) REFERENCES `website_product_category` (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `website_product_version`
--

LOCK TABLES `website_product_version` WRITE;
/*!40000 ALTER TABLE `website_product_version` DISABLE KEYS */;
INSERT INTO `website_product_version` VALUES (1,'2022-07-28 22:41:48','2022-07-28 22:41:48','Monitor','fadfadf','dashboard','enterprise|community',1,1,NULL);
/*!40000 ALTER TABLE `website_product_version` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `website_usecase`
--

DROP TABLE IF EXISTS `website_usecase`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `website_usecase` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `create_time` datetime DEFAULT NULL,
  `update_time` datetime DEFAULT NULL,
  `description` varchar(255) DEFAULT NULL,
  `link` varchar(255) DEFAULT NULL,
  `title` varchar(255) DEFAULT NULL,
  `create_user_id` bigint(20) DEFAULT NULL,
  `update_user_id` bigint(20) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `FKp7d4c1167rdxt013fkrm4jquj` (`create_user_id`),
  KEY `FKfr1wea10muao1lyt4q12eav54` (`update_user_id`),
  CONSTRAINT `FKfr1wea10muao1lyt4q12eav54` FOREIGN KEY (`update_user_id`) REFERENCES `e_upms_user` (`id`),
  CONSTRAINT `FKp7d4c1167rdxt013fkrm4jquj` FOREIGN KEY (`create_user_id`) REFERENCES `e_upms_user` (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `website_usecase`
--

LOCK TABLES `website_usecase` WRITE;
/*!40000 ALTER TABLE `website_usecase` DISABLE KEYS */;
/*!40000 ALTER TABLE `website_usecase` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2022-08-02  3:22:26